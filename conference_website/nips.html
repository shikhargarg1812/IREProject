<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="NeurIPS Website">
    <meta name="author" content="Neural Information Processing Systems Foundation">
    <!--   <link rel="shortcut icon" href="../../assets/ico/favicon.ico"> -->
    <script src="/static/virtual/js/virtual.js"></script>
    <meta name="google-site-verification" content="0jwPnVXIAk4FvFdT37dwMmd-kjHF86e5DKwvqlStUW0"/>

    <title>NeurIPS 2019 Videos</title>

    <!-- Custom styles for this template -->
    <link rel="stylesheet" href="/static/core/css/nips.css" type="text/css">
    <link rel="stylesheet" href="/static/core/bootstrap-3.4.1/css/bootstrap.min.css" type="text/css">
    <link rel="stylesheet" href="/static/core/css/offcanvas.css" type="text/css">
    <link rel="stylesheet" href="/static/core/css/custom.css" type="text/css">
    <link rel="stylesheet" href="/static/core/glyphicons_pro/glyphicons/web/html_css/css/glyphicons.css"
          type="text/css">
    <link rel="stylesheet" href="/static/core/bootstrap-wizard/src/bootstrap-wizard.css" type="text/css">


    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
  "tex2jax": {
    "inlineMath": [["$","$"], ["\\(","\\)"]],
    "displayMath": [["\\[","\\]"]],
    "processEscapes": true
  }
}
);

    </script>

    <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>


    <style>
        a[href]:after {
            content: none !important;
        }

        button:after {
            content: none !important;
        }
    </style>
    <!--This script keeps local links inside the web app rather than opening them
in Safari, and has nothing to do with editing or Aloha.-->

<script type="text/javascript">
	(function(document,navigator,standalone) {
		// prevents links from apps from oppening in mobile safari
		// this javascript must be the first script in your <head>
		if ((standalone in navigator) && navigator[standalone]) {
			var curnode, location=document.location, stop=/^(a|html)$/i;
			document.addEventListener('click', function(e) {
				curnode=e.target;
				while (!(stop).test(curnode.nodeName)) {
					curnode=curnode.parentNode;
				}
				// Condidions to do this only on links to your own app
				// if you want all links, use if('href' in curnode) instead.
				if(
					'href' in curnode && // is a link
					(chref=curnode.href).replace(location.href,'').indexOf('#') && // is not an anchor
					(	!(/^[a-z\+\.\-]+:/i).test(chref) ||                       // either does not have a proper scheme (relative links)
						chref.indexOf(location.protocol+'//'+location.host)===0 ) // or is in the same protocol and domain
				) {
					e.preventDefault();
					location.href = curnode.href;
				}
			},false);
		}
	})(document,window.navigator,'standalone');
</script>        

<!-- This style sets the minimum size of a blurb to 260 px unless there is a
template context variable blurb_min_height that sets it otherwise. If blurbs
aren't all about the same size, they don't flow well when the window is
resized.-->


<style>
/*This is here rather that in a .css file for a reason.*/
    @media screen and (min-width: 767px) {
        .blurb {
            min-height:260px;
        }
    }
</style>


    
    <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
    <script>if (typeof jQuery === 'undefined') {
        document.write(unescape('%3Cscript%20src%3D%22//static/core/js/jquery-2.2.4.min.js%22%3E%3C/script%3E'));
    }
    </script>


    <script>
        var jq2 = jQuery;
        /*Store a pointer to jquery2 so I can reference it later.  Aloha loads jquery 1.7 and much of bootstrap 3 is not compatible*/

    </script>

    
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script>
        if (typeof ($.fn.modal) === 'undefined') {
            document.write('<script src="//static/core/bootstrap/dist/js/bootstrap.min.js"><\/script>')
        }
    </script>

    


    <script src="/static/core/js/ajax-csrf-snippet.js" type="text/javascript"></script>


    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css"
          integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">


    

</head>
`
<body style="min-height:900px">


<div class="noprint">

    <div class="navbar navbar-fixed-top navbar-inverse showborder" role="navigation" style="height:50px !important">
        <div class="container showborder">
            <p class="pull-left visible-xs">
                <button type="button" class="navbar-toggle" data-toggle="offcanvas" onclick="window.scrollTo(0, 0);"
                        id="hamburger">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>

                </button>
            </p>
            <div class="navbar-header" style="white-space:nowrap;">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse"
                        style="position:relative;top:-5px" id="toggleSearch">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="glyphicon glyphicon-search" style="color:white;"></span>
                </button>
                <a class="navbar-brand" href="/"><span class="glyphicon glyphicon-home"></span></a>


                
                    
                    <a href="/accounts/login?nextp=/Conferences/2019/Videos " class="navbar-brand"><span
                            class="glyphicon glyphicon-log-in"></span> Login</a>
                
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;


            </div>
            <div class="collapse navbar-inverse navbar-collapse" style="padding-left:50px">

                <form class="navbar-form " role="search" action="/search">
                    <div class="input-group" style="max-width:400px">
                        <input type="text" class="form-control" spellcheck="false" placeholder="Search neurips.cc"
                               name="q" id="nips-search" style="width:100%">
                        <div class="input-group-btn">
                            <button class="btn btn-primary" type="submit"><i class="glyphicon glyphicon-search"></i>
                            </button>
                        </div>
                    </div>
                </form>

            </div><!-- /.nav-collapse -->
        </div><!-- /.container -->
    </div><!-- /.navbar -->
    </div><!--noprint div-->
    <!--For unit tests-->
    <div id="menuLoad"></div>



<div class="container pull-left" style="min-height:00px"> <!--The main container for the page content-->

    <div id="wholepage" class="row row-offcanvas row-offcanvas-left" style="z-index:5">
        <!--This holds the whole page including the navbar-->

        <!-- Sidebar on the left-->

        <div class="col-xs-6 col-sm-3 sidebar-offcanvas noprint" id="sidebar" role="navigation" style="z-index:5">
            <div class="Droid"><span style="font-size:2em">
                <b>NeurIPS <span>| 2019 </b></span><br>
                <div class="small">Thirty-third Conference on Neural Information Processing
                    Systems
                </div>
            </div>
            <div class="list-group">
                <div class="dropdown list-group-item active" style="background-color: #357ebd; border-color: #357ebd;"
                     id="dropdownMenu1">
                    <div class="dropdown-toggle btn-link" data-toggle="dropdown" style="color:white">
                        <span class="hidden-xs">Year </span><span id="conferenceYear"
                            
                                                                  class="blink">(2019)</span>
                        <span class="caret"></span>
                    </div>
                    <ul class="dropdown-menu" role="menu" aria-labelledby="dropdownMenu1" id="previousConferencesMenu">
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2021">2021</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2020">2020</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2019">2019</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2018">2018</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2017">2017</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2016">2016</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2015">2015</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2014">2014</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2013">2013</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2012">2012</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2011">2011</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2010">2010</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2009">2009</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2008">2008</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2007">2007</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/2006">2006</a></li>
                        <li role="presentation" class="divider"></li>
                        <li class="" role="menuitem" tabindex="-1"><a href="/Conferences/PastConferences">Earlier
                            Conferences</a></li>
                    </ul>
                </div>


                
                    
                    
                


                <div class="dropdown list-group-item">
                  <div class="dropdown-toggle btn-link" id="dropdownMenu4" data-toggle="dropdown">
                      Help <span class="caret"></span>
                  </div>
                      <ul class="dropdown-menu" role="menu" aria-labelledby="dropdownMenu4">
                        <li role="menuitem" tabindex="-1"> <a  href="/FAQ"><span class="glyphicon glyphicon-question-sign text-primary"></span> FAQ</a></li>
                        <li role="presentation" class="divider"></li>
                        <li role="menuitem" tabindex="-1"> <a href="/Profile/create"><span class="glyphicon glyphicon-user text-primary"></span> Create an Account</a></li>
                        <li role="presentation" class="divider"></li>
                        <li role="menuitem" tabindex="-1"> <a href="/Profile/resetpassword"><span class="glyphicon glyphicon-user text-primary"></span> Reset Password</a></li>
                        <li role="presentation" class="divider"></li>
                        <li role="menuitem" tabindex="-1"> <a href="/MergeAccounts"><i class="fa fa-user-plus text-primary"></i> Merge Profiles</a></li>
                        <li role="presentation" class="divider"></li>
                        <li role="menuitem" tabindex="-1"> <a href="/public/PrivacyPolicy"><span class="glyphicon glyphicon-info-sign text-primary"></span> Privacy Policy</a></li>
                      </ul>
                </div><!--HelpListGroup-->


                <li class="list-group-item" role="menuitem"><a href="/Profile">My Registrations</a></li>

                <!--=============Account================-->
                <div class="dropdown list-group-item">
                    <div class="dropdown-toggle btn-link" id="account" data-toggle="dropdown">
                        <span>Profile <span class="caret"></span></span>
                    </div>
                    <ul class="dropdown-menu" role="menu" aria-labelledby="account">
                        

                        <li role="menuitem"><a href="/EditProfile"><span
                                class="glyphicon glyphicon-edit text-primary"></span> Edit Profile</a></li>
                        <li role="presentation" class="divider"></li>
                        <li role="menuitem"><a href="/Profile/change-password"><span
                                class="glyphicon glyphicon-asterisk text-primary"></span> Change Password</a></li>
                        <li role="presentation" class="divider"></li>
                        <li role="menuitem"><a href="/MergeAccounts"><i class="fa fa-share-alt text-primary"></i> Merge
                            Profiles</a></li>
                        <li role="presentation" class="divider"></li>
                        <li role="menuitem"><a href="/Profile/create"><i class="fa fa-user-plus text-primary"></i>
                            Create New Profile</a></li>
                        <li role="presentation" class="divider"></li>
                        <li role="menuitem"><a href="/Profile/resetpassword"><i
                                class="fa fa-unlock-alt text-primary"></i> Reset Password</a></li>
                        <li role="presentation" class="divider"></li>
                        <li role="menuitem"><a href="/accounts/login?nextp=/"><span
                                class="glyphicon glyphicon-log-in text-primary"></span> Log In</a></li>
                        <li role="presentation" class="divider"></li>
                        <li role="menuitem"><a href="/logout"><span
                                class="glyphicon glyphicon-log-out text-primary"></span> Log Out </a></li>
                    </ul>
                </div>
                <!--=============Account================-->

                <a class="list-group-item" href="/Help/Contact"> Contact NeurIPS</a>
                <a href="https://blog.neurips.cc" class="list-group-item">NeurIPS Blog</a>
                <a href="/public/EthicsGuidelines" class="list-group-item">Ethics Guidelines</a>
                <a href="/public/CodeOfConduct" class="list-group-item">Code of Conduct</a>
                <a href="/public/DiversityInclusion" class="list-group-item">Diversity &amp; Inclusion</a>


                <!--<a href="/Conferences/2019/Committees" class="list-group-item">Committees</a>-->
                <a href="https://proceedings.neurips.cc" class="list-group-item">Online Proceedings</a>
                
                <a href="https://videos.neurips.cc/" class="list-group-item">Video Archives</a>
                
                
                

                <div class="list-group-item">
                    
                    <img src="/static/core/img/neurips-logo-new.svg" width="75" alt="NeurIPSLogo">
                </div>
            </div><!--Sidebar ListGroup-->






        </div><!--/sidebar on the left-->




        
        <main id="main">
            
                <div class="col-xs-9">
                    <nav class="navbar navbar-default">
  <div class="container-fluid ">
    <!-- Brand and toggle get grouped for better mobile display -->

    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

        <li><a href="/Conferences/2019/Dates">Dates</a></li>
        
          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Schedule<span class="caret"></span></a>
            <ul class="dropdown-menu">
                <li role="menuitem" tabindex="-1"> <a href="/Conferences/2019/Schedule"> Full Schedule <small class="gray">(mobile friendly)</small></a></li>
                <li role="presentation" class="divider"></li>
                <li role="menuitem" tabindex="-1"> <a href="/Conferences/2019/ScheduleMultitrack"> Multitrack Schedule</a></li>
                <li role="presentation" class="divider"></li>
                <li role="menuitem" tabindex="-1"> <a href="https://media.neurips.cc/Conferences/NeurIPS2019/NeurIPSProgramBook.pdf"> Conference Program PDF</a></li>
                <li role="presentation" class="divider"></li>
                <li role="menuitem" tabindex="-1"> <a href="https://media.neurips.cc/Conferences/NeurIPS2019/DiversityBrochure2019.pdf"> D &amp; I Brochure and Schedule</a></li>
                <li role="presentation" class="divider"></li>
                <li role="menuitem" tabindex="-1"> <a href="https://media.neurips.cc/Conferences/NeurIPS2019/NeurIPS_Expo_Book_2019.pdf"> Expo Brochure</a></li>
                <li role="presentation" class="divider"></li>
                <li role="menuitem" tabindex="-1"> <a href="/Conferences/2019/Workshopbook/100"> Workshop Book PDF</a></li>
                <li role="presentation" class="divider"></li>
                <li role="menuitem" tabindex="-1"> <a href="/Conferences/2019/Workshopbook/140"> Workshop Book (Large Type)</a></li>
                
                
            </ul>
          </li>
          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Submit<span class="caret"></span></a>
  					<ul class="dropdown-menu" role="menu" aria-labelledby="dropdownMenu3">

  							<li ><b> &nbsp;&nbsp;Calls 2019</b></li>
                <li role="menuitem" tabindex="-1"><a href="/Conferences/2019/CallForTutorials" class="strikethrough">Call for Tutorials</a></li>
  							<li role="menuitem" tabindex="-1"><a href="/Conferences/2019/CallForPapers" class="strikethrough">Call for Papers</a></li>
                <li role="menuitem" tabindex="-1"><a  href="/Conferences/2019/CallForCompetitions" class="">Call for Competitions &nbsp;</a></li>  
                <li role="menuitem" tabindex="-1"><a  href="/Conferences/2019/CallForDemonstrations" class="">Call for Demonstrations &nbsp;</a></li>
                <li role="menuitem" tabindex="-1"><a  href="/Conferences/2019/CallForWorkshops" class="strikethrough">Call for Workshops &nbsp;</a></li>
                <li role="menuitem" tabindex="-1"><a class="" href="https://nips.cc/Conferences/2019/AcceptedWorkshopFAQ" style="font-size:.8em">&nbsp;&nbsp;&nbsp;&nbsp;Workshop FAQ &nbsp;</a></li>
                <li role="menuitem" tabindex="-1"><a  href="/Conferences/2019/CallForMusic" class="">Call for Music &nbsp;</a></li>

                
                <li role="presentation" class="divider"></li>


  						
              
                <li><b> &nbsp;&nbsp;Author Resources</b></li>
    						<li role="menuitem" tabindex="-1"> <a href="https://cmt3.research.microsoft.com/NeurIPS2019/"> NeurIPS 2019 CMT Site</a></li>

    						
                <li role="menuitem" tabindex="-1"> <a href="/Conferences/2019/PaperInformation/AC-SACGuidelines">AC and SAC Guidelines</a></li>
                <li role="menuitem" tabindex="-1"> <a href="/Conferences/2019/PaperInformation/ReviewerGuidelines">Reviewer Guidelines</a></li>
    						<li role="menuitem" tabindex="-1"> <a href="/Conferences/2019/PaperInformation/SubjectAreas">Subject Areas</a></li>
    						<li role="menuitem" tabindex="-1"> <a href="/Conferences/2019/PaperInformation/StyleFiles">Style Files</a></li>
              
  					</ul>
            
          </li>
        

			



        
        
        
        <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Organizers<span class="caret"></span></a>
            <ul class="dropdown-menu">
              <li><a href="/Conferences/2019/Board">NeurIPS Board</a></li>
              <li role="presentation" class="divider"></li>
              <li><a href="/Conferences/2019/Committees">Organizing Committee</a></li>
              <li role="presentation" class="divider"></li>
              <li><a href="/Conferences/2019/ProgramCommittee">Program Committee</a></li>
              <li role="presentation" class="divider"></li>
              <li><a href="/Conferences/2019/Reviewers">Reviewers</a></li>
              <li role="presentation" class="divider"></li>
              <li><a href="/About">NeurIPS Foundation</a></li>
            </ul>
        </li>
        




      </ul><!--Navbar itself-->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>
<script>
    function toggleYearsMenu(){
      var menuflash = setInterval(function(){$("#conferenceYear").toggleClass("warning-ring")}, 150);
      setTimeout(function(){clearInterval(menuflash);}, 1000 );
      setTimeout(function(){$("#dropdownMenu1").toggleClass("open");}, 300);

    }




    function openPreviousMeetings(){
      window.scrollTo(0,0);
      if ($(window).width() < 786) {
        $("#wholepage").toggleClass('active');
        var flashing = setInterval(function(){$("#hamburger").toggleClass("warning-ring")}, 150);
        setTimeout(function(){clearInterval(flashing);}, 1000 );

        setTimeout(function(){toggleYearsMenu();}, 1350);
      } else {
        setTimeout(function(){toggleYearsMenu();}, 100);
      }
    }

    function programBooks(){
      window.scrollTo(0,0);
      if ($(window).width() < 786) {
        $("#wholepage").toggleClass('active');
        var flashing = setInterval(function(){$("#hamburger").toggleClass("warning-ring")}, 150);
        setTimeout(function(){clearInterval(flashing);}, 1000 );
        setTimeout(function(){$("#program_books").toggleClass("open");}, 300);
      } else {
        var menuflash = setInterval(function(){$("#program_books").toggleClass("warning-ring")}, 150);
        setTimeout(function(){clearInterval(menuflash);}, 1000 );
        setTimeout(function(){$("#program_books").toggleClass("open");}, 300);

      }
    }


</script>

                </div>
            

            

<div class="col-xs-12 col-sm-9"><!-- This helps keep the red "required" asterisk from being on top of the form labels.-->

	
	<button type="button" class="btn btn-primary pull-right lower btn-sm" onClick="$('.abstract').toggle();">Toggle Abstracts</button>
	<h3>NeurIPS 2019 Videos</h3><br>

	
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower oral" id="maincard_15732">
            <div class='pull-right maincardHeader maincardType'>Oral</div>
            <div class="maincardHeader">{daterange} @ West Ballroom C  </div>
            <div class="maincardBody">Updates of Equilibrium Prop Match Gradients of Backprop Through Time in an RNN with Static Input</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15731">
                    Track 4 Session 1</a>
                </div>
            
            <div class="maincardFooter">Maxence Ernoult &middot; Julie Grollier &middot; Damien Querlioz &middot; Yoshua Bengio &middot; Benjamin Scellier</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-3824" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=Xb5sM0NRy_0&feature=youtu.be" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Equilibrium Propagation (EP) is a biologically inspired learning algorithm for
convergent recurrent neural networks, i.e. RNNs that are fed by a static input x and
settle to a steady state. Training convergent RNNs consists in adjusting the weights
until the steady state of output neurons coincides with a target y. Convergent RNNs
can also be trained with the more conventional Backpropagation Through Time
(BPTT) algorithm. In its original formulation EP was described in the case of
real-time neuronal dynamics, which is computationally costly. In this work, we
introduce a discrete-time version of EP with simplified equations and with reduced
simulation time, bringing EP closer to practical machine learning tasks. We first
prove theoretically, as well as numerically that the neural and weight updates of EP,
computed by forward-time dynamics, are step-by-step equal to the ones obtained by
BPTT, with gradients computed backward in time. The equality is strict when the
transition function of the dynamics derives from a primitive function and the steady
state is maintained long enough. We then show for more standard discrete-time
neural network dynamics that the same property is approximately respected and
we subsequently demonstrate training with EP with equivalent performance to
BPTT. In particular, we define the first convolutional architecture trained with EP
achieving ∼ 1% test error on MNIST, which is the lowest error reported with EP.
These results can guide the development of deep neural networks trained with EP.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower oral" id="maincard_15844">
            <div class='pull-right maincardHeader maincardType'>Oral</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall C + B3  </div>
            <div class="maincardBody">Uniform convergence may be unable to explain generalization in deep learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15843">
                    Track 1 Session 1</a>
                </div>
            
            <div class="maincardFooter">Vaishnavh Nagarajan &middot; J. Zico Kolter</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6214" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.cmu.edu/~vaishnan/talks/neurips19_uc_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.cmu.edu/~vaishnan/talks/neurips19_uc_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=o3GfnEjTdIQ" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Aimed at explaining the surprisingly good generalization behavior of overparameterized deep networks, recent works have developed a variety of generalization bounds for deep learning,  all  based on the fundamental learning-theoretic technique of uniform convergence. While
it is well-known that many of these existing bounds are numerically large, through numerous experiments, we bring to light a more concerning aspect of these bounds: 
in practice,  these bounds can {\em increase} with the training dataset size. Guided by our observations,
we then present examples of overparameterized linear classifiers and neural networks trained by  gradient descent (GD) where uniform convergence provably cannot ``explain generalization&#x27;&#x27; -- even if we take into account the implicit bias of GD {\em to the fullest extent possible}. More precisely, even if we consider only the set of classifiers output by GD, which have test errors less than some small $\epsilon$ in our settings, we show that applying (two-sided) uniform convergence on this set of classifiers will yield only a vacuous generalization guarantee larger than $1-\epsilon$. Through these findings,
we cast doubt on the power of uniform convergence-based generalization bounds to provide a complete picture of why overparameterized deep networks generalize well. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15733">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Ballroom C  </div>
            <div class="maincardBody">Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15731">
                    Track 4 Session 1</a>
                </div>
            
            <div class="maincardFooter">Aaron Voelker &middot; Ivana Kajić &middot; Chris Eliasmith</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-9024" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15733.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://docs.google.com/document/d/1uarYP9YqcKx2Qh7sHJJhrY87C-mVZbNTAVqRKVPDXmI/edit" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://docs.google.com/document/d/1uarYP9YqcKx2Qh7sHJJhrY87C-mVZbNTAVqRKVPDXmI/edit" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We propose a novel memory cell for recurrent neural networks that dynamically maintains information across long windows of time using relatively few resources. The Legendre Memory Unit~(LMU) is mathematically derived to orthogonalize its continuous-time history -- doing so by solving $d$ coupled ordinary differential equations~(ODEs), whose phase space linearly maps onto sliding windows of time via the Legendre polynomials up to degree $d - 1$. Backpropagation across LMUs outperforms equivalently-sized LSTMs on a chaotic time-series prediction task, improves memory capacity by two orders of magnitude, and significantly reduces training and inference times. LMUs can efficiently handle temporal dependencies spanning $100\text{,}000$ time-steps, converge rapidly, and use few internal state-variables to learn complex functions spanning long windows of time -- exceeding state-of-the-art performance among RNNs on permuted sequential MNIST. These results are due to the network&#x27;s disposition to learn scale-invariant features independently of step size. Backpropagation through the ODE solver allows each layer to adapt its internal time-step, enabling the network to learn task-relevant time-scales. We demonstrate that LMU memory cells can be implemented using $m$ recurrently-connected Poisson spiking neurons, $\mathcal{O}( m )$ time and memory, with error scaling as $\mathcal{O}( d / \sqrt{m} )$. We discuss implementations of LMUs on analog and digital neuromorphic hardware.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15734">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Ballroom C  </div>
            <div class="maincardBody">Point-Voxel CNN for Efficient 3D Deep Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15731">
                    Track 4 Session 1</a>
                </div>
            
            <div class="maincardFooter">Zhijian Liu &middot; Haotian Tang &middot; Yujun Lin &middot; Song Han</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-539" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15734.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://pvcnn.mit.edu" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We present Point-Voxel CNN (PVCNN) for efficient, fast 3D deep learning. Previous work processes 3D data using either voxel-based or point-based NN models. However, both approaches are computationally inefficient. The computation cost and memory footprints of the voxel-based models grow cubically with the input resolution, making it memory-prohibitive to scale up the resolution. As for point-based networks, up to 80% of the time is wasted on dealing with the sparse data which have rather poor memory locality, not on the actual feature extraction. In this paper, we propose PVCNN that represents the 3D input data in points to reduce the memory consumption, while performing the convolutions in voxels to reduce the irregular, sparse data access and improve the locality. Our PVCNN model is both memory and computation efficient. Evaluated on semantic and part segmentation datasets, it achieves much higher accuracy than the voxel-based baseline with 10× GPU memory reduction; it also outperforms the state-of-the-art point-based models with 7× measured speedup on average. Remarkably, the narrower version of PVCNN achieves 2× speedup over PointNet (an extremely efficient model) on part and scene segmentation benchmarks with much higher accuracy. We validate the general effectiveness of PVCNN on 3D object detection: by replacing the primitives in Frustrum PointNet with PVConv, it outperforms Frustrum PointNet++ by 2.4% mAP on average with 1.5× measured speedup and GPU memory reduction.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15678">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Ballroom A + B  </div>
            <div class="maincardBody">Identification of Conditional Causal Effects under Markov Equivalence</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15675">
                    Track 3 Session 1</a>
                </div>
            
            <div class="maincardFooter">Amin Jaber &middot; Jiji Zhang &middot; Elias Bareinboim</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6138" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15678.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/s/qucyzi28s7ycka9/NeurIPS19-CID.m4v?dl=0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Causal identification is the problem of deciding whether a post-interventional distribution is computable from a combination of qualitative knowledge about the data-generating process, which is encoded in a causal diagram, and an observational distribution. A generalization of this problem restricts the qualitative knowledge to a class of Markov equivalent causal diagrams, which, unlike a single, fully-specified causal diagram, can be inferred from the observational distribution.
Recent work by (Jaber et al., 2019a) devised a complete algorithm for the identification of unconditional causal effects given a Markov equivalence class of causal diagrams. However, there are identifiable conditional causal effects that cannot be handled by that algorithm. In this work, we derive an algorithm to identify conditional effects, which are particularly useful for evaluating conditional plans or policies.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15791">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall A  </div>
            <div class="maincardBody">Adversarial Examples Are Not Bugs, They Are Features</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15787">
                    Track 2 Session 1</a>
                </div>
            
            <div class="maincardFooter">Andrew Ilyas &middot; Shibani Santurkar &middot; Dimitris Tsipras &middot; Logan Engstrom &middot; Brandon Tran &middot; Aleksander Madry</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-71" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://people.csail.mit.edu/tsipras/bugs_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15791.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/-vhUWSHOqIM" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features (derived from patterns in the data distribution) that are highly predictive, yet brittle and (thus) incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a {\em misalignment} between the (human-specified) notion of robustness and the inherent geometry of the data.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15792">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall A  </div>
            <div class="maincardBody">Empirically Measuring Concentration: Fundamental Limits on Intrinsic Robustness</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15787">
                    Track 2 Session 1</a>
                </div>
            
            <div class="maincardFooter">Saeed Mahloujifar &middot; Xiao Zhang &middot; Mohammad Mahmoody &middot; David Evans</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2823" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1_bQ0AFR7_-GVDpnDWNUirBW3tqGeGJHF" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15792.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1UIzRxpAT2fWsreTcMM1YGWRV0EyCaY50" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1z-97tgTqB5dH3WzQcE6kBOVJHizo5z7A" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Many recent works have shown that adversarial examples that fool classifiers can be found by minimally perturbing a normal input. Recent theoretical results, starting with Gilmer et al. (2018b), show that if the inputs are drawn from a concentrated metric probability space, then adversarial examples with small perturbation are inevitable. A concentrated space has the property that any subset with Ω(1) (e.g.,1/100) measure, according to the imposed distribution, has small distance to almost all (e.g.,  99/100) of the points in the space. It is not clear,  however,  whether these theoretical results apply to actual distributions such as images. This paper presents a method for empirically measuring and bounding the concentration of a concrete dataset which is proven to converge to the actual concentration. We use it to empirically estimate the intrinsic robustness to and L_2 and L_infinity perturbations of several image classification benchmarks. Code for our experiments is available at https://github.com/xiaozhanguva/Measure-Concentration.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14027">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #1</div>
            <div class="maincardBody">A Game Theoretic Approach to Class-wise Selective Rationalization</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15493">
                    Algorithms -- Adversarial Learning</a>
                </div>
            
            <div class="maincardFooter">Shiyu Chang &middot; Yang Zhang &middot; Mo Yu &middot; Tommi Jaakkola</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5315" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/s/4jebt3cv22noxzt/poster_final.pdf?dl=0" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/s/5oimaavehk3veuv/CAR_slides_final.pdf?dl=0" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/s/tnr5emcp5a4wvig/video_final.mp4?dl=0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Selection of input features such as relevant pieces of text has become a common technique of highlighting how complex neural predictors operate. The selection can be optimized post-hoc for trained models or incorporated directly into the method itself (self-explaining). However, an overall selection does not properly capture the multi-faceted nature of useful rationales such as pros and cons for decisions. To this end, we propose a new game theoretic approach to class-dependent rationalization, where the method is specifically trained to highlight evidence supporting alternative conclusions. Each class involves three players set up competitively to find evidence for factual and counterfactual scenarios. We show theoretically in a simplified scenario how the game drives the solution towards meaningful class-dependent rationales. We evaluate the method in single- and multi-aspect sentiment classification tasks and demonstrate that the proposed method is able to identify both factual (justifying the ground truth label) and counterfactual (countering the ground truth label) rationales consistent with human rationalization.  The code for our method is publicly available. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13512">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #5</div>
            <div class="maincardBody">Adversarial training for free!</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15493">
                    Algorithms -- Adversarial Learning</a>
                </div>
            
            <div class="maincardFooter">Ali Shafahi &middot; Mahyar Najibi &middot; Mohammad Amin Ghiasi &middot; Zheng Xu &middot; John Dickerson &middot; Christoph Studer &middot; Larry Davis &middot; Gavin Taylor &middot; Tom Goldstein</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1853" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.cs.umd.edu/~ashafahi/free_training/Free_train_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.cs.umd.edu/~ashafahi/free_training/Free_train_slide.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/v8U9mM1Vwv0?t=285" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Adversarial training, in which a network is trained on adversarial examples, is one of the few defenses against adversarial attacks that withstands strong attacks. Unfortunately, the high cost of generating strong adversarial examples makes standard adversarial training impractical on large-scale problems like ImageNet. We present an algorithm that eliminates the overhead cost of generating adversarial examples by recycling the gradient information computed when updating model parameters. Our &quot;free&quot; adversarial training algorithm achieves comparable robustness to PGD adversarial training on the CIFAR-10 and CIFAR-100 datasets at negligible additional cost compared to natural training, and can be 7 to 30 times faster than other strong adversarial training methods. Using a single workstation with 4 P100 GPUs and 2 days of runtime, we can train a robust model for the large-scale ImageNet classification task that maintains 40% accuracy against PGD attacks.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14528">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #10</div>
            <div class="maincardBody">Empirically Measuring Concentration: Fundamental Limits on Intrinsic Robustness</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15493">
                    Algorithms -- Adversarial Learning</a>
                </div>
            
            <div class="maincardFooter">Saeed Mahloujifar &middot; Xiao Zhang &middot; Mohammad Mahmoody &middot; David Evans</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2823" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1_bQ0AFR7_-GVDpnDWNUirBW3tqGeGJHF" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1UIzRxpAT2fWsreTcMM1YGWRV0EyCaY50" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1z-97tgTqB5dH3WzQcE6kBOVJHizo5z7A" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Many recent works have shown that adversarial examples that fool classifiers can be found by minimally perturbing a normal input. Recent theoretical results, starting with Gilmer et al. (2018b), show that if the inputs are drawn from a concentrated metric probability space, then adversarial examples with small perturbation are inevitable. A concentrated space has the property that any subset with Ω(1) (e.g.,1/100) measure, according to the imposed distribution, has small distance to almost all (e.g.,  99/100) of the points in the space. It is not clear,  however,  whether these theoretical results apply to actual distributions such as images. This paper presents a method for empirically measuring and bounding the concentration of a concrete dataset which is proven to converge to the actual concentration. We use it to empirically estimate the intrinsic robustness to and L_2 and L_infinity perturbations of several image classification benchmarks. Code for our experiments is available at https://github.com/xiaozhanguva/Measure-Concentration.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13386">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #13</div>
            <div class="maincardBody">Multi-marginal Wasserstein GAN</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15493">
                    Algorithms -- Adversarial Learning</a>
                </div>
            
            <div class="maincardFooter">Jiezhang Cao &middot; Langyuan Mo &middot; Yifan Zhang &middot; Kui Jia &middot; Chunhua Shen &middot; Mingkui Tan</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1034" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://caojiezhang.com/poster/NeurIPS2019_MWGAN_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://caojiezhang.com/slides/NeurIPS2019_MWGAN_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://caojiezhang.com/video/NeurIPS2019_MWGAN_video.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Multiple marginal matching problem aims at learning mappings to match a source domain to multiple target domains and it has attracted great attention in many applications, such as multi-domain image translation. However, addressing this problem has two critical challenges: (i) Measuring the multi-marginal distance among different domains is very intractable; (ii) It is very difficult to exploit cross-domain correlations to match the target domain distributions. In this paper, we propose a novel Multi-marginal Wasserstein GAN (MWGAN) to minimize Wasserstein distance among domains. Specifically, with the help of multi-marginal optimal transport theory, we develop a new adversarial objective function with inner- and inter-domain constraints to exploit cross-domain correlations. Moreover, we theoretically analyze the generalization performance of MWGAN, and empirically evaluate it on the balanced and imbalanced translation tasks. Extensive experiments on toy and real-world datasets demonstrate the effectiveness of MWGAN.  </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13972">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #30</div>
            <div class="maincardBody">Correlation clustering with local objectives</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15495">
                    Algorithms -- Clustering</a>
                </div>
            
            <div class="maincardFooter">Sanchit Kalhan &middot; Konstantin Makarychev &middot; Timothy Zhou</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4985" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=0s1LF5qL2Do&feature=youtu.be" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Correlation Clustering is a powerful graph partitioning model that aims to cluster items based on the notion of similarity between items. An instance of the Correlation Clustering problem consists of a graph G (not necessarily complete) whose edges are labeled by a binary classifier as
similar and dissimilar. Classically, we are tasked with producing a clustering that minimizes the number of disagreements: an edge is in disagreement if it is a similar edge and is present across clusters or if it is a dissimilar edge and is present within a cluster. Define the disagreements vector to be an n dimensional vector indexed by the vertices, where the v-th index is the number of disagreements at vertex v.

Recently, Puleo and Milenkovic (ICML &#x27;16) initiated the study of the Correlation Clustering framework in which the objectives were more general functions of the disagreements vector. In this paper, we study algorithms for minimizing \ell_q norms (q &gt;= 1) of the disagreements vector for both arbitrary and complete graphs. We present the first known algorithm for minimizing the \ell_q norm of the disagreements vector on arbitrary graphs and also provide an improved algorithm for minimizing the \ell_q norm (q &gt;= 1) of the disagreements vector on complete graphs. We also study an alternate cluster-wise local objective introduced by Ahmadi, Khuller and Saha (IPCO &#x27;19), which aims to minimize the maximum number of disagreements associated with a cluster. We present an improved (2 + \eps) approximation algorithm for this objective.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14056">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #50</div>
            <div class="maincardBody">On Fenchel Mini-Max Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15497">
                    Algorithms -- Density Estimation</a>
                </div>
            
            <div class="maincardFooter">Chenyang Tao &middot; Liqun Chen &middot; Shuyang Dai &middot; Junya Chen &middot; Ke Bai &middot; Dong Wang &middot; Jianfeng Feng &middot; Wenlian Lu &middot; Georgiy Bobashev &middot; Lawrence Carin</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5511" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/chenyang-tao/FML/blob/master/poster/fml-poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/chenyang-tao/FML/blob/master/slides/fml-slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/chenyang-tao/FML/tree/master/video" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Inference, estimation, sampling and likelihood evaluation are four primary goals of probabilistic modeling. Practical considerations often force modeling approaches to make compromises between these objectives. We present a novel probabilistic learning framework, called Fenchel Mini-Max Learning (FML), that accommodates all four desiderata in a flexible and scalable manner. Our derivation is rooted in classical maximum likelihood estimation, and it overcomes a longstanding challenge that prevents unbiased estimation of unnormalized statistical models. By reformulating MLE as a mini-max game, FML enjoys an unbiased training objective that (i) does not explicitly involve the intractable normalizing constant and (ii) is directly amendable to stochastic gradient descent optimization. To demonstrate the utility of the proposed approach, we consider learning unnormalized statistical models, nonparametric density estimation and training generative models, with encouraging empirical results presented. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13868">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #62</div>
            <div class="maincardBody">Solving Interpretable Kernel Dimensionality Reduction</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15499">
                    Algorithms -- Kernel Methods</a>
                </div>
            
            <div class="maincardFooter">Chieh Wu &middot; Jared Miller &middot; Yale Chang &middot; Mario Sznaier &middot; Jennifer Dy</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4340" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1eU8JLJxy7EmGwlEcFqbIkeUoClPqBOHC/view?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://docs.google.com/presentation/d/1BUHKyj79hG4QdRJlmcWHX-JDE_eBu537nbYFlJkofSo/edit?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/q1ETeX3HvPY" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Kernel dimensionality reduction (KDR) algorithms find a low dimensional representation of the original data by optimizing kernel dependency measures that are capable of capturing nonlinear relationships. The standard strategy is to first map the data into a high dimensional feature space using kernels prior to a projection onto a low dimensional space. While KDR methods can be easily solved by keeping the most dominant eigenvectors of the kernel matrix, its features are no longer easy to interpret.  Alternatively, Interpretable KDR (IKDR) is different in that it projects onto a subspace \textit{before} the kernel feature mapping, therefore, the projection matrix can indicate how the original features linearly combine to form the new features. Unfortunately, the IKDR objective requires a non-convex manifold optimization that is difficult to solve and can no longer be solved by eigendecomposition. Recently, an efficient iterative spectral (eigendecomposition) method (ISM) has been proposed for this objective in the context of alternative clustering. However, ISM only provides theoretical guarantees for the Gaussian kernel. This greatly constrains ISM&#x27;s usage since any kernel method using ISM is now limited to a single kernel. This work extends the theoretical guarantees of ISM to an entire family of kernels, thereby empowering ISM to solve any kernel method of the same objective. In identifying this family, we prove that each kernel within the family has a surrogate $\Phi$ matrix and the optimal projection is formed by its most dominant eigenvectors. With this extension, we establish how a wide range of IKDR applications across different learning paradigms can be solved by ISM. To support reproducible results, the source code is made publicly available on  \url{https://github.com/ANONYMIZED}.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13551">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #67</div>
            <div class="maincardBody">Exact Rate-Distortion in Autoencoders via Echo Noise</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15501">
                    Algorithms -- Representation Learning</a>
                </div>
            
            <div class="maincardFooter">Rob Brekelmans &middot; Daniel Moyer &middot; Aram Galstyan &middot; Greg Ver Steeg</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2137" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1TddQTjsvJrpXOU_pSvRaTlyPbuJJM-iP/view" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.isi.edu/sites/default/files/users/gregv/echo_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://bit.ly/2Wdm6St" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Compression is at the heart of effective representation learning. However, lossy compression is typically achieved through simple parametric models like Gaussian noise to preserve analytic tractability, and the limitations this imposes on learning are largely unexplored.  Further, the Gaussian prior assumptions in models such as variational autoencoders (VAEs) provide only an upper bound on the compression rate in general.  We introduce a new noise channel, Echo noise, that admits a simple, exact expression for mutual information for arbitrary input distributions.  The noise is constructed in a data-driven fashion that does not require restrictive distributional assumptions.  With its complex encoding mechanism and exact rate regularization, Echo leads to improved bounds on log-likelihood and dominates beta-VAEs across the achievable range of rate-distortion trade-offs. Further, we show that Echo noise can outperform flow-based methods without the need to train additional distributional transformations.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14258">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #81</div>
            <div class="maincardBody">Communication-efficient Distributed SGD with Sketching</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15503">
                    Applications -- Communication- or Memory-Bounded Learning</a>
                </div>
            
            <div class="maincardFooter">Nikita Ivkin &middot; Daniel Rothchild &middot; Enayat Ullah &middot; Vladimir braverman &middot; Ion Stoica &middot; Raman Arora</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-7205" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://enayatullah.github.io/sketchedsgd/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://enayatullah.github.io/sketchedsgd/slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://enayatullah.github.io/sketchedsgd/video" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Large-scale distributed training of neural networks is often limited by network bandwidth, wherein the communication time overwhelms the local computation time. Motivated by the success of sketching methods in sub-linear/streaming algorithms, we introduce Sketched-SGD, an algorithm for carrying out distributed SGD by communicating sketches instead of full gradients. We show that \ssgd has favorable convergence rates on several classes of functions. When considering all communication -- both of gradients and of updated model weights -- Sketched-SGD reduces the amount of communication required compared to other gradient compression methods from $\mathcal{O}(d)$ or $\mathcal{O}(W)$ to $\mathcal{O}(\log d)$, where $d$ is the number of model parameters and $W$ is the number of workers participating in training. We run experiments on a transformer model, an LSTM, and a residual network, demonstrating up to a 40x reduction in total communication cost with no loss in final model performance. We also show experimentally that Sketched-SGD scales to at least 256 workers without increasing communication cost or degrading model performance.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14481">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #85</div>
            <div class="maincardBody">Adversarial Examples Are Not Bugs, They Are Features</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15506">
                    Applications -- Privacy, Anonymity, and Security</a>
                </div>
            
            <div class="maincardFooter">Andrew Ilyas &middot; Shibani Santurkar &middot; Dimitris Tsipras &middot; Logan Engstrom &middot; Brandon Tran &middot; Aleksander Madry</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-71" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://people.csail.mit.edu/tsipras/bugs_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/-vhUWSHOqIM" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features (derived from patterns in the data distribution) that are highly predictive, yet brittle and (thus) incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a {\em misalignment} between the (human-specified) notion of robustness and the inherent geometry of the data.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13395">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #103</div>
            <div class="maincardBody">Neural networks grown and self-organized by noise</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15509">
                    Deep Learning -- Biologically Plausible Deep Networks</a>
                </div>
            
            <div class="maincardFooter">Guruprasad Raghavan &middot; Matt Thomson</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1100" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://caltech.box.com/s/9tqfhrgo3cicoi5ue9z7qyhlsjfefdka" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Living neural networks emerge through a process of growth and self-organization that begins with a single cell and results in a brain, an organized and functional computational device. Artificial neural networks, however, rely on human-designed, hand-programmed architectures for their remarkable performance. Can we develop artificial computational devices that can grow and self-organize without human intervention? In this paper, we propose a biologically inspired developmental algorithm that can ‘grow’ a functional, layered neural network from a single initial cell. The algorithm organizes inter-layer connections to construct retinotopic pooling layers. Our approach is inspired by the mechanisms employed by the early visual system to wire the retina to the lateral geniculate nucleus (LGN), days before animals open their eyes.  The key ingredients for robust self-organization are an emergent spontaneous spatiotemporal activity wave in the first layer and a local learning rule in the second layer that ‘learns’ the underlying activity pattern in the first layer.  The algorithm is adaptable to a wide-range of input-layer geometries, robust to malfunctioning units in the first layer, and so can be used to successfully grow and self-organize pooling architectures of different pool-sizes and shapes. The algorithm provides a primitive procedure for constructing layered neural networks through growth and self-organization. We also demonstrate that networks grown from a single unit perform as well as hand-crafted networks on MNIST. Broadly, our work shows that biologically inspired developmental algorithms can be applied to autonomously grow functional `brains&#x27; in-silico.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13225">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #106</div>
            <div class="maincardBody">Updates of Equilibrium Prop Match Gradients of Backprop Through Time in an RNN with Static Input</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15509">
                    Deep Learning -- Biologically Plausible Deep Networks</a>
                </div>
            
            <div class="maincardFooter">Maxence Ernoult &middot; Julie Grollier &middot; Damien Querlioz &middot; Yoshua Bengio &middot; Benjamin Scellier</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-3824" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=Xb5sM0NRy_0&feature=youtu.be" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Equilibrium Propagation (EP) is a biologically inspired learning algorithm for
convergent recurrent neural networks, i.e. RNNs that are fed by a static input x and
settle to a steady state. Training convergent RNNs consists in adjusting the weights
until the steady state of output neurons coincides with a target y. Convergent RNNs
can also be trained with the more conventional Backpropagation Through Time
(BPTT) algorithm. In its original formulation EP was described in the case of
real-time neuronal dynamics, which is computationally costly. In this work, we
introduce a discrete-time version of EP with simplified equations and with reduced
simulation time, bringing EP closer to practical machine learning tasks. We first
prove theoretically, as well as numerically that the neural and weight updates of EP,
computed by forward-time dynamics, are step-by-step equal to the ones obtained by
BPTT, with gradients computed backward in time. The equality is strict when the
transition function of the dynamics derives from a primitive function and the steady
state is maintained long enough. We then show for more standard discrete-time
neural network dynamics that the same property is approximately respected and
we subsequently demonstrate training with EP with equivalent performance to
BPTT. In particular, we define the first convolutional architecture trained with EP
achieving ∼ 1% test error on MNIST, which is the lowest error reported with EP.
These results can guide the development of deep neural networks trained with EP.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14488">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #112</div>
            <div class="maincardBody">Point-Voxel CNN for Efficient 3D Deep Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15511">
                    Deep Learning -- Efficient Inference Methods</a>
                </div>
            
            <div class="maincardFooter">Zhijian Liu &middot; Haotian Tang &middot; Yujun Lin &middot; Song Han</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-539" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://pvcnn.mit.edu" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We present Point-Voxel CNN (PVCNN) for efficient, fast 3D deep learning. Previous work processes 3D data using either voxel-based or point-based NN models. However, both approaches are computationally inefficient. The computation cost and memory footprints of the voxel-based models grow cubically with the input resolution, making it memory-prohibitive to scale up the resolution. As for point-based networks, up to 80% of the time is wasted on dealing with the sparse data which have rather poor memory locality, not on the actual feature extraction. In this paper, we propose PVCNN that represents the 3D input data in points to reduce the memory consumption, while performing the convolutions in voxels to reduce the irregular, sparse data access and improve the locality. Our PVCNN model is both memory and computation efficient. Evaluated on semantic and part segmentation datasets, it achieves a much higher accuracy than the voxel-based baseline with 10x GPU memory reduction; it also outperforms the state-of-the-art point-based models with 7x measured speedup on average. Remarkably, the narrower version of PVCNN achieves 2x speedup over PointNet (an extremely efficient model) on part and scene segmentation benchmarks with much higher accuracy. We validate the general effectiveness of PVCNN on 3D object detection: by replacing the primitives in Frustrum PointNet with PVConv, it outperforms Frustrum PointNet++ by up to 2.4% mAP with 1.8x measured speedup and 1.4x GPU memory reduction.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13349">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #116</div>
            <div class="maincardBody">Model Compression with Adversarial Robustness: A Unified Optimization Framework</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15511">
                    Deep Learning -- Efficient Inference Methods</a>
                </div>
            
            <div class="maincardFooter">Shupeng Gui &middot; Haotao Wang &middot; Haichuan Yang &middot; Chen Yu &middot; Zhangyang Wang &middot; Ji Liu</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-760" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/shupenggui/ATMC/blob/master/materials/ATMC_NeurIPS19_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/shupenggui/ATMC/blob/master/materials/ATMC_full.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/shupenggui/ATMC/blob/master/materials/video.link" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Deep model compression has been extensively studied, and state-of-the-art methods can now achieve high compression ratios with minimal accuracy loss. This paper studies model compression through a different lens: could we compress models without hurting their robustness to adversarial attacks, in addition to maintaining accuracy? Previous literature suggested that the goals of robustness and compactness might sometimes contradict. We propose a novel Adversarially Trained Model Compression (ATMC) framework. ATMC constructs a unified constrained optimization formulation, where existing compression means (pruning, factorization, quantization) are all integrated into the constraints. An efficient algorithm is then developed. An extensive group of experiments are presented, demonstrating that ATMC obtains remarkably more favorable trade-off among model size, accuracy and robustness, over currently available alternatives in various settings. The codes are publicly available at: https://github.com/shupenggui/ATMC.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13570">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #119</div>
            <div class="maincardBody">A Prior of a Googol Gaussians: a Tensor Ring Induced Prior for Generative Models</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15512">
                    Deep Learning -- Generative Models</a>
                </div>
            
            <div class="maincardFooter">Maxim Kuznetsov &middot; Daniil Polykovskiy &middot; Dmitry Vetrov &middot; Alex Zhebrak</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2260" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1fDc9_BhTKT3gZAyCtuafL4tfuZivusia/view" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Generative models produce realistic objects in many domains, including text, image, video, and audio synthesis. Most popular models—Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs)—usually employ a standard Gaussian distribution as a prior. Previous works show that the richer family of prior distributions may help to avoid the mode collapse problem in GANs and to improve the evidence lower bound in VAEs. We propose a new family of prior distributions—Tensor Ring Induced Prior (TRIP)—that packs an exponential number of Gaussians into a high-dimensional lattice with a relatively small number of parameters. We show that these priors improve Fréchet Inception Distance for GANs and Evidence Lower Bound for VAEs. We also study generative models with TRIP in the conditional generation setup with missing conditions. Altogether, we propose a novel plug-and-play framework for generative models that can be utilized in any GAN and VAE-like architectures.
</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13308">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #138</div>
            <div class="maincardBody">Differentiable Cloth Simulation for Inverse Problems</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15514">
                    Deep Learning -- Optimization for Deep Networks</a>
                </div>
            
            <div class="maincardFooter">Junbang Liang &middot; Ming Lin &middot; Vladlen Koltun</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-394" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/ipIM-c4lCJ0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We propose a differentiable cloth simulator that can be embedded as a layer in deep neural networks.  This approach provides an effective, robust framework for modeling cloth dynamics, self-collisions, and contacts. Due to the high dimensionality of the dynamical system in modeling cloth, traditional gradient computation for collision response can become impractical. To address this problem, we propose to compute the gradient directly using QR decomposition of a much smaller matrix. Experimental results indicate that our method can speed up backpropagation by two orders of magnitude. We demonstrate the presented approach on a number of inverse problems, including parameter estimation and motion control for cloth.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14257">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #146</div>
            <div class="maincardBody">A Simple Baseline for Bayesian Uncertainty in Deep Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15515">
                    Deep Learning -- Predictive Models</a>
                </div>
            
            <div class="maincardFooter">Wesley Maddox &middot; Pavel Izmailov &middot; Timur Garipov &middot; Dmitry Vetrov &middot; Andrew Gordon Wilson</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-7203" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/wjmaddox/swa_gaussian/blob/master/slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://izmailovpavel.github.io/swag_video" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We propose SWA-Gaussian (SWAG), a simple,  scalable,  and general purpose approach for uncertainty representation and calibration in deep learning. Stochastic Weight Averaging (SWA), which computes the first moment of stochastic gradient descent (SGD) iterates with a modified learning rate schedule, has recently been shown to improve generalization in deep learning. With SWAG, we fit a Gaussian using the SWA solution as the first moment and a low rank plus diagonal covariance also derived from the SGD iterates, forming an approximate posterior distribution over neural network weights; we then sample from this Gaussian distribution to perform Bayesian model averaging. We empirically find that SWAG approximates the shape of the true posterior, in accordance with results describing the stationary distribution of SGD iterates. Moreover, we demonstrate that SWAG performs well on a wide variety of tasks, including out of sample detection, calibration,  and transfer learning,  in comparison to many popular alternatives including variational inference, MC dropout, KFAC Laplace, and temperature scaling.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14639">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #154</div>
            <div class="maincardBody">Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15516">
                    Deep Learning -- Recurrent Networks</a>
                </div>
            
            <div class="maincardFooter">Aaron Voelker &middot; Ivana Kajić &middot; Chris Eliasmith</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-9024" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://docs.google.com/document/d/1uarYP9YqcKx2Qh7sHJJhrY87C-mVZbNTAVqRKVPDXmI/edit" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://docs.google.com/document/d/1uarYP9YqcKx2Qh7sHJJhrY87C-mVZbNTAVqRKVPDXmI/edit" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We propose a novel memory cell for recurrent neural networks that dynamically maintains information across long windows of time using relatively few resources. The Legendre Memory Unit~(LMU) is mathematically derived to orthogonalize its continuous-time history -- doing so by solving $d$ coupled ordinary differential equations~(ODEs), whose phase space linearly maps onto sliding windows of time via the Legendre polynomials up to degree $d - 1$. Backpropagation across LMUs outperforms equivalently-sized LSTMs on a chaotic time-series prediction task, improves memory capacity by two orders of magnitude, and significantly reduces training and inference times. LMUs can efficiently handle temporal dependencies spanning $100\text{,}000$ time-steps, converge rapidly, and use few internal state-variables to learn complex functions spanning long windows of time -- exceeding state-of-the-art performance among RNNs on permuted sequential MNIST. These results are due to the network&#x27;s disposition to learn scale-invariant features independently of step size. Backpropagation through the ODE solver allows each layer to adapt its internal time-step, enabling the network to learn task-relevant time-scales. We demonstrate that LMU memory cells can be implemented using $m$ recurrently-connected Poisson spiking neurons, $\mathcal{O}( m )$ time and memory, with error scaling as $\mathcal{O}( d / \sqrt{m} )$. We discuss implementations of LMUs on analog and digital neuromorphic hardware.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14457">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #156</div>
            <div class="maincardBody">Reverse engineering recurrent networks for sentiment classification reveals line attractor dynamics</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15516">
                    Deep Learning -- Recurrent Networks</a>
                </div>
            
            <div class="maincardFooter">Niru Maheswaranathan &middot; Alex Williams &middot; Matthew Golub &middot; Surya Ganguli &middot; David Sussillo</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-9119" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=17m1_URju-fIRXzWOVLQyESsyYYBUfk1f" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1J-YIS9aSMNz1WX1ifBK4KlZaWhH32vXp" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Recurrent neural networks (RNNs) are a widely used tool for modeling sequential data, yet they are often treated as inscrutable black boxes. Given a trained recurrent network, we would like to reverse engineer it--to obtain a quantitative, interpretable description of how it solves a particular task. Even for simple tasks, a detailed understanding of how recurrent networks work, or a prescription for how to develop such an understanding, remains elusive. In this work, we use tools from dynamical systems analysis to reverse engineer recurrent networks trained to perform sentiment classification, a foundational natural language processing task. Given a trained network, we find fixed points of the recurrent dynamics and linearize the nonlinear system around these fixed points. Despite their theoretical capacity to implement complex, high-dimensional computations, we find that trained networks converge to highly interpretable, low-dimensional representations. In particular, the topological structure of the fixed points and corresponding linearized dynamics reveal an approximate line attractor within the RNN, which we can use to quantitatively understand how the RNN solves the sentiment analysis task. Finally, we find this mechanism present across RNN architectures (including LSTMs, GRUs, and vanilla RNNs) trained on multiple datasets, suggesting that our findings are not unique to a particular architecture or dataset. Overall, these results demonstrate that surprisingly universal and human interpretable computations can arise across a range of recurrent networks.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14293">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #165</div>
            <div class="maincardBody">Explanations can be manipulated and geometry is to blame</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15517">
                    Deep Learning -- Visualization or Exposition Techniques for Deep Networks</a>
                </div>
            
            <div class="maincardFooter">Ann-Kathrin Dombrowski &middot; Maximillian Alber &middot; Christopher Anders &middot; Marcel Ackermann &middot; Klaus-Robert Müller &middot; Pan Kessel</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-7516" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/playlist?list=PLPpfpYGbmCsoRah0LdcHBcr1qIcig28AK" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Explanation methods aim to make neural networks more trustworthy and interpretable. In this paper, we demonstrate a property of explanation methods which is disconcerting for both of these purposes. Namely, we show that explanations can be manipulated arbitrarily by applying visually hardly perceptible perturbations to the input that keep the network&#x27;s output approximately constant. We establish theoretically that this phenomenon can be related to certain geometrical properties of neural networks. This allows us to derive an upper bound on the susceptibility of explanations to manipulations. Based on this result, we propose effective mechanisms to enhance the robustness of explanations.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13476">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #166</div>
            <div class="maincardBody">Fooling Neural Network Interpretations via Adversarial Model Manipulation</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15517">
                    Deep Learning -- Visualization or Exposition Techniques for Deep Networks</a>
                </div>
            
            <div class="maincardFooter">Juyeon Heo &middot; Sunghwan Joo &middot; Taesup Moon</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1687" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/rmrisforbidden/Fooling_Neural_Network-Interpretations/blob/master/Materials/Poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/rmrisforbidden/Fooling_Neural_Network-Interpretations/blob/master/Materials/PPT.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/rmrisforbidden/Fooling_Neural_Network-Interpretations/blob/master/Materials/Video.md" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We ask whether the neural network interpretation methods can be fooled via adversarial model manipulation, which is defined as a model fine-tuning step that aims to radically alter the explanations without hurting the accuracy of the original models, e.g., VGG19, ResNet50, and DenseNet121. By incorporating the interpretation results directly in the penalty term of the objective function for fine-tuning, we show that the state-of-the-art saliency map based interpreters, e.g., LRP, Grad-CAM, and SimpleGrad, can be easily fooled with our model manipulation. We propose two types of fooling, Passive and Active, and demonstrate such foolings generalize well to the entire validation set as well as transfer to other interpretation methods. Our results are validated by both visually showing the fooled explanations and reporting quantitative metrics that measure the deviations from the original explanations.  We claim that the stability of neural network interpretation method with respect to our adversarial model manipulation is an important criterion to check for developing robust and reliable neural network interpretation method.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13391">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #173</div>
            <div class="maincardBody">Visualizing the PHATE of Neural Networks</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15517">
                    Deep Learning -- Visualization or Exposition Techniques for Deep Networks</a>
                </div>
            
            <div class="maincardFooter">Scott Gigante &middot; Adam S Charles &middot; Smita Krishnaswamy &middot; Gal Mishne</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1058" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/scottgigante/m-phate/raw/master/img/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://mishne.ucsd.edu/m-phate-video.html" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Understanding why and how certain neural networks outperform others is key to guiding future development of network architectures and optimization methods. To this end, we introduce a novel visualization algorithm that reveals the internal geometry of such networks: Multislice PHATE (M-PHATE), the first method designed explicitly to visualize how a neural network&#x27;s hidden representations of data evolve throughout the course of training. We demonstrate that our visualization provides intuitive, detailed summaries of the learning dynamics beyond simple global measures (i.e., validation loss and accuracy), without the need to access validation data. Furthermore, M-PHATE better captures both the dynamics and community structure of the hidden units as compared to visualization based on standard dimensionality reduction methods (e.g., ISOMAP, t-SNE). We demonstrate M-PHATE with two vignettes: continual learning and generalization. In the former, the M-PHATE visualizations display the mechanism of &quot;catastrophic forgetting&quot; which is a major challenge for learning in task-switching contexts. In the latter, our visualizations reveal how increased heterogeneity among hidden units correlates with improved generalization performance. An implementation of M-PHATE, along with scripts to reproduce the figures in this paper, is available at https://github.com/scottgigante/M-PHATE.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14600">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #186</div>
            <div class="maincardBody">Identification of Conditional Causal Effects under Markov Equivalence</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15519">
                    Probabilistic Methods -- Causal Inference</a>
                </div>
            
            <div class="maincardFooter">Amin Jaber &middot; Jiji Zhang &middot; Elias Bareinboim</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6138" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/s/qucyzi28s7ycka9/NeurIPS19-CID.m4v?dl=0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Causal identification is the problem of deciding whether a post-interventional distribution is computable from a combination of qualitative knowledge about the data-generating process, which is encoded in a causal diagram, and an observational distribution. A generalization of this problem restricts the qualitative knowledge to a class of Markov equivalent causal diagrams, which, unlike a single, fully-specified causal diagram, can be inferred from the observational distribution.
Recent work by (Jaber et al., 2019a) devised a complete algorithm for the identification of unconditional causal effects given a Markov equivalence class of causal diagrams. However, there are identifiable conditional causal effects that cannot be handled by that algorithm. In this work, we derive an algorithm to identify conditional effects, which are particularly useful for evaluating conditional plans or policies.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13604">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #198</div>
            <div class="maincardBody">Successor Uncertainties: Exploration and Uncertainty in Temporal Difference Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15521">
                    Reinforcement Learning and Planning -- Exploration</a>
                </div>
            
            <div class="maincardFooter">David Janz &middot; Jiri Hron &middot; Przemysław Mazur &middot; Katja Hofmann &middot; José Miguel Hernández-Lobato &middot; Sebastian Tschiatschek</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2543" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="djanz.org/successor_uncertainties/video" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Posterior sampling for reinforcement learning (PSRL) is an effective method for balancing exploration and exploitation in reinforcement learning. Randomised value functions (RVF) can be viewed as a promising approach to scaling PSRL. However, we show that most contemporary algorithms combining RVF with neural network function approximation do not possess the properties which make PSRL effective, and provably fail in sparse reward problems. Moreover, we find that propagation of uncertainty, a property of PSRL previously thought important for exploration, does not preclude this failure. We use these insights to design Successor Uncertainties (SU), a cheap and easy to implement RVF algorithm that retains key properties of PSRL. SU is highly effective on hard tabular exploration benchmarks. Furthermore, on the Atari 2600 domain, it surpasses human performance on 38 of 49 games tested (achieving a median human normalised score of 2.09), and outperforms its closest RVF competitor, Bootstrapped DQN, on 36 of those.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13962">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #205</div>
            <div class="maincardBody">Sampling Networks and Aggregate Simulation for Online POMDP Planning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15522">
                    Reinforcement Learning and Planning -- Markov Decision Processes</a>
                </div>
            
            <div class="maincardFooter">Hao(Jackson) Cui &middot; Roni Khardon</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4951" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/IcC-O1AALXE" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >The paper introduces a new algorithm for planning in partially observable Markov decision processes (POMDP) based on the idea of aggregate simulation. The algorithm uses product distributions to approximate the belief state and shows how to build a representation graph of an approximate action-value function over belief space. The graph captures the result of simulating the model in aggregate under independence assumptions, giving a symbolic representation of the value function. The algorithm supports large observation spaces using sampling networks, a representation of the process of sampling values of observations, which is integrated into the graph representation. Following previous work in MDPs this approach enables action selection in POMDPs through gradient optimization over the graph representation. This approach complements recent algorithms for POMDPs which are based on particle representations of belief states and an explicit search for action selection. Our approach enables scaling to large factored action spaces in addition to large state spaces and observation spaces. An experimental evaluation demonstrates that the algorithm provides excellent performance relative to state of the art in large POMDP problems. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13276">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #209</div>
            <div class="maincardBody">Chasing Ghosts: Instruction Following as Bayesian State Tracking</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15523">
                    Reinforcement Learning and Planning -- Navigation</a>
                </div>
            
            <div class="maincardFooter">Peter Anderson &middot; Ayush Shrivastava &middot; Devi Parikh &middot; Dhruv Batra &middot; Stefan Lee</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-175" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.panderson.me/images/vln-chasing-ghosts.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >A visually-grounded navigation instruction can be interpreted as a sequence of expected observations and actions an agent following the correct trajectory would encounter and perform. Based on this intuition, we formulate the problem of finding the goal location in Vision-and-Language Navigation (VLN) within the framework of Bayesian state tracking - learning observation and motion models conditioned on these expectable events. Together with a mapper that constructs a semantic spatial map on-the-fly during navigation, we formulate an end-to-end differentiable Bayes filter and train it to identify the goal by predicting the most likely trajectory through the map according to the instructions. The resulting navigation policy constitutes a new approach to instruction following that explicitly models a probability distribution over states, encoding strong geometric and algorithmic priors while enabling greater explainability. Our experiments show that our approach outperforms a strong LingUNet baseline when predicting the goal location on the map. On the full VLN task, i.e. navigating to the goal location, our approach achieves promising results with less reliance on navigation constraints.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13240">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #229</div>
            <div class="maincardBody">Uniform convergence may be unable to explain generalization in deep learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15527">
                    Theory -- Learning Theory</a>
                </div>
            
            <div class="maincardFooter">Vaishnavh Nagarajan &middot; J. Zico Kolter</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6214" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.cmu.edu/~vaishnan/talks/neurips19_uc_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.cmu.edu/~vaishnan/talks/neurips19_uc_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=o3GfnEjTdIQ" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Aimed at explaining the surprisingly good generalization behavior of overparameterized deep networks, recent works have developed a variety of generalization bounds for deep learning,  all based on the fundamental learning-theoretic technique of uniform convergence. While
it is well-known that many of these existing bounds are numerically large, through numerous experiments, we bring to light a more concerning aspect of these bounds: 
in practice,  these bounds can {\em increase} with the training dataset size. Guided by our observations,
we then present examples of overparameterized linear classifiers and neural networks trained by  gradient descent (GD) where uniform convergence provably cannot ``explain generalization&#x27;&#x27; -- even if we take into account the implicit bias of GD {\em to the fullest extent possible}. More precisely, even if we consider only the set of classifiers output by GD, which have test errors less than some small $\epsilon$ in our settings, we show that applying (two-sided) uniform convergence on this set of classifiers will yield only a vacuous generalization guarantee larger than $1-\epsilon$. Through these findings,
we cast doubt on the power of uniform convergence-based generalization bounds to provide a complete picture of why overparameterized deep networks generalize well. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower oral" id="maincard_15683">
            <div class='pull-right maincardHeader maincardType'>Oral</div>
            <div class="maincardHeader">{daterange} @ West Ballroom A + B  </div>
            <div class="maincardBody">Causal Confusion in Imitation Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15682">
                    Track 3 Session 2</a>
                </div>
            
            <div class="maincardFooter">Pim de Haan &middot; Dinesh Jayaraman &middot; Sergey Levine</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6250" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/causal-confusion" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/causal-confusion" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Behavioral cloning reduces policy learning to supervised learning by training a discriminative model to predict expert actions given observations. Such discriminative models are non-causal: the training procedure is unaware of the causal structure of the interaction between the expert and the environment. We point out that ignoring causality is particularly damaging because of the distributional shift in imitation learning. In particular, it leads to a counter-intuitive &quot;causal misidentification&quot; phenomenon: access to more information can yield worse performance. We investigate how this problem arises, and propose a solution to combat it through targeted interventions---either environment interaction or expert queries---to determine the correct causal model. We show that causal misidentification occurs in several benchmark control domains as well as realistic driving settings, and validate our solution against DAgger and other baselines and ablations.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15796">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall A  </div>
            <div class="maincardBody">Asymmetric Valleys: Beyond Sharp and Flat Local Minima</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15794">
                    Track 2 Session 2</a>
                </div>
            
            <div class="maincardFooter">Haowei He &middot; Gao Huang &middot; Yang Yuan</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1457" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15796.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/962086838/code-for-Asymmetric-Valley/blob/master/asymmetric_ppt.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/zWwaJ3gbv_Q" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Despite the non-convex nature of their loss functions, deep neural networks are known to generalize well when optimized with stochastic gradient descent (SGD). Recent work conjectures that SGD with proper conﬁguration is able to ﬁnd wide and ﬂat local minima, which are correlated with good generalization performance. In this paper, we observe that local minima of modern deep networks are more than being ﬂat or sharp. Instead, at a local minimum there exist many asymmetric directions such that the loss increases abruptly along one side, and slowly along the opposite side – we formally deﬁne such minima as asymmetric valleys. Under mild assumptions, we ﬁrst prove that for asymmetric valleys, a solution biased towards the ﬂat side generalizes better than the exact empirical minimizer. Then, we show that performing weight averaging along the SGD trajectory implicitly induces such biased solutions. This provides theoretical explanations for a series of intriguing phenomena observed in recent work [25, 5, 51]. Finally, extensive empirical experiments on both modern deep networks and simple 2 layer networks are conducted to validate our assumptions and analyze the intriguing properties of asymmetric valleys.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15684">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Ballroom A + B  </div>
            <div class="maincardBody">Imitation Learning from Observations by Minimizing Inverse Dynamics Disagreement</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15682">
                    Track 3 Session 2</a>
                </div>
            
            <div class="maincardFooter">Chao Yang &middot; Xiaojian Ma &middot; Wenbing Huang &middot; Fuchun Sun &middot; Huaping Liu &middot; Junzhou Huang &middot; Chuang Gan</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-98" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/neurips19-iddm/home" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15684.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/neurips19-iddm/home" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/neurips19-iddm/home" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >This paper studies Learning from Observations (LfO) for imitation learning with access to state-only demonstrations. In contrast to Learning from Demonstration (LfD) that involves both action and state supervisions, LfO is more practical in leveraging previously inapplicable resources (e.g., videos), yet more challenging due to the incomplete expert guidance. In this paper, we investigate LfO and its difference with LfD in both theoretical and practical perspectives. We first prove that the gap between LfD and LfO actually lies in the disagreement of inverse dynamics models between the imitator and expert, if following the modeling approach of GAIL. More importantly, the upper bound of this gap is revealed by a negative causal entropy which can be minimized in a model-free way. We term our method as Inverse-Dynamics-Disagreement-Minimization (IDDM) which enhances the conventional LfO method through further bridging the gap to LfD. Considerable empirical results on challenging benchmarks indicate that our method attains consistent improvements over other LfO counterparts.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15853">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall C + B3  </div>
            <div class="maincardBody">Implicit Generation and Modeling with Energy Based Models</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15850">
                    Track 1 Session 2</a>
                </div>
            
            <div class="maincardFooter">Yilun Du &middot; Igor Mordatch</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1955" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15853.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/igebm" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Energy based models (EBMs) are appealing due to their generality and simplicity in likelihood modeling, but have been traditionally difficult to train. We present techniques to scale MCMC based EBM training on continuous neural networks, and we show its success on the high-dimensional data domains of ImageNet32x32, ImageNet128x128, CIFAR-10, and robotic hand trajectories, achieving better samples than other likelihood models and nearing the performance of contemporary GAN approaches, while covering all modes of the data. We highlight some unique capabilities of implicit generation such as compositionality and corrupt image reconstruction and inpainting. Finally, we show that EBMs are useful models across a wide variety of tasks, achieving state-of-the-art out-of-distribution classification, adversarially robust classification, state-of-the-art continual online class learning, and coherent long term predicted trajectory rollouts.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15855">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall C + B3  </div>
            <div class="maincardBody">Residual Flows for Invertible Generative Modeling</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15850">
                    Track 1 Session 2</a>
                </div>
            
            <div class="maincardFooter">Tian Qi Chen &middot; Jens Behrmann &middot; David Duvenaud &middot; Joern-Henrik Jacobsen</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5254" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15855.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.toronto.edu/~rtqichen/pdfs/residual_flows_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.toronto.edu/~rtqichen/posters/residual_flows_poster.pdf" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Flow-based generative models parameterize probability distributions through an invertible transformation and can be trained by maximum likelihood. Invertible residual networks provide a flexible family of transformations where only Lipschitz conditions rather than strict architectural constraints are needed for enforcing invertibility. However, prior work trained invertible residual networks for density estimation by relying on biased log-density estimates whose bias increased with the network&#x27;s expressiveness. We give a tractable unbiased estimate of the log density, and reduce the memory required during training by a factor of ten. Furthermore, we improve invertible residual blocks by proposing the use of activation functions that avoid gradient saturation and generalizing the Lipschitz condition to induced mixed norms. The resulting approach, called Residual Flows, achieves state-of-the-art performance on density estimation amongst flow-based models, and outperforms networks that use coupling blocks at joint generative and discriminative modeling.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15688">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Ballroom A + B  </div>
            <div class="maincardBody">Guided Meta-Policy Search</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15682">
                    Track 3 Session 2</a>
                </div>
            
            <div class="maincardFooter">Russell Mendonca &middot; Abhishek Gupta &middot; Rosen Kralev &middot; Pieter Abbeel &middot; Sergey Levine &middot; Chelsea Finn</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5115" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1JHKFFmTnMX1IvauTkeDc6AOJVCdgGkGJ/view?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15688.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1n4KsWoaMVSIhdateZ5UMNv84EAwRHB7n/view?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1hwnb9TaY4uPTvsLv1C6WULqcVWMm9AIc/view?usp=sharing" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Reinforcement learning (RL) algorithms have demonstrated promising results on complex tasks, yet often require impractical numbers of samples because they learn from scratch. Meta-RL aims to address this challenge by leveraging experience from previous tasks so as to more quickly solve new tasks. However, in practice, these algorithms generally also require large amounts of on-policy experience during the \emph{meta-training} process, making them impractical for use in many problems. To this end, we propose to learn a reinforcement learning procedure in a federated way, where individual off-policy learners can solve the individual meta-training tasks, and then consolidate these solutions into a single meta-learner. Since the central meta-learner learns by imitating the solutions to the individual tasks, it can accommodate either the standard meta-RL problem setting, or a hybrid setting where some or all tasks are provided with example demonstrations. The former results in an approach that can leverage policies learned for previous tasks without significant amounts of on-policy data during meta-training, whereas the latter is particularly useful in cases where demonstrations are easy for a person to provide. Across a number of continuous control meta-RL problems, we demonstrate significant improvements in meta-RL sample efficiency in comparison to prior work as well as the ability to scale to domains with visual observations. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower oral" id="maincard_15745">
            <div class='pull-right maincardHeader maincardType'>Oral</div>
            <div class="maincardHeader">{daterange} @ West Ballroom C  </div>
            <div class="maincardBody">Parameter elimination in particle Gibbs sampling</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15738">
                    Track 4 Session 2</a>
                </div>
            
            <div class="maincardFooter">Anna Wigren &middot; Riccardo Sven Risuleo &middot; Lawrence Murray &middot; Fredrik Lindsten</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4792" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.it.uu.se/katalog/annwi999/Publications/Neurips2019" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.it.uu.se/katalog/annwi999/Publications/Neurips2019" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Bayesian inference in state-space models is challenging due to high-dimensional state trajectories. A viable approach is particle Markov chain Monte Carlo (PMCMC), combining MCMC and sequential Monte Carlo to form ``exact approximations&#x27;&#x27; to otherwise-intractable MCMC methods. The performance of the approximation is limited to that of the exact method. We focus on particle Gibbs (PG) and particle Gibbs with ancestor sampling (PGAS), improving their performance beyond that of the ideal Gibbs sampler (which they approximate) by marginalizing out one or more parameters. This is possible when the parameter(s) has a conjugate prior relationship with the complete data likelihood. Marginalization yields a non-Markov model for inference, but we show that, in contrast to the general case, the methods still scale linearly in time. While marginalization can be cumbersome to implement, recent advances in probabilistic programming have enabled its automation. We demonstrate how the marginalized methods are viable as efficient inference backends in probabilistic programming, and demonstrate with examples in ecology and epidemiology.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15803">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall A  </div>
            <div class="maincardBody">Learning Positive Functions with Pseudo Mirror Descent</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15794">
                    Track 2 Session 2</a>
                </div>
            
            <div class="maincardFooter">Yingxiang Yang &middot; Haoxiang Wang &middot; Negar Kiyavash &middot; Niao He</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-7901" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15803.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/sh/veks5wyi9p1s4wd/AACfKZ-D-gjlorqfqT_bH_Gea?dl=0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >The nonparametric learning of positive-valued functions appears widely in machine learning, especially in the context of estimating intensity functions of point processes. Yet, existing approaches either require computing expensive projections or semidefinite relaxations, or lack convexity and theoretical guarantees after introducing nonlinear link functions. In this paper, we propose a novel algorithm, pseudo mirror descent, that performs efficient estimation of positive functions within a Hilbert space without expensive projections. The algorithm guarantees positivity by performing mirror descent with an appropriately selected Bregman divergence, and a pseudo-gradient is adopted to speed up the gradient evaluation procedure in practice. We analyze both asymptotic and nonasymptotic convergence of the algorithm. Through simulations, we show that pseudo mirror descent outperforms the state-of-the-art benchmarks for learning intensities of Poisson and multivariate Hawkes processes, in terms of both computational efficiency and accuracy.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15693">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Ballroom A + B  </div>
            <div class="maincardBody">Hindsight Credit Assignment</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15682">
                    Track 3 Session 2</a>
                </div>
            
            <div class="maincardFooter">Anna Harutyunyan &middot; Will Dabney &middot; Thomas Mesnard &middot; Mohammad Gheshlaghi Azar &middot; Bilal Piot &middot; Nicolas Heess &middot; Hado van Hasselt &middot; Gregory Wayne &middot; Satinder Singh &middot; Doina Precup &middot; Remi Munos</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6771" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15693.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/2EnckznIV2o" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We consider the problem of efficient credit assignment in reinforcement learning. In order to efficiently and meaningfully utilize new data, we propose to explicitly assign credit to past decisions based on the likelihood of them having led to the observed outcome. This approach uses new information in hindsight, rather than employing foresight. Somewhat surprisingly, we show that value functions can be rewritten through this lens, yielding a new family of algorithms. We study the properties of these algorithms, and empirically show that they successfully address important credit assignment challenges, through a set of illustrative tasks.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14381">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #32</div>
            <div class="maincardBody">Qsparse-local-SGD: Distributed SGD with Quantization, Sparsification and Local Computations</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15529">
                    Algorithms -- Large Scale Learning</a>
                </div>
            
            <div class="maincardFooter">Debraj Basu &middot; Deepesh Data &middot; Can Karakus &middot; Suhas Diggavi</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-8295" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1Tx0KTnu1VOi_yAxcrsLwc9JzTMdsvy5S/view" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/UxXdAdkyAF0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Communication bottleneck has been identified as a significant issue in distributed optimization of large-scale learning models. Recently, several approaches to mitigate this problem have been proposed, including different forms of gradient compression or computing local models and mixing them iteratively. In this paper we propose Qsparse-local-SGD algorithm, which combines aggressive sparsification with quantization and local computation along with error compensation, by keeping track of the difference between the true and compressed gradients. We propose both synchronous and asynchronous implementations of Qsparse-local-SGD. We analyze convergence for Qsparse-local-SGD in the distributed case, for smooth non-convex and convex objective functions. We demonstrate that Qsparse-local-SGD converges at the same rate as vanilla distributed SGD for many important classes of sparsifiers and quantizers. We use Qsparse-local-SGD to train ResNet-50 on ImageNet, and show that it results in significant savings over the state-of-the-art, in the number of bits transmitted to reach target accuracy.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14577">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #42</div>
            <div class="maincardBody">Guided Meta-Policy Search</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15530">
                    Algorithms -- Meta-Learning</a>
                </div>
            
            <div class="maincardFooter">Russell Mendonca &middot; Abhishek Gupta &middot; Rosen Kralev &middot; Pieter Abbeel &middot; Sergey Levine &middot; Chelsea Finn</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5115" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1JHKFFmTnMX1IvauTkeDc6AOJVCdgGkGJ/view?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1n4KsWoaMVSIhdateZ5UMNv84EAwRHB7n/view?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1hwnb9TaY4uPTvsLv1C6WULqcVWMm9AIc/view?usp=sharing" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Reinforcement learning (RL) algorithms have demonstrated promising results on complex tasks, yet often require impractical numbers of samples because they learn from scratch. Meta-RL aims to address this challenge by leveraging experience from previous tasks so as to more quickly solve new tasks. However, in practice, these algorithms generally also require large amounts of on-policy experience during the \emph{meta-training} process, making them impractical for use in many problems. To this end, we propose to learn a reinforcement learning procedure in a federated way, where individual off-policy learners can solve the individual meta-training tasks, and then consolidate these solutions into a single meta-learner. Since the central meta-learner learns by imitating the solutions to the individual tasks, it can accommodate either the standard meta-RL problem setting, or a hybrid setting where some or all tasks are provided with example demonstrations. The former results in an approach that can leverage policies learned for previous tasks without significant amounts of on-policy data during meta-training, whereas the latter is particularly useful in cases where demonstrations are easy for a person to provide. Across a number of continuous control meta-RL problems, we demonstrate significant improvements in meta-RL sample efficiency in comparison to prior work as well as the ability to scale to domains with visual observations. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14625">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #55</div>
            <div class="maincardBody">Learning Positive Functions with Pseudo Mirror Descent</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15532">
                    Algorithms -- Structured Prediction</a>
                </div>
            
            <div class="maincardFooter">Yingxiang Yang &middot; Haoxiang Wang &middot; Negar Kiyavash &middot; Niao He</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-7901" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/sh/veks5wyi9p1s4wd/AACfKZ-D-gjlorqfqT_bH_Gea?dl=0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >The nonparametric learning of positive-valued functions appears widely in machine learning, especially in the context of estimating intensity functions of point processes. Yet, existing approaches either require computing expensive projections or semidefinite relaxations, or lack convexity and theoretical guarantees after introducing nonlinear link functions. In this paper, we propose a novel algorithm, pseudo mirror descent, that performs efficient estimation of positive functions within a Hilbert space without expensive projections. The algorithm guarantees positivity by performing mirror descent with an appropriately selected Bregman divergence, and a pseudo-gradient is adopted to speed up the gradient evaluation procedure in practice. We analyze both asymptotic and nonasymptotic convergence of the algorithm. Through simulations, we show that pseudo mirror descent outperforms the state-of-the-art benchmarks for learning intensities of Poisson and multivariate Hawkes processes, in terms of both computational efficiency and accuracy.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13590">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #61</div>
            <div class="maincardBody">On Adversarial Mixup Resynthesis</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15533">
                    Algorithms -- Unsupervised Learning</a>
                </div>
            
            <div class="maincardFooter">Christopher Beckham &middot; Sina Honari &middot; Alex Lamb &middot; Vikas Verma &middot; Farnoosh Ghadiri &middot; R Devon Hjelm &middot; Yoshua Bengio &middot; Chris Pal</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2434" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=ezbC3_VZeNY" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >In this paper, we explore new approaches to combining information encoded within the learned representations of auto-encoders. We explore models that are capable of combining the attributes of multiple inputs such that a resynthesised output is trained to fool an adversarial discriminator for real versus synthesised data. Furthermore, we explore the use of such an architecture in the context of semi-supervised learning, where we learn a mixing function whose objective is to produce interpolations of hidden states, or masked combinations of latent representations that are consistent with a conditioned class label. We show quantitative and qualitative evidence that such a formulation is an interesting avenue of research.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13611">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #64</div>
            <div class="maincardBody">Symmetry-Based Disentangled Representation Learning requires Interaction with Environments</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15533">
                    Algorithms -- Unsupervised Learning</a>
                </div>
            
            <div class="maincardFooter">Hugo Caselles-Dupré &middot; Michael Garcia Ortiz &middot; David Filliat</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2585" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/Caselles/NeurIPS19-SBDRL/blob/master/static/_NeurIPS19_Poster__SBDRL_requires_Interactions_w_Env.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/Caselles/NeurIPS19-SBDRL/blob/master/static/%5BNeurIPS19%5D%20SBDRL%20requires%20Interactions%20with%20Environments.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/jyN3ZQNH1GI" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Finding a generally accepted formal definition of a disentangled representation in the context of an agent behaving in an environment is an important challenge towards the construction of data-efficient autonomous agents. Higgins et al. recently proposed Symmetry-Based Disentangled Representation Learning, a definition based on a characterization of symmetries in the environment using group theory. We build on their work and make observations, theoretical and empirical, that lead us to argue that Symmetry-Based Disentangled Representation Learning cannot only be based on static observations: agents should interact with the environment to discover its symmetries. Our experiments can be reproduced in Colab and the code is available on GitHub.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14516">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #79</div>
            <div class="maincardBody">Implicit Generation and Modeling with Energy Based Models</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15512">
                    Deep Learning -- Generative Models</a>
                </div>
            
            <div class="maincardFooter">Yilun Du &middot; Igor Mordatch</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1955" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/igebm" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Energy based models (EBMs) are appealing due to their generality and simplicity in likelihood modeling, but have been traditionally difficult to train. We present techniques to scale MCMC based EBM training on continuous neural networks, and we show its success on the high-dimensional data domains of ImageNet32x32, ImageNet128x128, CIFAR-10, and robotic hand trajectories, achieving better samples than other likelihood models and nearing the performance of contemporary GAN approaches, while covering all modes of the data. We highlight some unique capabilities of implicit generation such as compositionality and corrupt image reconstruction and inpainting. Finally, we show that EBMs are useful models across a wide variety of tasks, achieving state-of-the-art out-of-distribution classification, adversarially robust classification, state-of-the-art continual online class learning, and coherent long term predicted trajectory rollouts.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14581">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #85</div>
            <div class="maincardBody">Residual Flows for Invertible Generative Modeling</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15512">
                    Deep Learning -- Generative Models</a>
                </div>
            
            <div class="maincardFooter">Tian Qi Chen &middot; Jens Behrmann &middot; David Duvenaud &middot; Joern-Henrik Jacobsen</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5254" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.toronto.edu/~rtqichen/pdfs/residual_flows_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.toronto.edu/~rtqichen/posters/residual_flows_poster.pdf" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Flow-based generative models parameterize probability distributions through an invertible transformation and can be trained by maximum likelihood. Invertible residual networks provide a flexible family of transformations where only Lipschitz conditions rather than strict architectural constraints are needed for enforcing invertibility. However, prior work trained invertible residual networks for density estimation by relying on biased log-density estimates whose bias increased with the network&#x27;s expressiveness. We give a tractable unbiased estimate of the log density, and reduce the memory required during training by a factor of ten. Furthermore, we improve invertible residual blocks by proposing the use of activation functions that avoid gradient saturation and generalizing the Lipschitz condition to induced mixed norms. The resulting approach, called Residual Flows, achieves state-of-the-art performance on density estimation amongst flow-based models, and outperforms networks that use coupling blocks at joint generative and discriminative modeling.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13574">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #93</div>
            <div class="maincardBody">Limitations of the empirical Fisher approximation for natural gradient descent</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15514">
                    Deep Learning -- Optimization for Deep Networks</a>
                </div>
            
            <div class="maincardFooter">Frederik Kunstner &middot; Philipp Hennig &middot; Lukas Balles</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2300" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=f0jeOi4pW_A" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Natural gradient descent, which preconditions a gradient descent update
with the Fisher information matrix of the underlying statistical model,
is a way to capture partial second-order information. 
Several highly visible works have advocated an approximation known as the empirical Fisher,
drawing connections between approximate second-order methods and heuristics like Adam.
We dispute this argument by showing that the empirical Fisher---unlike the Fisher---does not generally capture second-order information.
We further argue that the conditions under which the empirical Fisher approaches the Fisher (and the Hessian)
are unlikely to be met in practice, and that, even on simple optimization problems,
the pathologies of the empirical Fisher can have undesirable effects.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13759">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #94</div>
            <div class="maincardBody">Maximum Mean Discrepancy Gradient Flow</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15514">
                    Deep Learning -- Optimization for Deep Networks</a>
                </div>
            
            <div class="maincardFooter">Michael Arbel &middot; Anna Korba &middot; Adil Salim &middot; Arthur Gretton</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-3487" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://michaelarbel.github.io/materials/poster_MMD_flow.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://michaelarbel.github.io/materials/MMD_flow.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >  We construct a Wasserstein gradient flow of the maximum mean discrepancy (MMD) and study its convergence properties.
  The MMD is an integral probability metric defined for a reproducing kernel Hilbert space (RKHS), and serves as a metric on probability measures for a sufficiently rich RKHS.  We obtain conditions for convergence of the gradient flow towards a global optimum, that can be related to particle transport when optimizing neural networks.
  We also propose a way to regularize this MMD flow, based on an injection of noise in the gradient. This algorithmic fix comes with theoretical and empirical evidence.
The practical implementation of the flow is straightforward, since both the MMD and its gradient have simple closed-form expressions, which can be easily estimated with samples.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13534">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #114</div>
            <div class="maincardBody">Tight Dimension Independent Lower Bound on the Expected Convergence Rate for Diminishing Step Sizes in SGD</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15535">
                    Optimization -- Convex Optimization</a>
                </div>
            
            <div class="maincardFooter">Ha Nguyen &middot; Lam Nguyen &middot; Marten van Dijk</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1973" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/16-1vGnbxycM5Wz_HFySa2jT1osR1Qrw1/view" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1AKJR9ef5TZgX4uQUbGqVvm0gsdRGehAj/view" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/18st_NJYsYWUimP3HhM1UW-LTALupQ-ms/view?usp=sharing" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We study the convergence of Stochastic Gradient Descent (SGD) for strongly convex  objective functions. We prove for all $t$ a lower bound on the expected convergence rate after the $t$-th SGD iteration; the lower bound is over all possible sequences of diminishing step sizes. It implies that recently proposed sequences of step sizes at ICML 2018 and ICML 2019 are {\em universally} close to optimal in that the expected convergence rate after {\em each} iteration is within a factor $32$ of our lower bound. This factor is independent of dimension $d$. We offer a framework for comparing with lower bounds in state-of-the-art literature and when applied to SGD for strongly convex objective functions our lower bound is a significant factor $775\cdot d$ larger compared to existing work. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14506">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #116</div>
            <div class="maincardBody">Asymmetric Valleys: Beyond Sharp and Flat Local Minima</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15536">
                    Optimization -- Non-Convex Optimization</a>
                </div>
            
            <div class="maincardFooter">Haowei He &middot; Gao Huang &middot; Yang Yuan</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1457" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/962086838/code-for-Asymmetric-Valley/blob/master/asymmetric_ppt.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/zWwaJ3gbv_Q" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Despite the non-convex nature of their loss functions, deep neural networks are known to generalize well when optimized with stochastic gradient descent (SGD). Recent work conjectures that SGD with proper conﬁguration is able to ﬁnd wide and ﬂat local minima, which are correlated with good generalization performance. In this paper, we observe that local minima of modern deep networks are more than being ﬂat or sharp. Instead, at a local minimum there exist many asymmetric directions such that the loss increases abruptly along one side, and slowly along the opposite side – we formally deﬁne such minima as asymmetric valleys. Under mild assumptions, we ﬁrst prove that for asymmetric valleys, a solution biased towards the ﬂat side generalizes better than the exact empirical minimizer. Then, we show that performing weight averaging along the SGD trajectory implicitly induces such biased solutions. This provides theoretical explanations for a series of intriguing phenomena observed in recent work [25, 5, 51]. Finally, extensive empirical experiments on both modern deep networks and simple 2 layer networks are conducted to validate our assumptions and analyze the intriguing properties of asymmetric valleys.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13540">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #123</div>
            <div class="maincardBody">Painless Stochastic Gradient: Interpolation, Line-Search, and Convergence Rates</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15536">
                    Optimization -- Non-Convex Optimization</a>
                </div>
            
            <div class="maincardFooter">Sharan Vaswani &middot; Aaron Mishkin &middot; Issam Laradji &middot; Mark Schmidt &middot; Gauthier Gidel &middot; Simon Lacoste-Julien</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2038" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/IssamLaradji/sls/tree/master/Poster" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/IssamLaradji/sls/tree/master/Video" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Recent works have shown that stochastic gradient descent (SGD) achieves the fast convergence rates of full-batch gradient descent for over-parameterized models satisfying certain interpolation conditions. However, the step-size used in these works depends on unknown quantities and SGD&#x27;s practical performance heavily relies on the choice of this step-size. We propose to use line-search techniques to automatically set the step-size when training models that can interpolate the data. In the interpolation setting, we prove that SGD with a stochastic variant of the classic Armijo line-search attains the deterministic convergence rates for both convex and strongly-convex functions. Under additional assumptions, SGD with Armijo line-search is shown to achieve fast convergence for non-convex functions. Furthermore, we show that stochastic extra-gradient with a Lipschitz line-search attains linear convergence for an important class of non-convex functions and saddle-point problems satisfying interpolation. To improve the proposed methods&#x27; practical performance, we give heuristics to use larger step-sizes and acceleration. We compare the proposed algorithms against numerous optimization methods on standard classification tasks using both kernel methods and deep networks. The proposed methods result in competitive performance across all models and datasets, while being robust to the precise choices of hyper-parameters. For multi-class classification using deep networks, SGD with Armijo line-search results in both faster convergence and better generalization. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14344">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #135</div>
            <div class="maincardBody">Integrating Markov processes with structural causal modeling enables counterfactual inference in complex systems</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15519">
                    Probabilistic Methods -- Causal Inference</a>
                </div>
            
            <div class="maincardFooter">Robert Ness &middot; Kaushal Paneri &middot; Olga Vitek</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-7995" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://bit.ly/MarkovP2SCM" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://bit.ly/MarkovP2SCM" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://bit.ly/MarkovP2SCM" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >This manuscript contributes a general and practical framework for casting a Markov process model of a system at equilibrium as a structural causal model, and carrying out counterfactual inference. Markov processes mathematically describe the mechanisms in the system, and predict the system’s equilibrium behavior upon intervention, but do not support counterfactual inference. In contrast, structural causal models support counterfactual inference, but do not identify the mechanisms. This manuscript leverages the benefits of both approaches. We define the structural causal models in terms of the parameters and the equilibrium dynamics of the Markov process models, and counterfactual inference flows from these settings. The proposed approach alleviates the identifiability drawback of the structural causal models, in that the counterfactual inference is consistent with the counterfactual trajectories simulated from the Markov process model. We showcase the benefits of this framework in case studies of complex biomolecular systems with nonlinear dynamics. We illustrate that, in presence of Markov process model misspecification, counterfactual inference leverages prior data, and therefore estimates the outcome of an intervention more accurately than a direct simulation.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14149">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #141</div>
            <div class="maincardBody">The Case for Evaluating Causal Models Using Interventional Measures and Empirical Data</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15519">
                    Probabilistic Methods -- Causal Inference</a>
                </div>
            
            <div class="maincardFooter">Amanda Gentzel &middot; Dan Garant &middot; David Jensen</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6256" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://agentzel.github.io/publications/Evaluation%20poster%20NeurIPS.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://agentzel.github.io/publications/neurips-2019-video.m4v" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Causal inference is central to many areas of artificial intelligence, including complex reasoning, planning, knowledge-base construction, robotics, explanation, and fairness. An active community of researchers develops and enhances algorithms that learn causal models from data, and this work has produced a series of impressive technical advances.  However, evaluation techniques for causal modeling algorithms have remained somewhat primitive, limiting what we can learn from experimental studies of algorithm performance, constraining the types of algorithms and model representations that researchers consider, and creating a gap between theory and practice.  We argue for more frequent use of evaluation techniques that examine interventional measures rather than structural or observational measures, and that evaluate those measures on empirical data rather than synthetic data.  We survey the current practice in evaluation and show that the techniques we recommend are rarely used in practice. We show that such techniques are feasible and that data sets are available to conduct such evaluations.  We also show that these techniques produce substantially different results than using structural measures and synthetic data.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13230">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #157</div>
            <div class="maincardBody">Parameter elimination in particle Gibbs sampling</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15541">
                    Probabilistic Methods -- MCMC</a>
                </div>
            
            <div class="maincardFooter">Anna Wigren &middot; Riccardo Sven Risuleo &middot; Lawrence Murray &middot; Fredrik Lindsten</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4792" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.it.uu.se/katalog/annwi999/Publications/Neurips2019" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.it.uu.se/katalog/annwi999/Publications/Neurips2019" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Bayesian inference in state-space models is challenging due to high-dimensional state trajectories. A viable approach is particle Markov chain Monte Carlo (PMCMC), combining MCMC and sequential Monte Carlo to form ``exact approximations&#x27;&#x27; to otherwise-intractable MCMC methods. The performance of the approximation is limited to that of the exact method. We focus on particle Gibbs (PG) and particle Gibbs with ancestor sampling (PGAS), improving their performance beyond that of the ideal Gibbs sampler (which they approximate) by marginalizing out one or more parameters. This is possible when the parameter(s) has a conjugate prior relationship with the complete data likelihood. Marginalization yields a non-Markov model for inference, but we show that, in contrast to the general case, the methods still scale linearly in time. While marginalization can be cumbersome to implement, recent advances in probabilistic programming have enabled its automation. We demonstrate how the marginalized methods are viable as efficient inference backends in probabilistic programming, and demonstrate with examples in ecology and epidemiology.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13241">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #174</div>
            <div class="maincardBody">Causal Confusion in Imitation Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15520">
                    Reinforcement Learning and Planning -- Decision and Control</a>
                </div>
            
            <div class="maincardFooter">Pim de Haan &middot; Dinesh Jayaraman &middot; Sergey Levine</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6250" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/causal-confusion" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/causal-confusion" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Behavioral cloning reduces policy learning to supervised learning by training a discriminative model to predict expert actions given observations. Such discriminative models are non-causal: the training procedure is unaware of the causal structure of the interaction between the expert and the environment. We point out that ignoring causality is particularly damaging because of the distributional shift in imitation learning. In particular, it leads to a counter-intuitive &quot;causal misidentification&quot; phenomenon: access to more information can yield worse performance. We investigate how this problem arises, and propose a solution to combat it through targeted interventions---either environment interaction or expert queries---to determine the correct causal model. We show that causal misidentification occurs in several benchmark control domains as well as realistic driving settings, and validate our solution against DAgger and other baselines and ablations.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14205">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #192</div>
            <div class="maincardBody">When to Trust Your Model: Model-Based Policy Optimization</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15543">
                    Reinforcement Learning and Planning -- Model-Based RL</a>
                </div>
            
            <div class="maincardFooter">Michael Janner &middot; Justin Fu &middot; Marvin Zhang &middot; Sergey Levine</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6805" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://people.eecs.berkeley.edu/~janner/mbpo/mbpo_poster_neurips_2019.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://people.eecs.berkeley.edu/~janner/mbpo/mbpo_slides_neurips_2019.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://people.eecs.berkeley.edu/~janner/mbpo/" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Designing effective model-based reinforcement learning algorithms is difficult because the ease of data generation must be weighed against the bias of model-generated data. In this paper, we study the role of model usage in policy optimization both theoretically and empirically. We first formulate and analyze a model-based reinforcement learning algorithm with a guarantee of monotonic improvement at each step. In practice, this analysis is overly pessimistic and suggests that real off-policy data is always preferable to model-generated on-policy data, but we show that an empirical estimate of model generalization can be incorporated into such analysis to justify model usage. Motivated by this analysis, we then demonstrate that a simple procedure of using short model-generated rollouts branched from real data has the benefits of more complicated model-based algorithms without the usual pitfalls. In particular, this approach surpasses the sample efficiency of prior model-based methods, matches the asymptotic performance of the best model-free algorithms, and scales to horizons that cause other model-based methods to fail entirely.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13659">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #199</div>
            <div class="maincardBody">On the Utility of Learning about Humans for Human-AI Coordination</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15544">
                    Reinforcement Learning and Planning -- Multi-Agent RL</a>
                </div>
            
            <div class="maincardFooter">Micah Carroll &middot; Rohin Shah &middot; Mark Ho &middot; Tom Griffiths &middot; Sanjit Seshia &middot; Pieter Abbeel &middot; Anca Dragan</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2815" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1y4CghZjgLu5K57Gq5P0ZXz4jQScY7Mb2/view?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1RwkXWwPksOR75dGrAwSBSVLMEnAvk0jE/view?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/13XjCGQ-suZGQOmCZQNbSiL1rMfExnKGj/view?usp=sharing" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >While we would like agents that can coordinate with humans, current algorithms such as self-play and population-based training create agents that can coordinate with themselves. Agents that assume their partner to be optimal or similar to them can converge to coordination protocols that fail to understand and be understood by humans. To demonstrate this, we introduce a simple environment that requires challenging coordination, based on the popular game Overcooked, and learn a simple model that mimics human play. We evaluate the performance of agents trained via self-play and population-based training. These agents perform very well when paired with themselves, but when paired with our human model, they are significantly worse than agents designed to play with the human model. An experiment with a planning algorithm yields the same conclusion, though only when the human-aware planner is given the exact human model that it is playing with. A user study with real humans shows this pattern as well, though less strongly. Qualitatively, we find that the gains come from having the agent adapt to the human&#x27;s gameplay. Given this result, we suggest several approaches for designing agents that learn about humans in order to better coordinate with them. Code is available at https://github.com/HumanCompatibleAI/overcooked_ai.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14613">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #204</div>
            <div class="maincardBody">Hindsight Credit Assignment</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15545">
                    Reinforcement Learning and Planning -- Reinforcement Learning</a>
                </div>
            
            <div class="maincardFooter">Anna Harutyunyan &middot; Will Dabney &middot; Thomas Mesnard &middot; Mohammad Gheshlaghi Azar &middot; Bilal Piot &middot; Nicolas Heess &middot; Hado van Hasselt &middot; Gregory Wayne &middot; Satinder Singh &middot; Doina Precup &middot; Remi Munos</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6771" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/2EnckznIV2o" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We consider the problem of efficient credit assignment in reinforcement learning. In order to efficiently and meaningfully utilize new data, we propose to explicitly assign credit to past decisions based on the likelihood of them having led to the observed outcome. This approach uses new information in hindsight, rather than employing foresight. Somewhat surprisingly, we show that value functions can be rewritten through this lens, yielding a new family of algorithms. We study the properties of these algorithms, and empirically show that they successfully address important credit assignment challenges, through a set of illustrative tasks.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14482">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #205</div>
            <div class="maincardBody">Imitation Learning from Observations by Minimizing Inverse Dynamics Disagreement</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15545">
                    Reinforcement Learning and Planning -- Reinforcement Learning</a>
                </div>
            
            <div class="maincardFooter">Chao Yang &middot; Xiaojian Ma &middot; Wenbing Huang &middot; Fuchun Sun &middot; Huaping Liu &middot; Junzhou Huang &middot; Chuang Gan</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-98" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/neurips19-iddm/home" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/neurips19-iddm/home" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/neurips19-iddm/home" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >This paper studies Learning from Observations (LfO) for imitation learning with access to state-only demonstrations. In contrast to Learning from Demonstration (LfD) that involves both action and state supervisions, LfO is more practical in leveraging previously inapplicable resources (e.g., videos), yet more challenging due to the incomplete expert guidance. In this paper, we investigate LfO and its difference with LfD in both theoretical and practical perspectives. We first prove that the gap between LfD and LfO actually lies in the disagreement of inverse dynamics models between the imitator and expert, if following the modeling approach of GAIL. More importantly, the upper bound of this gap is revealed by a negative causal entropy which can be minimized in a model-free way. We term our method as Inverse-Dynamics-Disagreement-Minimization (IDDM) which enhances the conventional LfO method through further bridging the gap to LfD. Considerable empirical results on challenging benchmarks indicate that our method attains consistent improvements over other LfO counterparts.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13903">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #222</div>
            <div class="maincardBody">Multiclass Learning from Contradictions</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15527">
                    Theory -- Learning Theory</a>
                </div>
            
            <div class="maincardFooter">Sauptik Dhar &middot; Vladimir Cherkassky &middot; Mohak Shah</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4552" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/6TayjC7qqPg" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We introduce the notion of learning from contradictions, a.k.a Universum learning, for multiclass problems and propose a novel formulation for multiclass universum SVM (MU-SVM). We show that learning from contradictions (using MU-SVM) incurs lower sample complexity compared to multiclass SVM (M-SVM) by deriving the Natarajan dimension for sample complexity for PAC-learnability of MU-SVM. We also propose an analytic span bound for MU-SVM and demonstrate its utility for model selection resulting in $\sim 2-4 \times$ faster computation times than standard resampling techniques. We empirically demonstrate the efficacy of MU- SVM on several real world datasets achieving $&gt;$ 20\% improvement in test accuracies compared to M-SVM. Insights into the underlying behavior of MU-SVM using a histograms-of-projections method are also provided.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower oral" id="maincard_15864">
            <div class='pull-right maincardHeader maincardType'>Oral</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall C + B3  </div>
            <div class="maincardBody">Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15863">
                    Track 1 Session 3</a>
                </div>
            
            <div class="maincardFooter">Vincent Sitzmann &middot; Michael Zollhoefer &middot; Gordon Wetzstein</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-667" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://vsitzmann.github.io/srns/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://vsitzmann.github.io/srns/slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://vsitzmann.github.io/srns/video/" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Unsupervised learning with generative models has the potential of discovering rich representations of 3D scenes. While geometric deep learning has explored 3D-structure-aware representations of scene geometry, these models typically require explicit 3D supervision. Emerging neural scene representations can be trained only with posed 2D images, but existing methods ignore the three-dimensional structure of scenes. We propose Scene Representation Networks (SRNs), a continuous, 3D-structure-aware scene representation that encodes both geometry and appearance. SRNs represent scenes as continuous functions that map world coordinates to a feature representation of local scene properties. By formulating the image formation as a differentiable ray-marching algorithm, SRNs can be trained end-to-end from only 2D images and their camera poses, without access to depth or shape. This formulation naturally generalizes across scenes, learning powerful geometry and appearance priors in the process. We demonstrate the potential of SRNs by evaluating them for novel view synthesis, few-shot reconstruction, joint shape and appearance interpolation, and unsupervised discovery of a non-rigid face model.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15697">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Ballroom A + B  </div>
            <div class="maincardBody">Calibration tests in multi-class classification: A unifying framework</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15695">
                    Track 3 Session 3</a>
                </div>
            
            <div class="maincardFooter">David Widmann &middot; Fredrik Lindsten &middot; Dave Zachariah</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6628" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/devmotion/CalibrationPaper/tree/master/poster/neurips.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15697.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/devmotion/CalibrationPaper/tree/master/slides/spotlight.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://vimeo.com/369295144" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >In safety-critical applications a probabilistic model is usually required to be calibrated, i.e., to capture the uncertainty of its predictions accurately. In multi-class classification, calibration of the most confident predictions only is often not sufficient. We propose and study calibration measures for multi-class classification that generalize existing measures such as the expected calibration error, the maximum calibration error, and the maximum mean calibration error. We propose and evaluate empirically different consistent and unbiased estimators for a specific class of measures based on matrix-valued kernels. Importantly, these estimators can be interpreted as test statistics associated with well-defined bounds and approximations of the p-value under the null hypothesis that the model is calibrated, significantly improving the interpretability of calibration measures, which otherwise lack any meaningful unit or scale.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15699">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Ballroom A + B  </div>
            <div class="maincardBody">Fast structure learning with modular regularization</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15695">
                    Track 3 Session 3</a>
                </div>
            
            <div class="maincardFooter">Greg Ver Steeg &middot; Hrayr Harutyunyan &middot; Daniel Moyer &middot; Aram Galstyan</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-9031" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15699.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.isi.edu/sites/default/files/users/gregv/corex_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://bit.ly/2N9IJ66" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Estimating graphical model structure from high-dimensional and undersampled data is a fundamental problem in many scientific fields.
Existing approaches, such as GLASSO, latent variable GLASSO, and latent tree models, suffer from high computational complexity and may impose unrealistic sparsity priors in some cases.
We introduce a novel method that leverages a newly discovered connection between information-theoretic measures and structured latent factor models to derive an optimization objective which encourages modular structures where each observed variable has a single latent parent.
The proposed method has linear stepwise computational complexity w.r.t. the number of observed variables.
Our experiments on synthetic data demonstrate that our approach is the only method that recovers modular structure better as the dimensionality increases. We also use our approach for estimating covariance structure for a number of real-world datasets and show that it consistently outperforms state-of-the-art estimators at a fraction of the computational cost. Finally, we apply the proposed method to high-resolution fMRI data (with more than 10^5 voxels) and show that it is capable of extracting meaningful patterns.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14640">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #16</div>
            <div class="maincardBody">Fast structure learning with modular regularization</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15550">
                    Algorithms -- Model Selection and Structure Learning</a>
                </div>
            
            <div class="maincardFooter">Greg Ver Steeg &middot; Hrayr Harutyunyan &middot; Daniel Moyer &middot; Aram Galstyan</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-9031" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.isi.edu/sites/default/files/users/gregv/corex_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://bit.ly/2N9IJ66" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Estimating graphical model structure from high-dimensional and undersampled data is a fundamental problem in many scientific fields.
Existing approaches, such as GLASSO, latent variable GLASSO, and latent tree models, suffer from high computational complexity and may impose unrealistic sparsity priors in some cases.
We introduce a novel method that leverages a newly discovered connection between information-theoretic measures and structured latent factor models to derive an optimization objective which encourages modular structures where each observed variable has a single latent parent.
The proposed method has linear stepwise computational complexity w.r.t. the number of observed variables.
Our experiments on synthetic data demonstrate that our approach is the only method that recovers modular structure better as the dimensionality increases. We also use our approach for estimating covariance structure for a number of real-world datasets and show that it consistently outperforms state-of-the-art estimators at a fraction of the computational cost. Finally, we apply the proposed method to high-resolution fMRI data (with more than 10^5 voxels) and show that it is capable of extracting meaningful patterns.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14190">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #38</div>
            <div class="maincardBody">Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with Dirichlet calibration</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15553">
                    Algorithms -- Uncertainty Estimation</a>
                </div>
            
            <div class="maincardFooter">Meelis Kull &middot; Miquel Perello Nieto &middot; Markus Kängsepp &middot; Telmo Silva Filho &middot; Hao Song &middot; Peter Flach</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6658" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://dirichletcal.github.io/documents/neurips2019/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://dirichletcal.github.io/documents/neurips2019/slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://dirichletcal.github.io/documents/neurips2019/video/" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Class probabilities predicted by most multiclass classifiers are uncalibrated, often tending towards over-confidence. With neural networks, calibration can be improved by temperature scaling, a method to learn a single corrective multiplicative factor for inputs to the last softmax layer. On non-neural models the existing methods apply binary calibration in a pairwise or one-vs-rest fashion. We propose a natively multiclass calibration method applicable to classifiers from any model class, derived from Dirichlet distributions and generalising the beta calibration method from binary classification. It is easily implemented with neural nets since it is equivalent to log-transforming the uncalibrated probabilities, followed by one linear layer and softmax. Experiments demonstrate improved probabilistic predictions according to multiple measures (confidence-ECE, classwise-ECE, log-loss, Brier score) across a wide range of datasets and classifiers. Parameters of the learned Dirichlet calibration map 
provide insights to the biases in the uncalibrated model.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14609">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #39</div>
            <div class="maincardBody">Calibration tests in multi-class classification: A unifying framework</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15553">
                    Algorithms -- Uncertainty Estimation</a>
                </div>
            
            <div class="maincardFooter">David Widmann &middot; Fredrik Lindsten &middot; Dave Zachariah</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6628" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/devmotion/CalibrationPaper/tree/master/poster/neurips.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/devmotion/CalibrationPaper/tree/master/slides/spotlight.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://vimeo.com/369295144" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >In safety-critical applications a probabilistic model is usually required to be calibrated, i.e., to capture the uncertainty of its predictions accurately. In multi-class classification, calibration of the most confident predictions only is often not sufficient. We propose and study calibration measures for multi-class classification that generalize existing measures such as the expected calibration error, the maximum calibration error, and the maximum mean calibration error. We propose and evaluate empirically different consistent and unbiased estimators for a specific class of measures based on matrix-valued kernels. Importantly, these estimators can be interpreted as test statistics associated with well-defined bounds and approximations of the p-value under the null hypothesis that the model is calibrated, significantly improving the interpretability of calibration measures, which otherwise lack any meaningful unit or scale.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14382">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #44</div>
            <div class="maincardBody">Likelihood Ratios for Out-of-Distribution Detection</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15553">
                    Algorithms -- Uncertainty Estimation</a>
                </div>
            
            <div class="maincardFooter">Jie Ren &middot; Peter Liu &middot; Emily Fertig &middot; Jasper Snoek &middot; Ryan  Poplin &middot; Mark Depristo &middot; Joshua V Dillon &middot; Balaji Lakshminarayanan</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-8301" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.gatsby.ucl.ac.uk/~balaji/NeurIPS2019-llr-ood-poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.gatsby.ucl.ac.uk/~balaji/NeurIPS2019-llr-ood-slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/-FduW9ZWAR4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Discriminative neural networks offer little or no performance guarantees when deployed on data not generated by the same process as the training distribution. On such out-of-distribution (OOD) inputs, the prediction may not only be erroneous, but confidently so, limiting the safe deployment of classifiers in real-world applications. One such challenging application is bacteria identification based on genomic sequences, which holds the promise of early detection of diseases, but requires a model that can output low confidence predictions on OOD genomic sequences from new bacteria that were not present in the training data. We introduce a genomics dataset for OOD detection that allows other researchers to benchmark progress on this important problem. We investigate deep generative model based approaches for OOD detection and observe that the likelihood score is heavily affected by population level background statistics. We propose a likelihood ratio method for deep generative models which effectively corrects for these confounding background statistics. We benchmark the OOD detection performance of the proposed method against existing approaches on the genomics dataset and show that our method achieves state-of-the-art performance. Finally, we demonstrate the generality of the proposed method by showing that it significantly improves OOD detection when applied to deep generative models of images.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13936">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #46</div>
            <div class="maincardBody">Modelling heterogeneous distributions with an Uncountable Mixture of Asymmetric Laplacians</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15553">
                    Algorithms -- Uncertainty Estimation</a>
                </div>
            
            <div class="maincardFooter">Axel Brando &middot; Jose A Rodriguez &middot; Jordi Vitria &middot; Alberto Rubio Muñoz</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4757" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://vimeo.com/369179175/a17d3de911" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >In regression tasks, aleatoric uncertainty is commonly addressed by considering a parametric distribution of the output variable, which is based on strong assumptions such as symmetry, unimodality or by supposing a restricted shape. These assumptions are too limited in scenarios where complex shapes, strong skews or multiple modes are present. In this paper, we propose a generic deep learning framework that learns an Uncountable Mixture of Asymmetric Laplacians (UMAL), which will allow us to estimate heterogeneous distributions of the output variable and we show its connections to quantile regression. Despite having a fixed number of parameters, the model can be interpreted as an infinite mixture of components, which yields a flexible approximation for heterogeneous distributions. Apart from synthetic cases, we apply this model to room price forecasting and to predict financial operations in personal bank accounts. We demonstrate that UMAL produces proper distributions, which allows us to extract richer insights and to sharpen decision-making.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14164">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #48</div>
            <div class="maincardBody">Prediction of Spatial Point Processes: Regularized Method with Out-of-Sample Guarantees</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15553">
                    Algorithms -- Uncertainty Estimation</a>
                </div>
            
            <div class="maincardFooter">Muhammad Osama &middot; Dave Zachariah &middot; Peter Stoica</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6422" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/s/r2q1dvvitgp357j/Poster_Spatial_process_neurips19.pdf?dl=0" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/s/scoifhfbtl63f7c/neurips19_presentation.pdf?dl=0" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/pg3Z3HEKHjc" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >A spatial point process can be characterized by an intensity function which predicts the number of events that occur across space. In this paper, we develop a method to infer predictive intensity intervals by learning a spatial model using a regularized criterion. We prove that the proposed method exhibits out-of-sample prediction performance guarantees which, unlike standard estimators, are valid even when the spatial model is misspecified. The method is demonstrated using synthetic as well as real spatial data.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13272">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #65</div>
            <div class="maincardBody">Joint-task Self-supervised Learning for Temporal Correspondence</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15555">
                    Applications -- Computer Vision</a>
                </div>
            
            <div class="maincardFooter">Xueting Li &middot; Sifei Liu &middot; Shalini De Mello &middot; Xiaolong Wang &middot; Jan Kautz &middot; Ming-Hsuan Yang</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-159" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=Rfy3dG3lRpM&feature=youtu.be" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >This paper proposes to learn reliable dense correspondence from videos in a self-supervised manner. Our learning process integrates two highly related tasks: tracking large image regions and establishing fine-grained pixel-level associations between consecutive video frames. We exploit the synergy between both tasks through a shared inter-frame affinity matrix, which simultaneously models transitions between video frames at both the region- and pixel-levels. While region-level localization helps reduce ambiguities in fine-grained matching by narrowing down search regions; fine-grained matching provides bottom-up features to facilitate region-level localization. Our method outperforms the state-of-the-art self-supervised methods on a variety of visual correspondence tasks, including video-object and part-segmentation propagation, keypoint tracking, and object tracking. Our self-supervised method even surpasses the fully-supervised affinity feature representation obtained from a ResNet-18 pre-trained on the ImageNet.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13311">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #66</div>
            <div class="maincardBody">Learning Conditional Deformable Templates with Convolutional Networks</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15555">
                    Applications -- Computer Vision</a>
                </div>
            
            <div class="maincardFooter">Adrian Dalca &middot; Marianne Rakic &middot; John Guttag &middot; Mert Sabuncu</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-405" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://voxelmorph.mit.edu/atlas_creation/files/cr_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://voxelmorph.mit.edu/atlas_creation/files/cr_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://voxelmorph.mit.edu/atlas_creation/files/cr_video.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >	We develop a learning framework for building deformable templates, which play a fundamental role in many image analysis and computational anatomy tasks. Conventional methods for template creation and image alignment to the template have undergone decades of rich technical development. In these frameworks, templates are constructed using an iterative process of template estimation and alignment, which is often computationally very expensive. Due in part to this shortcoming, most methods compute a single template for the entire population of images, or a few templates for  specific sub-groups of the data. In this work, we present a probabilistic model and efficient learning strategy that yields either universal or \textit{conditional} templates, jointly with a neural network that provides efficient alignment of the images to these templates. We demonstrate the usefulness of this method on a variety of domains, with a special focus on neuroimaging. This is particularly useful for clinical applications where a pre-existing template does not exist, or creating a new one with traditional methods can be prohibitively expensive. Our code and atlases are available online as part of the VoxelMorph library at http://voxelmorph.csail.mit.edu.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13216">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #71</div>
            <div class="maincardBody">Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15555">
                    Applications -- Computer Vision</a>
                </div>
            
            <div class="maincardFooter">Vincent Sitzmann &middot; Michael Zollhoefer &middot; Gordon Wetzstein</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-667" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://vsitzmann.github.io/srns/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://vsitzmann.github.io/srns/slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://vsitzmann.github.io/srns/video/" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Unsupervised learning with generative models has the potential of discovering rich representations of 3D scenes. While geometric deep learning has explored 3D-structure-aware representations of scene geometry, these models typically require explicit 3D supervision. Emerging neural scene representations can be trained only with posed 2D images, but existing methods ignore the three-dimensional structure of scenes. We propose Scene Representation Networks (SRNs), a continuous, 3D-structure-aware scene representation that encodes both geometry and appearance. SRNs represent scenes as continuous functions that map world coordinates to a feature representation of local scene properties. By formulating the image formation as a differentiable ray-marching algorithm, SRNs can be trained end-to-end from only 2D images and their camera poses, without access to depth or shape. This formulation naturally generalizes across scenes, learning powerful geometry and appearance priors in the process. We demonstrate the potential of SRNs by evaluating them for novel view synthesis, few-shot reconstruction, joint shape and appearance interpolation, and unsupervised discovery of a non-rigid face model.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13896">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #90</div>
            <div class="maincardBody">Learning-In-The-Loop Optimization: End-To-End Control And Co-Design Of Soft Robots Through Learned Deep Latent Representations</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15558">
                    Applications -- Robotics</a>
                </div>
            
            <div class="maincardFooter">Andrew Spielberg &middot; Allan Zhao &middot; Yuanming Hu &middot; Tao Du &middot; Wojciech Matusik &middot; Daniela Rus</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4493" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/umWPhw9o968" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Soft robots have continuum solid bodies that can deform in an infinite number of ways. Controlling soft robots is very challenging as there are no closed form solutions.  We present a learning-in-the-loop co-optimization algorithm in which a latent state representation is learned as the robot figures out how to solve the task. Our solution marries hybrid particle-grid-based simulation with deep, variational convolutional autoencoder architectures that can capture salient features of robot dynamics with high efficacy. We demonstrate our dynamics-aware feature learning algorithm on both 2D and 3D soft robots, and show that it is more robust and faster converging than the dynamics-oblivious baseline.  We validate the behavior of our algorithm with visualizations of the learned representation.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13450">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #94</div>
            <div class="maincardBody">Third-Person Visual Imitation Learning via Decoupled Hierarchical Controller</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15558">
                    Applications -- Robotics</a>
                </div>
            
            <div class="maincardFooter">Pratyusha Sharma &middot; Deepak Pathak &middot; Abhinav Gupta</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1488" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://pathak22.github.io/hierarchical-imitation/resources/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://pathak22.github.io/hierarchical-imitation/resources/slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/eWBkDuNFEKA" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We study a generalized setup for learning from demonstration to build an agent that can manipulate novel objects in unseen scenarios by looking at only a single video of human demonstration from a third-person perspective. To accomplish this goal, our agent should not only learn to understand the intent of the demonstrated third-person video in its context but also perform the intended task in its environment configuration. Our central insight is to enforce this structure explicitly during learning by decoupling what to achieve (intended task) from how to perform it (controller). We propose a hierarchical setup where a high-level module learns to generate a series of first-person sub-goals conditioned on the third-person video demonstration, and a low-level controller predicts the actions to achieve those sub-goals. Our agent acts from raw image observations without any access to the full state information. We show results on a real robotic platform using Baxter for the manipulation tasks of pouring and placing objects in a box. Project video is available at https://pathak22.github.io/hierarchical-imitation/</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13430">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #96</div>
            <div class="maincardBody">Multiview Aggregation for Learning Category-Specific Shape Reconstruction</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15559">
                    Applications -- Visual Scene Analysis and Interpretation</a>
                </div>
            
            <div class="maincardFooter">Srinath Sridhar &middot; Davis Rempe &middot; Julien Valentin &middot; Bouaziz Sofien &middot; Leonidas Guibas</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1385" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://geometry.stanford.edu/projects/xnocs" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://geometry.stanford.edu/projects/xnocs" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://geometry.stanford.edu/projects/xnocs" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We investigate the problem of learning category-specific 3D shape reconstruction from a variable number of RGB views of previously unobserved object instances. Most approaches for multiview shape reconstruction operate on sparse shape representations, or assume a fixed number of views. We present a method that can estimate dense 3D shape, and aggregate shape across multiple and varying number of input views. Given a single input view of an object instance, we propose a representation that encodes the dense shape of the visible object surface as well as the surface behind line of sight occluded by the visible surface. When multiple input views are available, the shape representation is designed to be aggregated into a single 3D shape using an inexpensive union operation. We train a 2D CNN to learn to predict this representation from a variable number of views (1 or more). We further aggregate multiview information by using permutation equivariant layers that promote order-agnostic view information exchange at the feature level. Experiments show that our approach is able to produce dense 3D reconstructions of objects that improve in quality as more views are added.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14451">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #97</div>
            <div class="maincardBody">TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15559">
                    Applications -- Visual Scene Analysis and Interpretation</a>
                </div>
            
            <div class="maincardFooter">Jingxiang Lin &middot; Unnat Jain &middot; Alex Schwing</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-9052" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://deanplayerljx.github.io/tabvcr/neurips_2019_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/FS66skIlIYQ" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Reasoning is an important ability that we learn from a very early age. Yet, reasoning is extremely hard for algorithms. Despite impressive recent progress that has been reported on tasks that necessitate reasoning, such as visual question answering and visual dialog, models often exploit biases in datasets. To develop models with better reasoning abilities, recently, the new visual commonsense reasoning (VCR) task has been introduced. Not only do models have to answer questions, but also do they have to provide a reason for the given answer. The proposed baseline achieved compelling results, leveraging a meticulously designed model composed of LSTM modules and attention nets. Here we show that a much simpler model obtained by ablating and pruning the existing intricate baseline can perform better with half the number of trainable parameters. By associating visual features with attribute information and better text to image grounding, we obtain further improvements for our simpler &amp; effective baseline, TAB-VCR. We show that this approach results in a 5.3%, 4.4% and 6.5% absolute improvement over the previous state-of-the-art on question answering, answer justification and holistic VCR. Webpage: https://deanplayerljx.github.io/tabvcr/</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14368">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #135</div>
            <div class="maincardBody">Deep Multi-State Dynamic Recurrent Neural Networks Operating on Wavelet Based Neural Features for Robust Brain Machine Interfaces</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15565">
                    Neuroscience and Cognitive Science -- Brain--Computer Interfaces and Neural Prostheses</a>
                </div>
            
            <div class="maincardFooter">Benyamin Allahgholizadeh Haghi &middot; Spencer Kellis &middot; Sahil Shah &middot; Maitreyi Ashok &middot; Luke Bashford &middot; Daniel Kramer &middot; Brian Lee &middot; Charles Liu &middot; Richard Andersen &middot; Azita Emami</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-8215" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/BenyaminHaghi/DRNN-NeurIPS2019/blob/master/NeurIPS2019_Poster_Benyamin_Haghi.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/BenyaminHaghi/DRNN-NeurIPS2019/blob/master/NeurIPS2019_BenyaminHaghi_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=VbgM-hO_fQ0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We present a new deep multi-state Dynamic Recurrent Neural Network (DRNN) architecture for Brain Machine Interface (BMI) applications. Our DRNN is used to predict Cartesian representation of a computer cursor movement kinematics from open-loop neural data recorded from the posterior parietal cortex (PPC) of a human subject in a BMI system. We design the algorithm to achieve a reasonable trade-off between performance and robustness, and we constrain memory usage in favor of future hardware implementation. We feed the predictions of the network back to the input to improve prediction performance and robustness. We apply a scheduled sampling approach to the model in order to solve a statistical distribution mismatch between the ground truth and predictions. Additionally, we configure a small DRNN to operate with a short history of input, reducing the required buffering of input data and number of memory accesses. This configuration lowers the expected power consumption in a neural network accelerator. Operating on wavelet-based neural features, we show that the average performance of DRNN surpasses other state-of-the-art methods in the literature on both single- and multi-day data recorded over 43 days. Results show that multi-state DRNN has the potential to model the nonlinear relationships between the neural data and kinematics for robust BMIs.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13937">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #139</div>
            <div class="maincardBody">Learning Macroscopic Brain Connectomes via Group-Sparse Factorization</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15566">
                    Neuroscience and Cognitive Science -- Connectomics</a>
                </div>
            
            <div class="maincardFooter">Farzane Aminmansour &middot; Andrew Patterson &middot; Lei Le &middot; Yisu  Peng &middot; Daniel  Mitchell &middot; Franco Pestilli &middot; Cesar F Caiafa &middot; Russell Greiner &middot; Martha White</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4758" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/framinmansour/Learning-Macroscopic-Brain-Connectomes-via-Group-Sparse-Factorization/raw/master/poster/cvpr19_poster_template_1.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/framinmansour/Learning-Macroscopic-Brain-Connectomes-via-Group-Sparse-Factorization/raw/master/video/3minute_presentation.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Mapping structural brain connectomes for living human brains typically requires expert analysis and rule-based models on diffusion-weighted magnetic resonance imaging. A data-driven approach, however, could overcome limitations in such rule-based approaches and improve precision mappings for individuals. In this work, we explore a framework that facilitates applying learning algorithms to automatically extract brain connectomes. Using a tensor encoding, we design an objective with a group-regularizer that prefers biologically plausible fascicle structure. We show that the objective is convex and has unique solutions, ensuring identifiable connectomes for an individual. We develop an efficient optimization strategy for this extremely high-dimensional sparse problem, by reducing the number of parameters using a greedy algorithm designed specifically for the problem. We show that this greedy algorithm significantly improves on a standard greedy algorithm, called Orthogonal Matching Pursuit. We conclude with an analysis of the solutions found by our method, showing we can accurately reconstruct the diffusion information while maintaining contiguous fascicles with smooth direction changes.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13424">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #141</div>
            <div class="maincardBody">Disentangled behavioural representations</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15567">
                    Neuroscience and Cognitive Science -- Human or Animal Learning</a>
                </div>
            
            <div class="maincardFooter">Amir Dezfouli &middot; Hassan Ashtiani &middot; Omar Ghattas &middot; Richard Nock &middot; Peter Dayan &middot; Cheng Soon Ong</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1331" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://adezfouli.github.io/materials/dagndc-neurips2019/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://vimeo.com/368702071" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Individual characteristics in human decision-making are often
  quantified by fitting a parametric cognitive model to subjects&#x27;
  behavior and then studying differences between them in the associated
  parameter space.  However, these models often fit behavior more poorly
  than recurrent neural networks (RNNs), which are more flexible and
  make fewer assumptions about the underlying decision-making processes.
  Unfortunately, the parameter and latent activity spaces of RNNs are
  generally high-dimensional and uninterpretable, making it hard to use
  them to study individual differences.  Here, we
  show how to benefit from the flexibility of RNNs while representing
  individual differences in a low-dimensional and interpretable space.
  To achieve this, we propose a novel end-to-end learning framework in
  which an encoder is trained to map the behavior of subjects into a
  low-dimensional latent space. These low-dimensional representations
  are used to generate the parameters of individual RNNs corresponding
  to the decision-making process of each subject.  We introduce terms
  into the loss function that ensure that the latent dimensions are
  informative and disentangled, i.e.,
encouraged to have distinct effects on behavior. This allows them to
align with separate facets of
  individual differences. We illustrate the performance
   of our framework on synthetic data as well as a dataset including the behavior
   of patients with psychiatric disorders.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13762">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #153</div>
            <div class="maincardBody">From voxels to pixels and back: Self-supervision in natural-image reconstruction from fMRI</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15573">
                    Neuroscience and Cognitive Science -- Visual Perception</a>
                </div>
            
            <div class="maincardFooter">Roman Beliy &middot; Guy Gaziv &middot; Assaf Hoogi &middot; Francesca Strappini &middot; Tal Golan &middot; Michal Irani</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-3508" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.wisdom.weizmann.ac.il/~vision/ssfmri2im/resources/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=h2JhDAdaa-Q&feature=youtu.be" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Reconstructing observed images from fMRI brain recordings is challenging. Unfortunately, acquiring sufficient &#x27;&#x27;labeled&#x27;&#x27; pairs of {Image, fMRI} (i.e., images with their corresponding fMRI responses) to span the huge space of natural images is prohibitive for many reasons. We present a novel approach which, in addition to the scarce labeled data (training pairs), allows to train fMRI-to-image reconstruction networks also on &quot;unlabeled&quot; data (i.e., images without fMRI recording, and fMRI recording without images). The proposed model utilizes both an Encoder network (image-to-fMRI) and a Decoder network (fMRI-to-image). Concatenating these two networks back-to-back (Encoder-Decoder &amp; Decoder-Encoder) allows augmenting the training data with both types of unlabeled data. Importantly, it allows training on the unlabeled test-fMRI data. This self-supervision adapts the reconstruction network to the new input test-data, despite its deviation from the statistics of the scarce training data.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14145">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #184</div>
            <div class="maincardBody">Structured Graph Learning Via Laplacian Spectral Constraints</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15578">
                    Probabilistic Methods -- Graphical Models</a>
                </div>
            
            <div class="maincardFooter">Sandeep Kumar &middot; Jiaxi Ying &middot; Jose Vinicius de Miranda Cardoso &middot; Daniel Palomar</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6220" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://palomar.home.ece.ust.hk/papers/2019/KumarYingCardosoPalomar-NIPS2019-slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/klAqFvyQx7k" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Learning a graph with a specific structure is essential for interpretability and identification of the relationships among data. But structured graph learning from observed samples is an NP-hard combinatorial problem. In this paper, we first show, for a set of important graph families it is possible to convert the combinatorial constraints of structure into eigenvalue constraints of the graph Laplacian matrix. Then we introduce a unified graph learning framework lying at the integration of the spectral properties of the Laplacian matrix with Gaussian graphical modeling, which is capable of learning structures of a large class of graph families. The proposed algorithms are provably convergent and practically amenable for big-data specific tasks. Extensive numerical experiments with both synthetic and real datasets demonstrate the effectiveness of the proposed methods. An R package containing codes for all the experimental results is submitted as a supplementary file.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13979">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #197</div>
            <div class="maincardBody">Language as an Abstraction for Hierarchical Deep Reinforcement Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15582">
                    Reinforcement Learning and Planning -- Hierarchical RL</a>
                </div>
            
            <div class="maincardFooter">YiDing Jiang &middot; Shixiang (Shane) Gu &middot; Kevin Murphy &middot; Chelsea Finn</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5017" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1VMP42q8vlZMsAkS4ZcjkyQ4IYNjF5rOJ" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1rFzT0sIcqXD1iHITTb9QMJ1fB9x6c1-F" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1tvJ6CsEdskbRIA2BFLxSgDqjbm1BaaRt" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Solving complex, temporally-extended tasks is a long-standing problem in reinforcement learning (RL). We hypothesize that one critical element of solving such problems is the notion of compositionality. With the ability to learn sub-skills that can be composed to solve longer tasks, i.e. hierarchical RL, we can acquire temporally-extended behaviors. However, acquiring effective yet general abstractions for hierarchical RL is remarkably challenging. In this paper, we propose to use language as the abstraction, as it provides unique compositional structure, enabling fast learning and combinatorial generalization, while retaining tremendous flexibility, making it suitable for a variety of problems. Our approach learns an instruction-following low-level policy and a high-level policy that can reuse abstractions across tasks, in essence, permitting agents to reason using structured language. To study compositional task learning, we introduce an open-source object interaction environment built using the MuJoCo physics engine and the CLEVR engine. We find that, using our approach, agents can learn to solve to diverse, temporally-extended tasks such as object sorting and multi-object rearrangement, including from raw pixel observations. Our analysis find that the compositional nature of language is critical for learning and systematically generalizing sub-skills in comparison to non-compositional abstractions that use the same supervision.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13452">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #198</div>
            <div class="maincardBody">Learning Robust Options by Conditional Value at Risk Optimization</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15582">
                    Reinforcement Learning and Planning -- Hierarchical RL</a>
                </div>
            
            <div class="maincardFooter">Takuya Hiraoka &middot; Takahisa Imagawa &middot; Tatsuya Mori &middot; Takashi Onishi &middot; Yoshimasa Tsuruoka</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1504" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1fINDAh_Vvrr_GJZQFWK-Q7DgUV497cQ5" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1DRmIaK5VomCey70rKD_5DgX2Jm_1rFlo/view" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Options are generally learned by using an inaccurate environment model (or simulator), which contains uncertain model parameters. 
While there are several methods to learn options that are robust against the uncertainty of model parameters, these methods only consider either the worst case or the average (ordinary) case for learning options. 
This limited consideration of the cases often produces options that do not work well in the unconsidered case. 
In this paper, we propose a conditional value at risk (CVaR)-based method to learn options that work well in both the average and worst cases. 
We extend the CVaR-based policy gradient method proposed by Chow and Ghavamzadeh (2014) to deal with robust Markov decision processes and then apply the extended method to learning robust options. 
We conduct experiments to evaluate our method in multi-joint robot control tasks (HopperIceBlock, Half-Cheetah, and Walker2D). 
Experimental results show that our method produces options that 1) give better worst-case performance than the options learned only to minimize the average-case loss, and 2) give better average-case performance than the options learned only to minimize the worst-case loss. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13973">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #226</div>
            <div class="maincardBody">Multiclass Performance Metric Elicitation</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15585">
                    Theory -- Learning Theory</a>
                </div>
            
            <div class="maincardFooter">Gaurush Hiranandani &middot; Shant Boodaghians &middot; Ruta Mehta &middot; Sanmi Koyejo</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4994" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/drive/folders/1AWZ6xvSUwNGQYeYzI2yf-MYPvgnba8YJ?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/drive/folders/1AWZ6xvSUwNGQYeYzI2yf-MYPvgnba8YJ?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/drive/folders/1AWZ6xvSUwNGQYeYzI2yf-MYPvgnba8YJ?usp=sharing" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Metric Elicitation is a principled framework for selecting the performance metric that best reflects implicit user preferences. However, available strategies have so far been limited to binary classification. In this paper, we propose novel strategies for eliciting multiclass classification performance metrics using only relative preference feedback. We also show that the strategies are robust to both finite sample and feedback noise. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15762">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Ballroom C  </div>
            <div class="maincardBody">Poincaré Recurrence, Cycles and Spurious Equilibria in Gradient-Descent-Ascent for Non-Convex Non-Concave Zero-Sum Games</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15758">
                    Track 4 Session 4</a>
                </div>
            
            <div class="maincardFooter">Emmanouil-Vasileios Vlatakis-Gkaragkounis &middot; Lampros Flokas &middot; Georgios Piliouras</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5517" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.columbia.edu/~emvlatakis/Posters/Poincare_Recurrence_Cycles_and_Spurious_Equilibria_in_Gradient-Descent-Ascent_for_Non-Convex_Non-Concave_Zero-Sum_Games.html" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15762.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.columbia.edu/~emvlatakis/Presentations/Poincare_Recurrence_Cycles_and_Spurious_Equilibria_in_Gradient-Descent-Ascent_for_Non-Convex_Non-Concave_Zero-Sum_Games.html" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.columbia.edu/~emvlatakis/Videos/Poincare_Recurrence_Cycles_and_Spurious_Equilibria_in_Gradient-Descent-Ascent_for_Non-Convex_Non-Concave_Zero-Sum_Games.html" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We study a wide class of non-convex non-concave min-max games that generalizes over standard bilinear zero-sum games. In this class, players control the inputs of a smooth function whose output is being applied to a bilinear zero-sum game. This class of games is motivated by the  indirect nature of the competition in
Generative Adversarial Networks, where players control the parameters of a neural network while the actual competition happens between the distributions that the generator and discriminator capture. We establish theoretically, that depending on the specific instance of the problem gradient-descent-ascent dynamics  can exhibit a variety of behaviors antithetical to convergence to the game theoretically meaningful min-max solution. Specifically, different forms of recurrent behavior (including periodicity and Poincar\&#x27;{e} recurrence) are possible as well as convergence to spurious (non-min-max) equilibria for a positive measure of initial conditions. At the technical level, our analysis combines tools from optimization theory, game theory and dynamical systems. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15767">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Ballroom C  </div>
            <div class="maincardBody">McDiarmid-Type Inequalities for Graph-Dependent Variables and Stability Bounds</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15758">
                    Track 4 Session 4</a>
                </div>
            
            <div class="maincardFooter">Rui (Ray) Zhang &middot; Xingwu Liu &middot; Yuyi Wang &middot; Liwei Wang</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5823" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15767.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://rui-ray-zhang.github.io/NIPS/NIPS_slide.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://rui-ray-zhang.github.io/NIPS/NIPS.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >A crucial assumption in most statistical learning theory is that samples are independently and identically distributed (i.i.d.). However, for many real applications, the i.i.d. assumption does not hold. We consider learning problems in which examples are dependent and their dependency relation is characterized by a graph. To establish algorithm-dependent generalization theory for learning with non-i.i.d. data, we first prove novel McDiarmid-type concentration inequalities for Lipschitz functions of graph-dependent random variables. We show that concentration relies on the forest complexity of the graph, which characterizes the strength of the dependency. We demonstrate that for many types of dependent data, the forest complexity is small and thus implies good concentration. Based on our new inequalities we are able to build stability bounds for learning from graph-dependent data.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15880">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall C + B3  </div>
            <div class="maincardBody">Optimal Sparse Decision Trees</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15870">
                    Track 1 Session 4</a>
                </div>
            
            <div class="maincardFooter">Xiyang Hu &middot; Cynthia Rudin &middot; Margo Seltzer</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-3960" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/xiyanghu/OSDT/blob/master/doc/OSDT_NIPS_Poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15880.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/xiyanghu/OSDT/blob/master/doc/NeurIPSSlides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=UMjMQaH508M&feature=youtu.be" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Decision tree algorithms have been among the most popular algorithms for interpretable (transparent) machine learning since the early 1980&#x27;s. The problem that has plagued decision tree algorithms since their inception is their lack of optimality, or lack of guarantees of closeness to optimality: decision tree algorithms are often greedy or myopic, and sometimes produce unquestionably suboptimal models. Hardness of decision tree optimization is both a theoretical and practical obstacle, and even careful mathematical programming approaches have not been able to solve these problems efficiently. This work introduces the first practical algorithm for optimal decision trees for binary variables. The algorithm is a co-design of analytical bounds that reduce the search space and modern systems techniques, including data structures and a custom bit-vector library. We highlight possible steps to improving the scalability and speed of future generations of this algorithm based on insights from our theory and experiments.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14552">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #15</div>
            <div class="maincardBody">Optimal Sparse Decision Trees</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15588">
                    Algorithms -- Classification</a>
                </div>
            
            <div class="maincardFooter">Xiyang Hu &middot; Cynthia Rudin &middot; Margo Seltzer</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-3960" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/xiyanghu/OSDT/blob/master/doc/OSDT_NIPS_Poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/xiyanghu/OSDT/blob/master/doc/NeurIPSSlides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=UMjMQaH508M&feature=youtu.be" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Decision tree algorithms have been among the most popular algorithms for interpretable (transparent) machine learning since the early 1980&#x27;s. The problem that has plagued decision tree algorithms since their inception is their lack of optimality, or lack of guarantees of closeness to optimality: decision tree algorithms are often greedy or myopic, and sometimes produce unquestionably suboptimal models. Hardness of decision tree optimization is both a theoretical and practical obstacle, and even careful mathematical programming approaches have not been able to solve these problems efficiently. This work introduces the first practical algorithm for optimal decision trees for binary variables. The algorithm is a co-design of analytical bounds that reduce the search space and modern systems techniques, including data structures and a custom bit-vector library. Our experiments highlight advantages in scalability, speed, and proof of optimality.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14034">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #24</div>
            <div class="maincardBody">Unsupervised Meta-Learning for Few-Shot Image Classification</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15590">
                    Algorithms -- Few-Shot Learning</a>
                </div>
            
            <div class="maincardFooter">Siavash Khodadadeh &middot; Ladislau Boloni &middot; Mubarak Shah</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5350" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/siavash-khodadadeh/MetaLearning-TF2.0/raw/master/UMTRA_Paper/Poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/siavash-khodadadeh/MetaLearning-TF2.0/raw/master/UMTRA_Paper/Presentation.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/siavash-khodadadeh/MetaLearning-TF2.0/raw/master/UMTRA_Paper/VideoPresentation.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Few-shot or one-shot learning of classifiers requires a significant inductive bias towards the type of task to be learned. One way to acquire this is by meta-learning on tasks similar to the target task. In this paper, we propose UMTRA, an algorithm that performs unsupervised, model-agnostic meta-learning for classification tasks.
 The meta-learning step of UMTRA is performed on a flat collection of unlabeled images. While we assume that these images can be grouped into a diverse set of classes and are relevant to the target task, no explicit information about the classes or any labels are needed.  UMTRA uses random sampling and augmentation to create synthetic training tasks for meta-learning phase. Labels are only needed at the final target task learning step, and they can be as little as one sample per class.
 On the Omniglot and Mini-Imagenet few-shot learning benchmarks, UMTRA outperforms every tested approach based on unsupervised learning of representations, while alternating for the best performance with the recent CACTUs algorithm. Compared to supervised model-agnostic meta-learning approaches, UMTRA trades off some classification accuracy for a reduction in the required labels of several orders of magnitude.
</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13536">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #44</div>
            <div class="maincardBody">MCP: Learning Composable Hierarchical Control with Multiplicative Compositional Policies</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15593">
                    Algorithms -- Multitask and Transfer Learning</a>
                </div>
            
            <div class="maincardFooter">Xue Bin Peng &middot; Michael Chang &middot; Grace Zhang &middot; Pieter Abbeel &middot; Sergey Levine</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2016" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/HLD6H2eJK1E" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Humans are able to perform a myriad of sophisticated tasks by drawing upon skills acquired through prior experience. For autonomous agents to have this capability, they must be able to extract reusable skills from past experience that can be recombined in new ways for subsequent tasks. Furthermore, when controlling complex high-dimensional morphologies, such as humanoid bodies, tasks often require coordination of multiple skills simultaneously. Learning discrete primitives for every combination of skills quickly becomes prohibitive. Composable primitives that can be recombined to create a large variety of behaviors can be more suitable for modeling this combinatorial explosion. In this work, we propose multiplicative compositional policies (MCP), a method for learning reusable motor skills that can be composed to produce a range of complex behaviors. Our method factorizes an agent&#x27;s skills into a collection of primitives, where multiple primitives can be activated simultaneously via multiplicative composition. This flexibility allows the primitives to be transferred and recombined to elicit new behaviors as necessary for novel tasks. We demonstrate that MCP is able to extract composable skills for highly complex simulated characters from pre-training tasks, such as motion imitation, and then reuse these skills to solve challenging continuous control tasks, such as dribbling a soccer ball to a goal, and picking up an object and transporting it to a target location.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13594">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #47</div>
            <div class="maincardBody">Uncertainty-based Continual Learning with Adaptive Regularization</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15593">
                    Algorithms -- Multitask and Transfer Learning</a>
                </div>
            
            <div class="maincardFooter">Hongjoon Ahn &middot; Sungmin Cha &middot; Donggyu Lee &middot; Taesup Moon</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2447" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/csm9493/UCL/blob/master/links/NeurIPS2019_UCL_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/project-page-of-ucl" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We introduce a new neural network-based continual learning algorithm, dubbed as Uncertainty-regularized Continual Learning (UCL), which builds on traditional Bayesian online learning framework with variational inference. We focus on two significant drawbacks of the recently proposed regularization-based methods: a) considerable additional memory cost for determining the per-weight regularization strengths and b) the absence of gracefully forgetting scheme, which can prevent performance degradation in learning new tasks. In this paper, we show UCL can solve these two problems by introducing a fresh interpretation on the Kullback-Leibler (KL) divergence term of the variational lower bound for Gaussian mean-field approximation. Based on the interpretation, we propose the notion of node-wise uncertainty, which drastically reduces the number of additional parameters for implementing per-weight regularization. Moreover, we devise two additional regularization terms that enforce \emph{stability} by freezing important parameters for past tasks and allow \emph{plasticity} by controlling the actively learning parameters for a new task. Through extensive experiments, we show UCL convincingly outperforms most of recent state-of-the-art baselines not only on popular supervised learning benchmarks, but also on challenging lifelong reinforcement learning tasks. The source code of our algorithm is available at  https://github.com/csm9493/UCL.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13853">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #71</div>
            <div class="maincardBody">A Unifying Framework for Spectrum-Preserving Graph Sparsification and Coarsening</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15597">
                    Algorithms -- Spectral Methods</a>
                </div>
            
            <div class="maincardFooter">Gecia Bravo-Hermsdorff &middot; Lee Gunderson</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4192" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/playlist?list=PLmfiQcz2q6d0Qeq7IBJ1izsMIWdVwM5Q0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >How might one &quot;reduce&quot; a graph? 
That is, generate a smaller graph that preserves the global structure at the expense of discarding local details?  
There has been extensive work on both graph sparsification (removing edges) and graph coarsening (merging nodes, often by edge contraction); however, these operations are currently treated separately.  
Interestingly, for a planar graph, edge deletion corresponds to edge contraction in its planar dual (and more generally, for a graphical matroid and its dual).  
Moreover, with respect to the dynamics induced by the graph Laplacian (e.g., diffusion), deletion and contraction are physical manifestations of two reciprocal limits: edge weights of $0$ and $\infty$, respectively.  
In this work, we provide a unifying framework that captures both of these operations, allowing one to simultaneously sparsify and coarsen a graph while preserving its large-scale structure.  
The limit of infinite edge weight is rarely considered, as many classical notions of graph similarity diverge.  However, its algebraic, geometric, and physical interpretations are reflected in the Laplacian pseudoinverse $L^\dagger$, which remains finite in this limit.  
Motivated by this insight, we provide a probabilistic algorithm that reduces graphs while preserving $L^\dagger$, using an unbiased procedure that minimizes its variance. 
We compare our algorithm with several existing sparsification and coarsening algorithms using real-world datasets, and demonstrate that it more accurately preserves the large-scale structure. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14428">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #75</div>
            <div class="maincardBody">DeepWave: A Recurrent Neural-Network for Real-Time Acoustic Imaging</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15598">
                    Applications -- Audio and Speech Processing</a>
                </div>
            
            <div class="maincardFooter">Matthieu SIMEONI &middot; Sepand Kashani &middot; Paul Hurley &middot; Martin Vetterli</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-8774" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://infoscience.epfl.ch/record/265765/files/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=PwB3CS2rHdI" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We propose a recurrent neural-network for real-time reconstruction of acoustic camera spherical maps. The network, dubbed DeepWave, is both physically and algorithmically motivated: its recurrent architecture mimics iterative solvers from convex optimisation, and its parsimonious parametrisation is based on the natural structure of acoustic imaging problems.
Each network layer applies successive filtering, biasing and activation steps to its input, which can be interpreted as generalised deblurring and sparsification steps. To comply with the irregular geometry of spherical maps, filtering operations are implemented efficiently by means of graph signal processing techniques.
Unlike commonly-used imaging network architectures, DeepWave is moreover capable of directly processing the complex-valued raw microphone correlations, learning how to optimally back-project these into a spherical map. We propose moreover a smart physically-inspired initialisation scheme that attains much faster training and higher performance than random initialisation.
Our real-data experiments show DeepWave has similar computational speed to the state-of-the-art delay-and-sum imager with vastly superior resolution. While developed primarily for acoustic cameras, DeepWave could easily be adapted to neighbouring  signal processing fields, such as radio astronomy, radar and sonar.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13645">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #79</div>
            <div class="maincardBody">Few-shot Video-to-Video Synthesis</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15555">
                    Applications -- Computer Vision</a>
                </div>
            
            <div class="maincardFooter">Ting-Chun Wang &middot; Ming-Yu Liu &middot; Andrew Tao &middot; Guilin Liu &middot; Bryan Catanzaro &middot; Jan Kautz</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2765" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=8AZBuyEuDqc&feature=youtu.be" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Video-to-video synthesis (vid2vid) aims at converting an input semantic video, such as videos of human poses or segmentation masks, to an output photorealistic video. While the state-of-the-art of vid2vid has advanced significantly, existing approaches share two major limitations. First, they are data-hungry. Numerous images of a target human subject or a scene are required for training. Second, a learned model has limited generalization capability. A pose-to-human vid2vid model can only synthesize poses of the single person in the training set. It does not generalize to other humans that are not in the training set. To address the limitations, we propose a few-shot vid2vid framework, which learns to synthesize videos of previously unseen subjects or scenes by leveraging few example images of the target at test time. Our model achieves this few-shot generalization capability via a novel network weight generation module utilizing an attention mechanism. We conduct extensive experimental validations with comparisons to strong baselines using several large-scale video datasets including human-dancing videos, talking-head videos, and street-scene videos. The experimental results verify the effectiveness of the proposed framework in addressing the two limitations of existing vid2vid approaches.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13347">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #81</div>
            <div class="maincardBody">Image Synthesis with a Single (Robust) Classifier</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15555">
                    Applications -- Computer Vision</a>
                </div>
            
            <div class="maincardFooter">Shibani Santurkar &middot; Andrew Ilyas &middot; Dimitris Tsipras &middot; Logan Engstrom &middot; Brandon Tran &middot; Aleksander Madry</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-753" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://people.csail.mit.edu/tsipras/synthesis_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/l3SoeIIjxTM" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We show that the basic classification framework alone can be used to tackle some of the most challenging tasks in image synthesis. In contrast to other state-of-the-art approaches, the toolkit we develop is rather minimal: it uses a single, off-the-shelf classifier for all these tasks. The crux of our approach is that we train this classifier to be adversarially robust. It turns out that adversarial robustness is precisely what we need to directly manipulate salient features of the input. Overall, our findings demonstrate the utility of robustness in the broader machine learning context.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13553">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #91</div>
            <div class="maincardBody">Domes to Drones: Self-Supervised Active Triangulation for 3D Human Pose Reconstruction</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15555">
                    Applications -- Computer Vision</a>
                </div>
            
            <div class="maincardFooter">Aleksis Pirinen &middot; Erik Gärtner &middot; Cristian Sminchisescu</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2164" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://lu.app.box.com/s/49wx5vfkpp5pkhp74ni497q5x4sfyzh3" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://lu.app.box.com/s/xd1nidkirdlg0htlkyomq33ipk01k6gk" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Existing state-of-the-art estimation systems can detect 2d poses of multiple people in images quite reliably. In contrast, 3d pose estimation from a single image is ill-posed due to occlusion and depth ambiguities. Assuming access to multiple cameras, or given an active system able to position itself to observe the scene from multiple viewpoints, reconstructing 3d pose from 2d measurements becomes well-posed within the framework of standard multi-view geometry. Less clear is what is an informative set of viewpoints for accurate 3d reconstruction, particularly in complex scenes, where people are occluded by others or by scene objects. In order to address the view selection problem in a principled way, we here introduce ACTOR, an active triangulation agent for 3d human pose reconstruction. Our fully trainable agent consists of a 2d pose estimation network (any of which would work) and a deep reinforcement learning-based policy for camera viewpoint selection. The policy predicts observation viewpoints, the number of which varies adaptively depending on scene content, and the associated images are fed to an underlying pose estimator. Importantly, training the view selection policy requires no annotations -- given a pre-trained 2d pose estimator, ACTOR is trained in a self-supervised manner. In extensive evaluations on complex multi-people scenes filmed in a Panoptic dome, under multiple viewpoints, we compare our active triangulation agent to strong multi-view baselines, and show that ACTOR produces significantly more accurate 3d pose reconstructions. We also provide a proof-of-concept experiment indicating the potential of connecting our view selection policy to a physical drone observer.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13303">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #98</div>
            <div class="maincardBody">Multiway clustering via tensor block models  </div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15600">
                    Applications -- Matrix and Tensor Factorization</a>
                </div>
            
            <div class="maincardFooter">Miaoyan Wang &middot; Yuchen Zeng</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-365" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/s/577rmkrpynl2kkk/tbm_poster.pdf?dl=0" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/s/xzfo4qevpv52yzd/Multiway_clustering_via_tensor_block_models__1_.pdf?dl=0" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/b3sOTLwxHMY" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We consider the problem of identifying multiway block structure from a large noisy tensor. Such problems arise frequently in applications such as genomics, recommendation system, topic modeling, and sensor network localization. We propose a tensor block model, develop a unified least-square estimation, and obtain the theoretical accuracy guarantees for multiway clustering. The statistical convergence of the estimator is established, and we show that the associated clustering procedure achieves partition consistency. A sparse regularization is further developed for identifying important blocks with elevated means. The proposal handles a broad range of data types, including binary, continuous, and hybrid observations. Through simulation and application to two real datasets, we demonstrate the outperformance of our approach over previous methods.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13644">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #120</div>
            <div class="maincardBody">Visual Concept-Metaconcept Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15603">
                    Applications -- Visual Question Answering</a>
                </div>
            
            <div class="maincardFooter">Chi Han &middot; Jiayuan Mao &middot; Chuang Gan &middot; Josh Tenenbaum &middot; Jiajun Wu</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2764" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1-td0BQp2tcSHwMVPCIOgOBLEyRph4dak" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1yP5gYyd8-Tx8SKvd1bWbO2H7prZO1Ndn" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Humans reason with concepts and metaconcepts: we recognize red and blue from visual input; we also understand that they are colors, i.e., red is an instance of color. In this paper, we propose the visual concept-metaconcept learner (VCML) for joint learning of concepts and metaconcepts from images and associated question-answer pairs. The key is to exploit the bidirectional connection between visual concepts and metaconcepts. Visual representations provide grounding cues for predicting relations between unseen pairs of concepts. Knowing that red and blue are instances of color, we generalize to the fact that green is also an instance of color since they all categorize the hue of objects. Meanwhile, knowledge about metaconcepts empowers visual concept learning from limited, noisy, and even biased data. From just a few examples of purple cubes we can understand a new color purple, which resembles the hue of the cubes instead of the shape of them. Evaluation on both synthetic and real-world datasets validates our claims.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14229">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #122</div>
            <div class="maincardBody">Neuropathic Pain Diagnosis Simulator for Causal Discovery Algorithm Evaluation</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15604">
                    Data, Challenges, Implementations, and Software -- Benchmarks</a>
                </div>
            
            <div class="maincardFooter">Ruibo Tu &middot; Kun Zhang &middot; Bo Bertilson &middot; Hedvig Kjellstrom &middot; Cheng Zhang</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6955" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/drive/folders/1Pup1r-R8FCseGXfHyltEevo3nQB6Edsg?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/1UvVnIbjSX8" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Discovery of causal relations from observational data is essential for many disciplines of science and real-world applications. However, unlike other machine learning algorithms, whose development has been greatly fostered by a large amount of available benchmark datasets, causal discovery algorithms are notoriously difficult to be systematically evaluated because few datasets with known ground-truth causal relations are available. In this work, we handle the problem of evaluating causal discovery algorithms by building a flexible simulator in the medical setting. We develop a neuropathic pain diagnosis simulator, inspired by the fact that the biological processes of neuropathic pathophysiology are well studied with well-understood causal influences. Our simulator exploits the causal graph of the neuropathic pain pathology and its parameters in the generator are estimated from real-life patient cases. We show that the data generated from our simulator have similar statistics as real-world data. As a clear advantage, the simulator can produce infinite samples without jeopardizing the privacy of real-world patients. Our simulator provides a natural tool for evaluating various types of causal discovery algorithms, including those to deal with practical issues in causal discovery, such as unknown confounders, selection bias, and missing data. Using our simulator, we have evaluated extensively causal discovery algorithms under various settings. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14391">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #143</div>
            <div class="maincardBody">Icebreaker: Element-wise Efficient Information Acquisition with a Bayesian Deep Latent Gaussian Model</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15561">
                    Deep Learning -- Generative Models</a>
                </div>
            
            <div class="maincardFooter">Wenbo Gong &middot; Sebastian Tschiatschek &middot; Sebastian Nowozin &middot; Richard Turner &middot; José Miguel Hernández-Lobato &middot; Cheng Zhang</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-8401" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?feature=%3Dyoutu.be&v=UST9Uhg8CkA" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >In this paper, we address the ice-start problem, i.e., the challenge of deploying machine learning models when only a little or no training data is initially available, and acquiring each feature element of data is associated with costs. This setting is representative of the real-world machine learning applications. For instance, in the health care domain, obtaining every single measurement comes with a cost. We propose Icebreaker, a principled framework for elementwise training data acquisition. Icebreaker introduces a full Bayesian Deep Latent Gaussian Model (BELGAM) with a novel inference method, which combines recent advances in amortized inference and stochastic gradient MCMC to enable fast and accurate posterior inference. By utilizing BELGAM’s ability to fully quantify model uncertainty, we also propose two information acquisition functions for imputation and active prediction problems. We demonstrate that BELGAM performs significantly better than previous variational autoencoder (VAE) based models, when the data set size is small, using both machine learning benchmarks and real world recommender systems and health-care applications. Moreover, Icebreaker not only demonstrates improved performance compared to baselines, but it is also capable of achieving better test performance with less training data available.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14280">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #148</div>
            <div class="maincardBody">ODE2VAE: Deep generative second order ODEs with Bayesian neural networks</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15561">
                    Deep Learning -- Generative Models</a>
                </div>
            
            <div class="maincardFooter">Cagatay Yildiz &middot; Markus Heinonen &middot; Harri Lahdesmaki</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-7407" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/cagatayyildiz/ODE2VAE" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We present Ordinary Differential Equation Variational Auto-Encoder (ODE2VAE), a latent second order ODE model for high-dimensional sequential data. Leveraging the advances in deep generative models, ODE2VAE can simultaneously learn the embedding of high dimensional trajectories and infer arbitrarily complex continuous-time latent dynamics. Our model explicitly decomposes the latent space into momentum and position components and solves a second order ODE system, which is in contrast to recurrent neural network (RNN) based time series models and recently proposed black-box ODE techniques. In order to account for uncertainty, we propose probabilistic latent ODE dynamics parameterized by deep Bayesian neural networks. We demonstrate our approach on motion capture, image rotation, and bouncing balls datasets. We achieve state-of-the-art performance in long term motion prediction and imputation tasks.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14005">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #156</div>
            <div class="maincardBody">Convergence-Rate-Matching Discretization of Accelerated Optimization Flows Through Opportunistic State-Triggered Control</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15608">
                    Optimization -- Convex Optimization</a>
                </div>
            
            <div class="maincardFooter">Miguel Vaquero &middot; Jorge Cortes</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5181" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/sh/6rygo2q0iwg2wbr/AABnfjDC5XlKfpEv2rHyO_P3a?dl=0" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/sh/aildrjci7n55359/AAB1A2jEg66lgs2k8s2GWuWAa?dl=0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >A recent body of exciting work seeks to shed light on the behavior of accelerated methods in optimization via high-resolution differential equations. These differential equations are continuous counterparts of the discrete-time optimization algorithms, and their convergence properties can be characterized using the powerful tools provided by classical Lyapunov stability analysis. An outstanding question of pivotal importance is how to discretize these continuous flows while maintaining their convergence rates. This paper provides a novel approach through the idea of opportunistic state-triggered control. We take advantage of the Lyapunov functions employed to characterize the rate of convergence of high-resolution differential equations to design variable-stepsize forward-Euler discretizations that preserve the Lyapunov decay of the original dynamics. The philosophy of our approach is not limited to forward-Euler discretizations and may be combined with other integration schemes.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14031">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #157</div>
            <div class="maincardBody">Decentralized sketching of low rank matrices</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15608">
                    Optimization -- Convex Optimization</a>
                </div>
            
            <div class="maincardFooter">Rakshith Sharma Srinivasa &middot; Kiryung Lee &middot; Marius  Junge &middot; Justin Romberg</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5343" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/sh/f2cbabzpbxk2ltl/AACf85SVwrCfvl9pg2bBnGe0a?dl=0" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/sh/kpl064804i9ks1y/AADxPFiVivRDgPlku0lXX68na?dl=0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We address a low-rank matrix recovery problem where each column of a rank-r matrix X of size (d1,d2) is compressed beyond the point of recovery to size L with L &lt;&lt; d1. Leveraging the joint structure between the columns, we propose a method to recover the matrix to within an epsilon relative error in the Frobenius norm from a total of O(r(d_1 + d_2)\log^6(d_1 + d_2)/\epsilon^2) observations. This guarantee holds uniformly for all incoherent matrices of rank r. In our method, we propose to use a novel matrix norm called the mixed-norm along with the maximum l2 norm of the columns to design a novel convex relaxation for low-rank recovery that is tailored to our observation model. We also show that our proposed mixed-norm, the standard nuclear norm, and the max-norm are particular instances of convex regularization of low-rankness via tensor norms. Finally, we provide a scalable ADMM algorithm for the mixed-norm based method and demonstrate its empirical performance via large-scale simulations. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14193">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #160</div>
            <div class="maincardBody">Fast and Accurate Stochastic Gradient Estimation</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15608">
                    Optimization -- Convex Optimization</a>
                </div>
            
            <div class="maincardFooter">Beidi Chen &middot; Yingchen Xu &middot; Anshumali Shrivastava</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6671" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1VRSKSXdHSQ0-HiYzVLUAHhR_GvTeHuMh" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1pUVctPvxz0wVNjWx3-AOEJUfpQ2TgqWy" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1GJAErrv_7iAvzqhJEcfZd2vGVnQdaA_A" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Stochastic Gradient Descent or SGD is the most popular optimization algorithm for large-scale problems. SGD estimates the gradient by uniform sampling with sample size one. There have been several other works that suggest faster epoch-wise convergence by using weighted non-uniform sampling for better gradient estimates. Unfortunately, the per-iteration cost of maintaining this adaptive distribution for gradient estimation is more than calculating the full gradient itself, which we call the chicken-and-the-egg loop. As a result, the false impression of faster convergence in iterations, in reality, leads to slower convergence in time. In this paper, we break this barrier by providing the first demonstration of a scheme, Locality sensitive hashing (LSH) sampled Stochastic Gradient Descent (LGD), which leads to superior gradient estimation while keeping the sampling cost per iteration similar to that of the uniform sampling. Such an algorithm is possible due to the sampling view of LSH, which came to light recently. As a consequence of superior and fast estimation, we reduce the running time of all existing gradient descent algorithms, that relies on gradient estimates including Adam, Ada-grad, etc. We demonstrate the effectiveness of our proposal with experiments on linear models as well as the non-linear BERT, which is a recent popular deep learning based language representation model.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14340">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #161</div>
            <div class="maincardBody">Fast, Provably convergent IRLS Algorithm for p-norm Linear Regression</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15608">
                    Optimization -- Convex Optimization</a>
                </div>
            
            <div class="maincardFooter">Deeksha Adil &middot; Richard Peng &middot; Sushant Sachdeva</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-7941" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=lG3ycfrK88g&feature=youtu.be" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Linear regression in L_p-norm is a canonical optimization problem that arises in several applications, including sparse recovery, semi-supervised learning, and signal processing. Generic convex optimization algorithms for solving L_p-regression are slow in practice. Iteratively Reweighted Least Squares (IRLS) is an easy to implement family of algorithms for solving these problems that has been studied for over 50 years. However, these algorithms often diverge for p &gt; 3, and since the work of Osborne (1985), it has been an open problem whether there is an IRLS algorithm that converges for p &gt; 3. We propose p-IRLS, the first IRLS algorithm that provably converges geometrically for any p \in [2,\infty). Our algorithm is simple to implement and is guaranteed to find a high accuracy solution in a sub-linear number of iterations. Our experiments demonstrate that it performs even better than our theoretical bounds, beats the standard Matlab/CVX implementation for solving these problems by 10–50x, and is the fastest among available implementations in the high-accuracy regime.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14015">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #167</div>
            <div class="maincardBody">Stochastic Variance Reduced Primal Dual Algorithms for Empirical Composition Optimization</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15608">
                    Optimization -- Convex Optimization</a>
                </div>
            
            <div class="maincardFooter">Adithya M Devraj &middot; Jianshu Chen</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5233" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/adidevraj/SVRPDA/wiki/Poster" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/adidevraj/SVRPDA/wiki/Slides" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/adidevraj/SVRPDA/wiki/Video" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We consider a generic empirical composition optimization problem, where there are empirical averages present both outside and inside nonlinear loss functions. Such a problem is of interest in various machine learning applications, and cannot be directly solved by standard methods such as stochastic gradient descent (SGD). We take a novel approach to solving this problem by reformulating the original minimization objective into an equivalent min-max objective, which brings out all the empirical averages that are originally inside the nonlinear loss functions. We exploit the rich structures of the reformulated problem and develop a stochastic primal-dual algorithms, SVRPDA-I, to solve the problem efficiently. We carry out extensive theoretical analysis of the proposed algorithm, obtaining the convergence rate, the total computation complexity and the storage complexity. In particular, the algorithm is shown to converge at a linear rate when the problem is strongly convex. Moreover, we also develop an approximate version of the algorithm, named SVRPDA-II, which further reduces the memory requirement. Finally, we evaluate the performance of our algorithms on several real-world benchmarks and experimental results show that they significantly outperform existing techniques.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14404">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #170</div>
            <div class="maincardBody">Function-Space Distributions over Kernels</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15609">
                    Probabilistic Methods -- Gaussian Processes</a>
                </div>
            
            <div class="maincardFooter">Gregory Benton &middot; Wesley Maddox &middot; Jayson Salkey &middot; Julio Albinati &middot; Andrew Gordon Wilson</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-8540" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/wjmaddox/spectralgp/blob/master/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://wjmaddox.github.io/assets/fkl-slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://cims.nyu.edu/~andrewgw/spectralgp
https://g-benton.github.io/spectralgp/" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >	Gaussian processes are flexible function approximators, with inductive biases controlled by a covariance kernel. Learning the kernel is the key to representation learning and strong predictive performance. In this paper, we develop functional kernel learning (FKL) to directly infer functional posteriors over kernels. In particular, we place a transformed Gaussian process over a spectral density, to induce a non-parametric distribution over kernel functions. The resulting approach enables learning of rich representations, with support for any stationary kernel, uncertainty over the values of the kernel, and an interpretable specification of a prior directly over kernels, without requiring sophisticated initialization or manual intervention. We perform inference through elliptical slice sampling, which is especially well suited to marginalizing posteriors with the strongly correlated priors typical to function space modeling. We develop our approach for non-uniform, large-scale, multi-task, and multidimensional data, and show promising performance in a wide range of settings, including interpolation, extrapolation, and kernel recovery experiments.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14587">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #221</div>
            <div class="maincardBody">Poincaré Recurrence, Cycles and Spurious Equilibria in Gradient-Descent-Ascent for Non-Convex Non-Concave Zero-Sum Games</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15584">
                    Theory -- Game Theory and Computational Economics</a>
                </div>
            
            <div class="maincardFooter">Emmanouil-Vasileios Vlatakis-Gkaragkounis &middot; Lampros Flokas &middot; Georgios Piliouras</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5517" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.columbia.edu/~emvlatakis/Posters/Poincare_Recurrence_Cycles_and_Spurious_Equilibria_in_Gradient-Descent-Ascent_for_Non-Convex_Non-Concave_Zero-Sum_Games.html" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.columbia.edu/~emvlatakis/Presentations/Poincare_Recurrence_Cycles_and_Spurious_Equilibria_in_Gradient-Descent-Ascent_for_Non-Convex_Non-Concave_Zero-Sum_Games.html" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.columbia.edu/~emvlatakis/Videos/Poincare_Recurrence_Cycles_and_Spurious_Equilibria_in_Gradient-Descent-Ascent_for_Non-Convex_Non-Concave_Zero-Sum_Games.html" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We study a wide class of non-convex non-concave min-max games that generalizes over standard bilinear zero-sum games. In this class, players control the inputs of a smooth function whose output is being applied to a bilinear zero-sum game. This class of games is motivated by the  indirect nature of the competition in
Generative Adversarial Networks, where players control the parameters of a neural network while the actual competition happens between the distributions that the generator and discriminator capture. We establish theoretically, that depending on the specific instance of the problem gradient-descent-ascent dynamics  can exhibit a variety of behaviors antithetical to convergence to the game theoretically meaningful min-max solution. Specifically, different forms of recurrent behavior (including periodicity and Poincar\&#x27;{e} recurrence) are possible as well as convergence to spurious (non-min-max) equilibria for a positive measure of initial conditions. At the technical level, our analysis combines tools from optimization theory, game theory and dynamical systems. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14593">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #223</div>
            <div class="maincardBody">McDiarmid-Type Inequalities for Graph-Dependent Variables and Stability Bounds</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15614">
                    Theory -- Large Deviations and Asymptotic Analysis</a>
                </div>
            
            <div class="maincardFooter">Rui (Ray) Zhang &middot; Xingwu Liu &middot; Yuyi Wang &middot; Liwei Wang</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5823" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://rui-ray-zhang.github.io/NIPS/NIPS_slide.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://rui-ray-zhang.github.io/NIPS/NIPS.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >A crucial assumption in most statistical learning theory is that samples are independently and identically distributed (i.i.d.). However, for many real applications, the i.i.d. assumption does not hold. We consider learning problems in which examples are dependent and their dependency relation is characterized by a graph. To establish algorithm-dependent generalization theory for learning with non-i.i.d. data, we first prove novel McDiarmid-type concentration inequalities for Lipschitz functions of graph-dependent random variables. We show that concentration relies on the forest complexity of the graph, which characterizes the strength of the dependency. We demonstrate that for many types of dependent data, the forest complexity is small and thus implies good concentration. Based on our new inequalities we are able to build stability bounds for learning from graph-dependent data.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower oral" id="maincard_15882">
            <div class='pull-right maincardHeader maincardType'>Oral</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall C + B3  </div>
            <div class="maincardBody">Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15881">
                    Track 1 Session 5</a>
                </div>
            
            <div class="maincardFooter">Jonas Kubilius &middot; Martin Schrimpf &middot; Ha Hong &middot; Najib Majaj &middot; Rishi Rajalingham &middot; Elias Issa &middot; Kohitij Kar &middot; Pouya Bashivan &middot; Jonathan Prescott-Roy &middot; Kailyn Schmidt &middot; Aran Nayebi &middot; Daniel Bear &middot; Daniel Yamins &middot; James J DiCarlo</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6969" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/dicarlolab/neurips2019/blob/master/slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://cbmm.mit.edu/video/brain-object-recognition-high-performing-shallow-recurrent-anns" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Deep convolutional artificial neural networks (ANNs) are the leading class of candidate models of the mechanisms of visual processing in the primate ventral stream. While initially inspired by brain anatomy, over the past years, these ANNs have evolved from a simple eight-layer architecture in AlexNet to extremely deep and branching architectures, demonstrating increasingly better object categorization performance, yet bringing into question how brain-like they still are. In particular, typical deep models from the machine learning community are often hard to map onto the brain&#x27;s anatomy due to their vast number of layers and missing biologically-important connections, such as recurrence. Here we demonstrate that better anatomical alignment to the brain and high performance on machine learning as well as neuroscience measures do not have to be in contradiction. We developed CORnet-S, a shallow ANN with four anatomically mapped areas and recurrent connectivity, guided by Brain-Score, a new large-scale composite of neural and behavioral benchmarks for quantifying the functional fidelity of models of the primate ventral visual stream. Despite being significantly shallower than most models, CORnet-S is the top model on Brain-Score and outperforms similarly compact models on ImageNet. Moreover, our extensive analyses of CORnet-S circuitry variants reveal that recurrence is the main predictive factor of both Brain-Score and ImageNet top-1 performance. Finally, we report that the temporal evolution of the CORnet-S &quot;IT&quot; neural population resembles the actual monkey IT population dynamics. Taken together, these results establish CORnet-S, a compact, recurrent ANN, as the current best model of the primate ventral visual stream.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15772">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Ballroom C  </div>
            <div class="maincardBody">This Looks Like That: Deep Learning for Interpretable Image Recognition</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15769">
                    Track 4 Session 5</a>
                </div>
            
            <div class="maincardFooter">Chaofan Chen &middot; Oscar Li &middot; Daniel Tao &middot; Alina Barnett &middot; Cynthia Rudin &middot; Jonathan K Su</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4795" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15772.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/k3IQnRsl9U4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture -- prototypical part network (ProtoPNet), that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The model thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training without any annotations for parts of images. We demonstrate our method on the CUB-200-2011 dataset and the Stanford Cars dataset. Our experiments show that ProtoPNet can achieve comparable accuracy with its analogous non-interpretable counterpart, and when several ProtoPNets are combined into a larger network, it can achieve an accuracy that is on par with some of the best-performing deep models. Moreover, ProtoPNet provides a level of interpretability that is absent in other interpretable deep models.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15830">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall A  </div>
            <div class="maincardBody">Adversarial Training and Robustness for Multiple Perturbations</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15825">
                    Track 2 Session 5</a>
                </div>
            
            <div class="maincardFooter">Florian Tramer &middot; Dan Boneh</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-3146" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15830.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://floriantramer.com/docs/slides/multirobustness19_video.pptx" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=aUDkfVd3t_8" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Defenses against adversarial examples, such as adversarial training, are typically tailored to a single perturbation type (e.g., small $\ell_\infty$-noise). For other perturbations, these defenses offer no guarantees and, at times, even increase the model&#x27;s vulnerability.
Our aim is to understand the reasons underlying this robustness trade-off, and to train models that are simultaneously robust to multiple perturbation types.

We prove that a trade-off in robustness to different types of $\ell_p$-bounded and spatial perturbations must exist in a natural and simple statistical setting.
We corroborate our formal analysis by demonstrating similar robustness trade-offs on MNIST and CIFAR10. We propose new multi-perturbation adversarial training schemes, as well as an efficient attack for the $\ell_1$-norm, and use these to show that models trained against multiple attacks fail to achieve robustness competitive with that of models trained on each attack individually. 
In particular, we find that adversarial training with first-order $\ell_\infty, \ell_1$ and $\ell_2$ attacks on MNIST achieves merely $50\%$ robust accuracy, partly because of gradient-masking.
Finally, we propose affine attacks that linearly interpolate between perturbation types and further degrade the accuracy of adversarially trained models.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15775">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Ballroom C  </div>
            <div class="maincardBody">Multi-Criteria Dimensionality Reduction with Applications to Fairness</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15769">
                    Track 4 Session 5</a>
                </div>
            
            <div class="maincardFooter">Uthaipon Tantipongpipat &middot; Samira Samadi &middot; Mohit Singh &middot; Jamie Morgenstern &middot; Santosh Vempala</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-8678" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/uthaipon/multi-criteria-dimensionality-reduction" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15775.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/uthaipon/multi-criteria-dimensionality-reduction" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/aR64H5Jn0gY" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Dimensionality reduction is a classical technique widely used for data analysis. One foundational instantiation is Principal Component Analysis (PCA),
which minimizes the average reconstruction error. In this paper, we introduce the multi-criteria dimensionality reduction problem where we are given multiple objectives that need to be optimized simultaneously. As an application, our model captures several fairness criteria for dimensionality reduction such as the Fair-PCA problem introduced by Samadi et al. [NeurIPS18] and the Nash Social Welfare (NSW) problem. In the Fair-PCA problem, the input data is divided into k groups, and the goal is to find a single d-dimensional representation for all groups for which the maximum reconstruction error of any one group is minimized. In NSW the goal is to maximize the product of the  individual variances of the groups achieved by the common low-dimensinal space.

Our main result is an exact polynomial-time algorithm for the two-criteria dimensionality reduction problem when the two criteria are increasing concave functions. As an application of this result, we obtain a polynomial time algorithm for Fair-PCA for k=2 groups, resolving an open problem of Samadi et al.[NeurIPS18], and a polynomial time algorithm for NSW objective for k=2 groups.  We also give approximation algorithms for k&gt;2. Our technical contribution in the above results is to prove new low-rank properties of extreme point solutions to semi-definite programs. We conclude with the results of several experiments indicating improved performance and generalized application of our algorithm on real-world datasets.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13427">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #6</div>
            <div class="maincardBody">Integrating Bayesian and Discriminative Sparse Kernel Machines for  Multi-class Active Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15617">
                    Algorithms -- Active Learning</a>
                </div>
            
            <div class="maincardFooter">Weishi Shi &middot; Qi Yu</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1349" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1XZT7e0viIVeV9zilQ6RH3DE0zCtwhJM7" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1UOYwk5gQmoKRt3fFdVGCJ0IZq2Bu4A1T" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1awBUI9liuh28vfJWHlc2beoYm8Zfybm9" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We propose a novel active learning (AL) model that integrates Bayesian and discriminative kernel machines for fast and accurate multi-class data sampling. By joining a sparse Bayesian model and a maximum margin machine under a unified kernel machine committee (KMC), the proposed model is able to identify a small number of data samples that best represent the overall data space while accurately capturing the decision boundaries. The integration is conducted using the  maximum entropy discrimination framework, resulting in a joint objective function that contains generalized entropy as a regularizer. Such a property allows the proposed AL model to choose data samples that more effectively handle non-separable classification problems. Parameter learning is achieved through a principled optimization framework that leverages  convex duality and sparse structure of KMC to efficiently optimize the joint objective function. Key model parameters are used to design a novel sampling function  to choose data samples that can simultaneously improve multiple decision boundaries, making it an effective sampler for problems with a large number of classes. Experiments conducted over both synthetic and real data and comparison with competitive AL methods demonstrate the effectiveness of the proposed model. 
</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14009">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #33</div>
            <div class="maincardBody">Practical Two-Step Lookahead Bayesian Optimization</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15619">
                    Algorithms -- AutoML</a>
                </div>
            
            <div class="maincardFooter">Jian Wu &middot; Peter Frazier</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5204" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/wujian16/TwoStep-BayesOpt/tree/master/Presentation" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/wujian16/TwoStep-BayesOpt/tree/master/Presentation" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Expected improvement and other acquisition functions widely used in Bayesian optimization use a &quot;one-step&quot; assumption: they value objective function evaluations assuming no future evaluations will be performed. Because we usually evaluate over multiple steps, this assumption may leave substantial room for improvement. Existing theory gives acquisition functions looking multiple steps in the future but calculating them requires solving a high-dimensional continuous-state continuous-action Markov decision process (MDP). Fast exact solutions of this MDP remain out of reach of today&#x27;s methods. As a result, previous two- and multi-step lookahead Bayesian optimization algorithms are either too expensive to implement in most practical settings or resort to heuristics that may fail to fully realize the promise of two-step lookahead. This paper proposes a computationally efficient algorithm that provides an accurate solution to the two-step lookahead Bayesian optimization problem in seconds to at most several minutes of computation per batch of evaluations. The resulting acquisition function provides increased query efficiency and robustness compared with previous two- and multi-step lookahead methods in both single-threaded and batch experiments. This unlocks the value of two-step lookahead in practice. We demonstrate the value of our algorithm with extensive experiments on synthetic test functions and real-world problems.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13495">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #46</div>
            <div class="maincardBody">Thompson Sampling for Multinomial Logit Contextual Bandits</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15620">
                    Algorithms -- Bandit Algorithms</a>
                </div>
            
            <div class="maincardFooter">Min-hwan Oh &middot; Garud Iyengar</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1775" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.columbia.edu/~mo2499/files/ts-mnl-poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.columbia.edu/~mo2499/ts-mnl.html" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We consider a dynamic assortment selection problem where the goal is to offer a sequence of assortments that maximizes the expected cumulative revenue, or alternatively, minimize the expected regret. The feedback here is the item that the user picks from the assortment. The distinguishing feature in this work is that this feedback has a multinomial logistic distribution. The utility of each item is a dynamic function of contextual information of both the item and the user.
We propose two Thompson sampling algorithms for this multinomial logit contextual bandit. Our first algorithm maintains a posterior distribution of the true parameter and establishes  $\tilde{O}(d\sqrt{T})$ Bayesian regret over $T$ rounds with $d$ dimensional context vector. The worst-case computational complexity of this algorithm could be high when the prior distribution is not a conjugate.  The second algorithm approximates the posterior by a Gaussian distribution and uses a new optimistic sampling procedure to address the issues that arise in worst-case regret analysis. This algorithm achieves $\tilde{O}(d^{3/2}\sqrt{T})$ worst-case (frequentist) regret bound. The numerical experiments show that the practical performance of both methods is in line with the theoretical guarantees.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14160">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #59</div>
            <div class="maincardBody">Online Continual Learning with Maximal Interfered Retrieval</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15622">
                    Algorithms -- Multitask and Transfer Learning</a>
                </div>
            
            <div class="maincardFooter">Rahaf Aljundi &middot; Eugene Belilovsky &middot; Tinne Tuytelaars &middot; Laurent Charlin &middot; Massimo Caccia &middot; Min Lin &middot; Lucas Page-Caccia</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6371" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=wfb9UV_n8jg&feature=youtu.be" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Continual learning, the setting where a learning agent is faced with a never-ending stream of data, continues to be a great challenge for modern machine learning systems. In particular the online or &quot;single-pass through the data&quot; setting has gained attention recently as a natural setting that is difficult to tackle. Methods based on replay, either generative or from a stored memory, have been shown to be effective approaches for continual learning, matching or exceeding the state of the art in a number of standard benchmarks. These approaches typically rely on randomly selecting samples from the replay memory or from a generative model, which is suboptimal. In this work, we consider a controlled sampling of memories for replay. We retrieve the samples which are most interfered, i.e. whose prediction will be most negatively impacted by the foreseen parameters update. We show a formulation for this sampling criterion in both the generative replay and the experience replay setting, producing consistent gains in performance and greatly reduced forgetting. We release an implementation of our method at https://github.com/optimass/Maximally_Interfered_Retrieval</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13809">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #69</div>
            <div class="maincardBody">Unsupervised Emergence of Egocentric Spatial Structure from Sensorimotor Prediction</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15623">
                    Algorithms -- Representation Learning</a>
                </div>
            
            <div class="maincardFooter">Alban Laflaquière &middot; Michael Garcia Ortiz</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-3880" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/sh/6jcy6mq1tp2u8th/AAD8aQiSvCybLKSL4kA-wdhia?dl=0" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/sh/6jcy6mq1tp2u8th/AAD8aQiSvCybLKSL4kA-wdhia?dl=0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Despite its omnipresence in robotics application, the nature of spatial knowledge and the mechanisms that underlie its emergence in autonomous agents are still poorly understood. Recent theoretical works suggest that the Euclidean structure of space induces invariants in an agent’s raw sensorimotor experience. We hypothesize that capturing these invariants is beneficial for sensorimotor prediction and that, under certain exploratory conditions, a motor representation capturing the structure of the external space should emerge as a byproduct of learning to predict future sensory experiences. We propose a simple sensorimotor predictive scheme, apply it to different agents and types of exploration, and evaluate the pertinence of these hypotheses. We show that a naive agent can capture the topology and metric regularity of its sensor’s position in an egocentric spatial frame without any a priori knowledge, nor extraneous supervision.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14634">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #80</div>
            <div class="maincardBody">Multi-Criteria Dimensionality Reduction with Applications to Fairness</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15624">
                    Applications -- Fairness, Accountability, and Transparency</a>
                </div>
            
            <div class="maincardFooter">Uthaipon Tantipongpipat &middot; Samira Samadi &middot; Mohit Singh &middot; Jamie Morgenstern &middot; Santosh Vempala</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-8678" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/uthaipon/multi-criteria-dimensionality-reduction" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/uthaipon/multi-criteria-dimensionality-reduction" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/aR64H5Jn0gY" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Dimensionality reduction is a classical technique widely used for data analysis. One foundational instantiation is Principal Component Analysis (PCA),
which minimizes the average reconstruction error. In this paper, we introduce the multi-criteria dimensionality reduction problem where we are given multiple objectives that need to be optimized simultaneously. As an application, our model captures several fairness criteria for dimensionality reduction such as the Fair-PCA problem introduced by Samadi et al. [NeurIPS18] and the Nash Social Welfare (NSW) problem. In the Fair-PCA problem, the input data is divided into k groups, and the goal is to find a single d-dimensional representation for all groups for which the maximum reconstruction error of any one group is minimized. In NSW the goal is to maximize the product of the  individual variances of the groups achieved by the common low-dimensinal space.

Our main result is an exact polynomial-time algorithm for the two-criteria dimensionality reduction problem when the two criteria are increasing concave functions. As an application of this result, we obtain a polynomial time algorithm for Fair-PCA for k=2 groups, resolving an open problem of Samadi et al.[NeurIPS18], and a polynomial time algorithm for NSW objective for k=2 groups.  We also give approximation algorithms for k&gt;2. Our technical contribution in the above results is to prove new low-rank properties of extreme point solutions to semi-definite programs. We conclude with the results of several experiments indicating improved performance and generalized application of our algorithm on real-world datasets.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14571">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #85</div>
            <div class="maincardBody">This Looks Like That: Deep Learning for Interpretable Image Recognition</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15624">
                    Applications -- Fairness, Accountability, and Transparency</a>
                </div>
            
            <div class="maincardFooter">Chaofan Chen &middot; Oscar Li &middot; Daniel Tao &middot; Alina Barnett &middot; Cynthia Rudin &middot; Jonathan K Su</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4795" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/k3IQnRsl9U4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture -- prototypical part network (ProtoPNet), that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The model thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training without any annotations for parts of images. We demonstrate our method on the CUB-200-2011 dataset and the Stanford Cars dataset. Our experiments show that ProtoPNet can achieve comparable accuracy with its analogous non-interpretable counterpart, and when several ProtoPNets are combined into a larger network, it can achieve an accuracy that is on par with some of the best-performing deep models. Moreover, ProtoPNet provides a level of interpretability that is absent in other interpretable deep models.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14536">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #87</div>
            <div class="maincardBody">Adversarial Training and Robustness for Multiple Perturbations</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15625">
                    Applications -- Privacy, Anonymity, and Security</a>
                </div>
            
            <div class="maincardFooter">Florian Tramer &middot; Dan Boneh</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-3146" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://floriantramer.com/docs/slides/multirobustness19_video.pptx" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=aUDkfVd3t_8" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Defenses against adversarial examples, such as adversarial training, are typically tailored to a single perturbation type (e.g., small $\ell_\infty$-noise). For other perturbations, these defenses offer no guarantees and, at times, even increase the model&#x27;s vulnerability.
Our aim is to understand the reasons underlying this robustness trade-off, and to train models that are simultaneously robust to multiple perturbation types.

We prove that a trade-off in robustness to different types of $\ell_p$-bounded and spatial perturbations must exist in a natural and simple statistical setting.
We corroborate our formal analysis by demonstrating similar robustness trade-offs on MNIST and CIFAR10. We propose new multi-perturbation adversarial training schemes, as well as an efficient attack for the $\ell_1$-norm, and use these to show that models trained against multiple attacks fail to achieve robustness competitive with that of models trained on each attack individually. 
In particular, we find that adversarial training with first-order $\ell_\infty, \ell_1$ and $\ell_2$ attacks on MNIST achieves merely $50\%$ robust accuracy, partly because of gradient-masking.
Finally, we propose affine attacks that linearly interpolate between perturbation types and further degrade the accuracy of adversarially trained models.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13264">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #110</div>
            <div class="maincardBody">Multi-Resolution Weak Supervision for Sequential Data</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15627">
                    Applications -- Time Series Analysis</a>
                </div>
            
            <div class="maincardFooter">Paroma Varma &middot; Frederic Sala &middot; Shiori Sagawa &middot; Jason A Fries &middot; Daniel Fu &middot; Saelig Khattar &middot; Ashwini Ramamoorthy &middot; Ke Xiao &middot; Kayvon  Fatahalian &middot; James Priest &middot; Christopher Ré</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-86" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://fredsala.github.io/MultiResWS.mov" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Since manually labeling training data is slow and expensive, recent industrial and scientific research efforts have turned to weaker or noisier forms of supervision sources. However, existing weak supervision approaches fail to model multi-resolution sources for sequential data, like video, that can assign labels to individual elements or collections of elements in a sequence. A key challenge in weak supervision is estimating the unknown accuracies and correlations of these sources without using labeled data. Multi-resolution sources exacerbate this challenge due to complex correlations and sample complexity that scales in the length of the sequence. We propose Dugong, the first framework to model multi-resolution weak supervision sources with complex correlations to assign probabilistic labels to training data. Theoretically, we prove that Dugong, under mild conditions, can uniquely recover the unobserved accuracy and correlation parameters and use parameter sharing to improve sample complexity. Our method assigns clinician-validated labels to population-scale biomedical video repositories, helping outperform traditional supervision by 36.8 F1 points and addressing a key use case where machine learning has been severely limited by the lack of expert labeled data. On average, Dugong improves over traditional supervision by 16.0 F1 points and existing weak supervision approaches by 24.2 F1 points across several video and sensor classification tasks. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13278">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #124</div>
            <div class="maincardBody">Reducing Noise in GAN Training with Variance Reduced Extragradient</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15628">
                    Deep Learning -- Adversarial Networks</a>
                </div>
            
            <div class="maincardFooter">Tatjana Chavdarova &middot; Gauthier Gidel &middot; François Fleuret &middot; Simon Lacoste-Julien</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-192" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/Chavdarova/SVRE/blob/master/poster/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/Chavdarova/SVRE/tree/master/slides" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/Chavdarova/SVRE/tree/master/video" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We study the effect of the stochastic gradient noise on the training of generative adversarial networks (GANs) and show that it can prevent the convergence of standard game optimization methods, while the batch version converges. We address this issue with a novel stochastic variance-reduced extragradient (SVRE) optimization algorithm, which for a large class of games improves upon the previous convergence rates proposed in the literature. We observe empirically that SVRE performs similarly to a batch method on MNIST while being computationally cheaper, and that SVRE yields more stable GAN training on standard datasets.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13266">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #126</div>
            <div class="maincardBody">The Point Where Reality Meets Fantasy: Mixed Adversarial Generators for Image Splice Detection</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15628">
                    Deep Learning -- Adversarial Networks</a>
                </div>
            
            <div class="maincardFooter">Vladimir V. Kniaz &middot; Vladimir Knyaz &middot; Fabio Remondino</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-93" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/sh/2oklpl896a2voq9/AAAa751mBQHgNc0-ePmePHZpa?dl=0" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/s/xfxszql3dh6a7uk/MAG_Presentation.mp4?dl=0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Modern photo editing tools allow creating realistic manipulated images easily. While fake images can be quickly generated, learning models for their detection is challenging due to the high variety of tampering artifacts and the lack of large labeled datasets of manipulated images. In this paper, we propose a new framework for training of discriminative segmentation model via an adversarial process. We simultaneously train four models: a generative retouching model G_R that translates manipulated image to the real image domain, a generative annotation model G_A that estimates the pixel-wise probability of image patch being either real or fake, and two discriminators D_R and D_A that qualify the output of G_R and G_A. The aim of model G_R is to maximize the probability of model G_A making a mistake. Our method extends the generative adversarial networks framework with two main contributions: (1) training of a generative model G_R against a deep semantic segmentation network G_A that learns rich scene semantics for manipulated region detection, (2) proposing per class semantic loss that facilitates semantically consistent image retouching by the G_R. We collected large-scale manipulated image dataset to train our model. The dataset includes 16k real and fake images with pixel-level annotations of manipulated areas. The dataset also provides ground truth pixel-level object annotations. We validate our approach on several modern manipulated image datasets, where quantitative results and ablations demonstrate that our method achieves and surpasses the state-of-the-art in manipulated image detection. We made our code and dataset publicly available.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13646">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #145</div>
            <div class="maincardBody">Neural Similarity Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15629">
                    Deep Learning -- CNN Architectures</a>
                </div>
            
            <div class="maincardFooter">Weiyang Liu &middot; Zhen Liu &middot; James Rehg &middot; Le Song</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2770" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://wyliu.com/papers/LiuNSL2019_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://wyliu.com/papers/LiuNSL2019_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://wyliu.com/" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Inner product-based convolution has been the founding stone of convolutional neural networks (CNNs), enabling end-to-end learning of visual representation. By generalizing inner product with a bilinear matrix, we propose the neural similarity which serves as a learnable parametric similarity measure for CNNs. Neural similarity naturally generalizes the convolution and enhances flexibility. Further, we consider the neural similarity learning (NSL) in order to learn the neural similarity adaptively from training data. Specifically, we propose two different ways of learning the neural similarity: static NSL and dynamic NSL. Interestingly, dynamic neural similarity makes the CNN  become a dynamic inference network. By regularizing the bilinear matrix, NSL can be viewed as learning the shape of kernel and the similarity measure simultaneously. We further justify the effectiveness of NSL with a theoretical viewpoint. Most importantly, NSL shows promising performance in visual recognition and few-shot learning, validating the superiority of NSL over the inner product-based convolution counterparts.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13946">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #177</div>
            <div class="maincardBody">Modeling Expectation Violation in Intuitive Physics with Coarse Probabilistic Object Representations</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15632">
                    Neuroscience and Cognitive Science -- Cognitive Science</a>
                </div>
            
            <div class="maincardFooter">Kevin Smith &middot; Lingjie Mei &middot; Shunyu Yao &middot; Jiajun Wu &middot; Elizabeth Spelke &middot; Josh Tenenbaum &middot; Tomer Ullman</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4818" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=95HlF9nCca4&feature=youtu.be" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >From infancy, humans have expectations about how objects will move and interact. Even young children expect objects not to move through one another, teleport, or disappear. They are surprised by mismatches between physical expectations and perceptual observations, even in unfamiliar scenes with completely novel objects. A model that exhibits human-like understanding of physics should be similarly surprised, and adjust its beliefs accordingly.  We propose ADEPT, a model that uses a coarse (approximate geometry) object-centric representation for dynamic 3D scene understanding. Inference integrates deep recognition networks, extended probabilistic physical simulation, and particle filtering for forming predictions and expectations across occlusion. We also present a new test set for measuring violations of physical expectations, using a range of scenarios derived from developmental psychology.  We systematically compare ADEPT, baseline models, and human expectations on this test set.  ADEPT outperforms standard network architectures in discriminating physically implausible scenes, and often performs this discrimination at the same level as people.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13837">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #187</div>
            <div class="maincardBody">Nonlinear scaling of resource allocation in sensory bottlenecks</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15633">
                    Neuroscience and Cognitive Science -- Neural Coding</a>
                </div>
            
            <div class="maincardFooter">Laura R Edmondson &middot; Alejandro Jimenez Rodriguez &middot; Hannes P. Saal</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4107" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=M6ohnt_6J9Q" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >In many sensory systems, information transmission is constrained by a bottleneck,
where the number of output neurons is vastly smaller than the number of input
neurons. Efficient coding theory predicts that in these scenarios the brain should
allocate its limited resources by removing redundant information. Previous work
has typically assumed that receptors are uniformly distributed across the sensory
sheet, when in reality these vary in density, often by an order of magnitude. How,
then, should the brain efficiently allocate output neurons when the density of input
neurons is nonuniform? Here, we show analytically and numerically that resource
allocation scales nonlinearly in efficient coding models that maximize information
transfer, when inputs arise from separate regions with different receptor densities.
Importantly, the proportion of output neurons allocated to a given input region
changes depending on the width of the bottleneck, and thus cannot be predicted
from input density or region size alone. Narrow bottlenecks favor magnification of
high density input regions, while wider bottlenecks often cause contraction. Our
results demonstrate that both expansion and contraction of sensory input regions
can arise in efficient coding models and that the final allocation crucially depends
on the neural resources made available.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13245">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #190</div>
            <div class="maincardBody">Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15634">
                    Neuroscience and Cognitive Science -- Neuroscience</a>
                </div>
            
            <div class="maincardFooter">Jonas Kubilius &middot; Martin Schrimpf &middot; Kohitij Kar &middot; Rishi Rajalingham &middot; Ha Hong &middot; Najib Majaj &middot; Elias Issa &middot; Pouya Bashivan &middot; Jonathan Prescott-Roy &middot; Kailyn Schmidt &middot; Aran Nayebi &middot; Daniel Bear &middot; Daniel Yamins &middot; James J DiCarlo</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6969" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/dicarlolab/neurips2019/blob/master/slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://cbmm.mit.edu/video/brain-object-recognition-high-performing-shallow-recurrent-anns" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Deep convolutional artificial neural networks (ANNs) are the leading class of candidate models of the mechanisms of visual processing in the primate ventral stream. While initially inspired by brain anatomy, over the past years, these ANNs have evolved from a simple eight-layer architecture in AlexNet to extremely deep and branching architectures, demonstrating increasingly better object categorization performance, yet bringing into question how brain-like they still are. In particular, typical deep models from the machine learning community are often hard to map onto the brain&#x27;s anatomy due to their vast number of layers and missing biologically-important connections, such as recurrence. Here we demonstrate that better anatomical alignment to the brain and high performance on machine learning as well as neuroscience measures do not have to be in contradiction. We developed CORnet-S, a shallow ANN with four anatomically mapped areas and recurrent connectivity, guided by Brain-Score, a new large-scale composite of neural and behavioral benchmarks for quantifying the functional fidelity of models of the primate ventral visual stream. Despite being significantly shallower than most models, CORnet-S is the top model on Brain-Score and outperforms similarly compact models on ImageNet. Moreover, our extensive analyses of CORnet-S circuitry variants reveal that recurrence is the main predictive factor of both Brain-Score and ImageNet top-1 performance. Finally, we report that the temporal evolution of the CORnet-S &quot;IT&quot; neural population resembles the actual monkey IT population dynamics. Taken together, these results establish CORnet-S, a compact, recurrent ANN, as the current best model of the primate ventral visual stream.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14028">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #198</div>
            <div class="maincardBody">Efficiently avoiding saddle points with zero order methods: No gradients required </div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15636">
                    Optimization -- Non-Convex Optimization</a>
                </div>
            
            <div class="maincardFooter">Emmanouil-Vasileios Vlatakis-Gkaragkounis &middot; Lampros Flokas &middot; Georgios Piliouras</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5317" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.columbia.edu/~emvlatakis/Posters/Poincare_Recurrence_Cycles_and_Spurious_Equilibria_in_Gradient-Descent-Ascent_for_Non-Convex_Non-Concave_Zero-Sum_Games.html" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.columbia.edu/~emvlatakis/Presentations/Poincare_Recurrence_Cycles_and_Spurious_Equilibria_in_Gradient-Descent-Ascent_for_Non-Convex_Non-Concave_Zero-Sum_Games.html" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.cs.columbia.edu/~emvlatakis/Videos/Poincare_Recurrence_Cycles_and_Spurious_Equilibria_in_Gradient-Descent-Ascent_for_Non-Convex_Non-Concave_Zero-Sum_Games.html" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We consider the case of derivative-free algorithms for non-convex optimization, also known as zero order algorithms, that use only function evaluations rather than gradients. For a wide variety of gradient approximators based on finite differences, we establish asymptotic convergence to second order stationary points using a carefully tailored application of the Stable Manifold Theorem.  Regarding efficiency, we introduce a noisy zero-order method that converges to second order stationary points, i.e avoids saddle points. Our algorithm uses only $\tilde{\mathcal{O}}(1 / \epsilon^2)$ approximate gradient calculations and, thus, it matches the converge rate guarantees of their exact gradient counterparts up to constants. In contrast to previous work, our convergence rate analysis avoids imposing additional dimension dependent slowdowns in the number of iterations required for non-convex zero order optimization.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14207">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #213</div>
            <div class="maincardBody">Control What You Can: Intrinsically Motivated Task-Planning Agent</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15638">
                    Reinforcement Learning and Planning -- Planning</a>
                </div>
            
            <div class="maincardFooter">Sebastian Blaes &middot; Marin Vlastelica Pogančić &middot; Jiajie Zhu &middot; Georg Martius</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6819" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://owncloud.tuebingen.mpg.de/index.php/s/M3Ze4GStAn4aZdD" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We present a novel intrinsically motivated agent that learns how to control the
environment in a sample efficient manner, that is with as few environment interactions as possible, by optimizing learning progress. It learns what can be controlled, how to allocate time and attention as well as the relations between objects using surprise-based motivation. The effectiveness of our method is demonstrated in a synthetic and robotic manipulation environment yielding considerably improved performance and smaller sample complexity compared to an intrinsically motivated, non-hierarchical and state-of-the-art hierarchical baseline. In a nutshell, our work combines several task-level planning agent structures (backtracking search on task-graph, probabilistic road-maps, allocation of search efforts) with intrinsic motivation to achieve learning from scratch.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14324">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #228</div>
            <div class="maincardBody">Generalization in Reinforcement Learning with Selective Noise Injection and Information Bottleneck</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15639">
                    Reinforcement Learning and Planning -- Reinforcement Learning</a>
                </div>
            
            <div class="maincardFooter">Maximilian Igl &middot; Kamil Ciosek &middot; Yingzhen Li &middot; Sebastian Tschiatschek &middot; Cheng Zhang &middot; Sam Devlin &middot; Katja Hofmann</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-7793" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://1drv.ms/v/s!Aj45y31uNubdlVXufoKxmwAqr0fP?e=TtGFfX" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >The ability for policies to generalize to new environments is key to the broad application of RL agents. A promising approach to prevent an agent’s policy from overfitting to a limited set of training environments is to apply regularization techniques originally developed for supervised learning. However, there are stark differences between supervised learning and RL. We discuss those differences and propose modifications to existing regularization techniques in order to better adapt them to RL. In particular, we focus on regularization techniques relying on the injection of noise into the learned function, a family that includes some of the most widely used approaches such as Dropout and Batch Normalization. To adapt them to RL, we propose Selective Noise Injection (SNI), which maintains the regularizing effect the injected noise has, while mitigating the adverse effects it has on the gradient quality. Furthermore, we demonstrate that the Information Bottleneck (IB) is a particularly well suited regularization technique for RL as it is effective in the low-data regime encountered early on in training RL agents. Combining the IB with SNI, we significantly outperform current state of the art results, including on the recently proposed generalization benchmark Coinrun.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14270">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #230</div>
            <div class="maincardBody">Gossip-based Actor-Learner Architectures for Deep Reinforcement Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15639">
                    Reinforcement Learning and Planning -- Reinforcement Learning</a>
                </div>
            
            <div class="maincardFooter">Mahmoud Assran &middot; Joshua Romoff &middot; Nicolas Ballas &middot; Joelle Pineau &middot; Mike Rabbat</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-7307" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/sh/1ommra478q2j0mx/AAD8DpJMrnX_jYcfPKrht4nWa?dl=0" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/sh/1ommra478q2j0mx/AAD8DpJMrnX_jYcfPKrht4nWa?dl=0" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/sh/1ommra478q2j0mx/AAD8DpJMrnX_jYcfPKrht4nWa?dl=0" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Multi-simulator training has contributed to the recent success of Deep Reinforcement Learning (Deep RL) by stabilizing learning and allowing for higher training throughputs. In this work, we propose Gossip-based Actor-Learner Architectures (GALA) where several actor-learners (such as A2C agents) are organized in a peer-to-peer communication topology, and exchange information through asynchronous gossip in order to take advantage of a large number of distributed simulators. We prove that GALA agents remain within an epsilon-ball of one-another during training when using loosely coupled asynchronous communication. By reducing the amount of synchronization between agents, GALA is more computationally efficient and scalable compared to A2C, its fully-synchronous counterpart. GALA also outperforms A2C, being more robust and sample efficient. We show that we can run several loosely coupled GALA agents in parallel on a single GPU and achieve significantly higher hardware utilization and frame-rates than vanilla A2C at comparable power draws.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14462">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #231</div>
            <div class="maincardBody">Imitation-Projected Programmatic Reinforcement Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15639">
                    Reinforcement Learning and Planning -- Reinforcement Learning</a>
                </div>
            
            <div class="maincardFooter">Abhinav Verma &middot; Hoang Le &middot; Yisong Yue &middot; Swarat Chaudhuri</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-9215" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/programmatic-rl" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.dropbox.com/s/3x5l7v4i0ssxdsf/PROPEL.pdf?dl=0" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://sites.google.com/view/programmatic-rl" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We study the problem of programmatic reinforcement learning, in which policies are represented as short programs in a symbolic language. Programmatic policies can be more interpretable, generalizable, and amenable to formal verification than neural policies; however, designing rigorous learning approaches for such policies remains a challenge. Our approach to this challenge - a meta-algorithm called PROPEL - is based on three insights. First, we view our learning task as optimization in policy space, modulo the constraint that the desired policy has a programmatic representation, and solve this optimization problem using a form of mirror descent that takes a gradient step into the unconstrained policy space and then projects back onto the constrained space.  Second, we view the unconstrained policy space as mixing neural and programmatic representations, which enables employing state-of-the-art deep policy gradient approaches.  Third, we cast the projection step as program synthesis via imitation learning, and exploit contemporary combinatorial methods for this task. We present theoretical convergence results for PROPEL and empirically evaluate the approach in three continuous control domains. The experiments show that PROPEL can significantly outperform state-of-the-art approaches for learning programmatic policies.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13900">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #242</div>
            <div class="maincardBody">The spiked matrix model with generative priors</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15640">
                    Theory -- Information Theory</a>
                </div>
            
            <div class="maincardFooter">Benjamin Aubin &middot; Bruno Loureiro &middot; Antoine Maillard &middot; Florent Krzakala &middot; Lenka Zdeborová</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4541" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/benjaminaubin/StructuredPrior_demo/blob/master/Poster/Poster_NeurIPS2019_StructuredPrior.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/benjaminaubin/StructuredPrior_demo/blob/master/Slides/Slides_NeurIPS2019_StructuredPrior.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/0XEVjCL_9Dk" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Using a low-dimensional parametrization of signals is a generic and powerful way to enhance performance in signal processing and statistical inference. A very popular and widely explored type of dimensionality reduction is sparsity; another type is generative modelling of signal distributions. Generative models based on neural networks, such as GANs or variational auto-encoders, are particularly performant and are gaining on applicability. In this paper we study spiked matrix models, where a low-rank matrix is observed through a noisy channel. This problem with sparse structure of the spikes has attracted broad attention in the past literature. Here, we replace the sparsity assumption by generative modelling, and investigate the consequences on statistical and algorithmic properties. We analyze the Bayes-optimal performance under specific generative models for the spike. In contrast with the sparsity assumption, we do not observe regions of parameters where statistical performance is superior to the best known algorithmic performance. We show that in the analyzed cases the approximate message passing algorithm is able to reach optimal performance. We also design enhanced spectral algorithms and analyze their performance and thresholds using random matrix theory, showing their superiority to the classical principal component analysis. We complement our theoretical results by illustrating the performance of the spectral algorithms when the spikes come from real datasets.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14170">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #246</div>
            <div class="maincardBody">The Impact of Regularization on High-dimensional Logistic Regression</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15641">
                    Theory -- Regularization</a>
                </div>
            
            <div class="maincardFooter">Fariborz Salehi &middot; Ehsan Abbasi &middot; Babak Hassibi</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6476" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://caltech.box.com/s/e8gcoyxd2bwasd6kvkrgxvc9i9osmmmv" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Logistic regression is commonly used for modeling dichotomous outcomes. In the classical setting, where the number of observations is much larger than the number of parameters, properties of the maximum likelihood estimator in logistic regression are well understood. Recently, Sur and Candes~\cite{sur2018modern} have studied logistic regression in the high-dimensional regime, where the number of observations and parameters are comparable, and show, among other things, that the maximum likelihood estimator is biased. In the high-dimensional regime the underlying parameter vector is often structured (sparse, block-sparse, finite-alphabet, etc.) and so in this paper we study regularized logistic regression (RLR), where a convex regularizer that encourages the desired structure is added to the negative of the log-likelihood function. An advantage of RLR is that it allows parameter recovery even for instances where the (unconstrained) maximum likelihood estimate does not exist. We provide a precise analysis of the performance of RLR via the solution of a system of six nonlinear equations, through which any performance metric of interest (mean, mean-squared error, probability of support recovery, etc.) can be explicitly computed. Our results generalize those of Sur and Candes and we provide a detailed study for the cases of $\ell_2^2$-RLR and sparse ($\ell_1$-regularized) logistic regression. In both cases, we obtain explicit expressions for various performance metrics and can find the values of the regularizer parameter that optimizes the desired performance. The theory is validated by extensive numerical simulations across a range of parameter values and problem instances.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15834">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall A  </div>
            <div class="maincardBody">On the Downstream Performance of Compressed Word Embeddings</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15832">
                    Track 2 Session 6</a>
                </div>
            
            <div class="maincardFooter">Avner May &middot; Jian Zhang &middot; Tri Dao &middot; Christopher Ré</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6320" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://avnermay.github.io/compressed_embeddings_neurips_2019_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15834.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://avnermay.github.io/compressed_embeddings_neurips_2019_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/Slides/nips/2019/westexhibitionhalla(12-15-50)-12-16-05-15834-on_the_downstre.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://avnermay.github.io/compressed_embeddings_neurips_2019_video.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Compressing word embeddings is important for deploying NLP models in memory-constrained settings. However, understanding what makes compressed embeddings perform well on downstream tasks is challenging---existing measures of compression quality often fail to distinguish between embeddings that perform well and those that do not. We thus propose the eigenspace overlap score as a new measure. We relate the eigenspace overlap score to downstream performance by developing generalization bounds for the compressed embeddings in terms of this score, in the context of linear and logistic regression. We then show that we can lower bound the eigenspace overlap score for a simple uniform quantization compression method, helping to explain the strong empirical performance of this method. Finally, we show that by using the eigenspace overlap score as a selection criterion between embeddings drawn from a representative set we compressed, we can efficiently identify the better performing embedding with up to 2x lower selection error rates than the next best measure of compression quality, and avoid the cost of training a separate model for each task of interest.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower spotlight" id="maincard_15890">
            <div class='pull-right maincardHeader maincardType'>Spotlight</div>
            <div class="maincardHeader">{daterange} @ West Exhibition Hall C + B3  </div>
            <div class="maincardBody">Ask not what AI can do, but what AI should do: Towards a framework of task delegability</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15888">
                    Track 1 Session 6</a>
                </div>
            
            <div class="maincardFooter">Brian Lubars &middot; Chenhao Tan</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-39" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://tiny.cc/delegationposter" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="/media/neurips-2019/Slides/15890.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://tiny.cc/delegationslides" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://tiny.cc/delegationvideo" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >While artificial intelligence (AI) holds promise for addressing societal challenges, issues of exactly which tasks to automate and to what extent to do so remain understudied. We approach this problem of task delegability from a human-centered perspective by developing a framework on human perception of task delegation to AI. We consider four high-level factors that can contribute to a delegation decision: motivation, difficulty, risk, and trust. To obtain an empirical understanding of human preferences in different tasks, we build a dataset of 100 tasks from academic papers, popular media portrayal of AI, and everyday life, and administer a survey based on our proposed framework. We find little preference for full AI control and a strong preference for machine-in-the-loop designs, in which humans play the leading role. Among the four factors, trust is the most correlated with human preferences of optimal human-machine delegation. This framework represents a first step towards characterizing human preferences of AI automation across tasks. We hope this work encourages future efforts towards understanding such individual attitudes; our goal is to inform the public and the AI research community rather than dictating any direction in technology development.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14103">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #22</div>
            <div class="maincardBody">Online Forecasting of Total-Variation-bounded Sequences</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15645">
                    Algorithms -- Online Learning</a>
                </div>
            
            <div class="maincardFooter">Dheeraj Baby &middot; Yu-Xiang Wang</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5938" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/yuxiangw/tv_online/blob/master/arrows_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/yuxiangw/tv_online/blob/master/online_forecasting_talk.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://slideslive.com/38917673/online-forecasting-of-totalvariationbounded-sequences" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We consider the problem of online forecasting of sequences of length $n$ with total-variation at most $C_n$ using observations contaminated by independent $\sigma$-subgaussian noise. We design an $O(n\log n)$-time algorithm that achieves a cumulative square error of $\tilde{O}(n^{1/3}C_n^{2/3}\sigma^{4/3} + C_n^2)$ with high probability. We also prove a lower bound that matches the upper bound in all parameters (up to a $\log(n)$ factor). To the best of our knowledge, this is the first **polynomial-time** algorithm that achieves the optimal $O(n^{1/3})$ rate in forecasting total variation bounded sequences and the first algorithm that **adapts to unknown** $C_n$.Our proof techniques leverage the special localized structure of Haar wavelet basis and the adaptivity to unknown smoothness parameters in the classical wavelet smoothing [Donoho et al., 1998]. We also compare our model to the rich literature of dynamic regret minimization and nonstationary stochastic optimization, where our problem can be treated as a special case. We show that the workhorse in those settings --- online gradient descent and its variants with a fixed restarting schedule --- are instances of a class of **linear forecasters** that require a suboptimal regret of $\tilde{\Omega}(\sqrt{n})$. This implies that the use of more adaptive algorithms is necessary to obtain the optimal rate. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14437">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #37</div>
            <div class="maincardBody">Understanding the Representation Power of Graph Neural Networks in Learning Graph Topology</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15623">
                    Algorithms -- Representation Learning</a>
                </div>
            
            <div class="maincardFooter">Nima Dehmamy &middot; Albert-Laszlo Barabasi &middot; Rose Yu</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-8876" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/nimadehmamy/Understanding-GCN" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/nimadehmamy/Understanding-GCN" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://github.com/nimadehmamy/Understanding-GCN" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >To deepen our understanding of graph neural networks, we investigate the representation power of Graph Convolutional Networks (GCN) through the looking glass of graph moments, a key property of  graph topology encoding path of various lengths.
We find that GCNs are rather restrictive in learning graph moments. Without careful design, GCNs can fail miserably even with multiple layers and nonlinear activation functions.
We analyze theoretically the expressiveness of GCNs, arriving at a modular GCN design, using different propagation rules.
Our modular design is capable of distinguishing graphs from different graph generation models for surprisingly small graphs, a notoriously difficult problem in network science. 
Our investigation suggests that, depth is much more influential than width and deeper GCNs are more capable of learning higher order graph moments. 
Additionally, combining  GCN modules with different propagation rules is critical to the representation power of GCNs.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14196">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #56</div>
            <div class="maincardBody">Universality in Learning from Linear Measurements</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15647">
                    Algorithms -- Sparsity and Compressed Sensing</a>
                </div>
            
            <div class="maincardFooter">Ehsan Abbasi &middot; Fariborz Salehi &middot; Babak Hassibi</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6710" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://caltech.box.com/s/vwr8lrxy9edr5m2vbwqheeryoi7y3wq6" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We study the problem of recovering a structured signal from independently and identically drawn linear measurements. A convex penalty function $f(\cdot)$ is considered which penalizes deviations from the desired structure, and signal recovery is performed by minimizing $f(\cdot)$ subject to the linear measurement constraints. The main question of interest is to determine the minimum number of measurements that is necessary and sufficient for the perfect recovery of the unknown signal with high probability. Our main result states that, under some mild conditions on $f(\cdot)$ and on the distribution from which the linear measurements are drawn, the minimum number of measurements required for perfect recovery depends only on the first and second order statistics of the measurement vectors. As a result, the required of number of measurements can be determining by studying measurement vectors that are Gaussian (and have the same mean vector and covariance matrix) for which a rich literature and comprehensive theory exists. As an application, we show that the minimum number of random quadratic measurements (also known as rank-one projections) required to recover a low rank positive semi-definite matrix is $3nr$, where $n$ is the dimension of the matrix and $r$ is its rank. As a consequence, we settle the long standing open question of determining the minimum number of measurements required for perfect signal recovery in phase retrieval using the celebrated PhaseLift algorithm, and show it to be $3n$.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14289">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #63</div>
            <div class="maincardBody">Search-Guided, Lightly-Supervised Training of Structured Prediction Energy Networks</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15649">
                    Algorithms -- Structured Prediction</a>
                </div>
            
            <div class="maincardFooter">Amirmohammad Rooshenas &middot; Dongxu Zhang &middot; Gopal Sharma &middot; Andrew McCallum</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-7492" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://rooshenas.github.io/files/sg-spen-slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://rooshenas.github.io/files/sg-spen.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" > In structured output prediction tasks, labeling ground-truth training output is often expensive. However, for many tasks, even when the true output is unknown, we can evaluate predictions using a scalar reward function, which may be easily assembled from human knowledge or non-differentiable pipelines.  But searching through the entire output space to find the best output with respect to this reward function is typically intractable.  In this paper, we instead use efficient truncated randomized search in this reward function to train structured prediction energy networks (SPENs), which provide efficient test-time inference using gradient-based search on a smooth, learned representation of the score landscape, and have previously yielded state-of-the-art results in structured prediction.  In particular, this truncated randomized search in the reward function yields previously unknown local improvements, providing effective supervision to SPENs, avoiding their traditional need for labeled training data.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14353">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #82</div>
            <div class="maincardBody">Computational Mirrors: Blind Inverse Light Transport by Deep Matrix Factorization</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15653">
                    Applications -- Computational Photography</a>
                </div>
            
            <div class="maincardFooter">Miika Aittala &middot; Prafull Sharma &middot; Lukas Murmann &middot; Adam Yedidia &middot; Gregory Wornell &middot; Bill Freeman &middot; Fredo Durand</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-8097" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://compmirrors.csail.mit.edu/videos/compmirrors_3minute.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We recover a video of the motion taking place in a hidden scene by observing changes in indirect illumination in a nearby uncalibrated visible region. We solve this problem by factoring the observed video into a matrix product between the unknown hidden scene video and an unknown light transport matrix. This task is extremely ill-posed, as any non-negative factorization will satisfy the data. Inspired by recent work on the Deep Image Prior, we parameterize the factor matrices using randomly initialized convolutional neural networks trained in a one-off manner, and show that this results in decompositions that reflect the true motion in the hidden scene.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13995">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #92</div>
            <div class="maincardBody">Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15655">
                    Applications -- Computer Vision</a>
                </div>
            
            <div class="maincardFooter">Wenzheng Chen &middot; Huan Ling &middot; Jun Gao &middot; Edward Smith &middot; Jaakko Lehtinen &middot; Alec Jacobson &middot; Sanja Fidler</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5098" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1l2A0dBLd2-Gi6aGzyYKVAei1KKJA4v53/view" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://nv-tlabs.github.io/DIB-R/" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Many machine learning models operate on images, but ignore the fact that images are 2D projections formed by 3D geometry interacting with light, in a process called rendering. Enabling ML models to understand image formation might be key for generalization. However, due to an essential rasterization step involving discrete assignment operations, rendering pipelines are non-differentiable and thus largely inaccessible to gradient-based ML techniques. In this paper, we present DIB-Render, a novel rendering framework through which gradients can be analytically computed. Key to our approach is to view rasterization as a weighted interpolation, allowing image gradients to back-propagate through various standard vertex shaders within a single framework. Our approach supports optimizing over vertex positions, colors, normals, light directions and texture coordinates, and allows us to incorporate various well-known lighting models from graphics. We showcase our approach in two ML applications: single-image 3D object prediction, and 3D textured object generation, both trained using exclusively 2D supervision. </p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13954">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #101</div>
            <div class="maincardBody">STAR-Caps: Capsule Networks with Straight-Through Attentive Routing</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15655">
                    Applications -- Computer Vision</a>
                </div>
            
            <div class="maincardFooter">Karim Ahmed &middot; Lorenzo Torresani</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4875" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://bit.ly/2pimMKd" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://bit.ly/2PA6JlV" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" > Capsule networks have been shown to be powerful models for image classification, thanks to their ability to represent and capture viewpoint variations of an object. However, the high computational complexity of capsule networks that stems from the recurrent dynamic routing poses a major drawback making their use for large-scale image classification challenging. In this work, we propose Star-Caps a capsule-based network that exploits a straight-through attentive routing to address the drawbacks of capsule networks. By utilizing attention modules augmented by differentiable binary routers, the proposed mechanism estimates the routing coefficients between capsules without recurrence, as opposed to prior related work. Subsequently, the routers utilize straight-through estimators to make binary decisions to either connect or disconnect the route between capsules, allowing stable and faster performance. The experiments conducted on several image classification datasets, including MNIST, SmallNorb, CIFAR-10, CIFAR-100, and ImageNet show that STAR-Caps outperforms the baseline capsule networks. 
</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14480">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #104</div>
            <div class="maincardBody">Ask not what AI can do, but what AI should do: Towards a framework of task delegability</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15624">
                    Applications -- Fairness, Accountability, and Transparency</a>
                </div>
            
            <div class="maincardFooter">Brian Lubars &middot; Chenhao Tan</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-39" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://tiny.cc/delegationposter" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://tiny.cc/delegationslides" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://tiny.cc/delegationvideo" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >While artificial intelligence (AI) holds promise for addressing societal challenges, issues of exactly which tasks to automate and to what extent to do so remain understudied. We approach this problem of task delegability from a human-centered perspective by developing a framework on human perception of task delegation to AI. We consider four high-level factors that can contribute to a delegation decision: motivation, difficulty, risk, and trust. To obtain an empirical understanding of human preferences in different tasks, we build a dataset of 100 tasks from academic papers, popular media portrayal of AI, and everyday life, and administer a survey based on our proposed framework. We find little preference for full AI control and a strong preference for machine-in-the-loop designs, in which humans play the leading role. Among the four factors, trust is the most correlated with human preferences of optimal human-machine delegation. This framework represents a first step towards characterizing human preferences of AI automation across tasks. We hope this work encourages future efforts towards understanding such individual attitudes; our goal is to inform the public and the AI research community rather than dictating any direction in technology development.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14143">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #120</div>
            <div class="maincardBody">A Zero-Positive Learning Approach for Diagnosing Software Performance Regressions</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15657">
                    Applications -- Hardware and Systems</a>
                </div>
            
            <div class="maincardFooter">Mejbah Alam &middot; Justin Gottschlich &middot; Nesime Tatbul &middot; Javier Turek &middot; Tim Mattson &middot; Abdullah Muzahid</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6217" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/0B5Ycn3lPj7vwc0prbFRWUzBrN1R2UzdENHNESWlyZTI5NjB3/view?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/FkT1aNoKbG4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >The field of machine programming (MP), the automation of the development of software, is making notable research advances. This is, in part, due to the emergence of a wide range of novel techniques in machine learning. In this paper, we apply MP to the automation of software performance regression testing. A performance regression is a software performance degradation caused by a code change. We present AutoPerf – a novel approach to automate regression testing that utilizes three core techniques: (i) zero-positive learning, (ii) autoencoders, and (iii) hardware telemetry. We demonstrate AutoPerf’s generality and efficacy against 3 types of performance regressions across 10 real performance bugs in 7 benchmark and open-source programs. On average, AutoPerf exhibits 4% profiling
overhead and accurately diagnoses more performance bugs than prior state-of-the-art approaches. Thus far, AutoPerf has produced no false negatives.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13907">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #125</div>
            <div class="maincardBody">The Synthesis of XNOR Recurrent Neural Networks with Stochastic Logic</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15657">
                    Applications -- Hardware and Systems</a>
                </div>
            
            <div class="maincardFooter">Arash Ardakani &middot; Zhengyun Ji &middot; Amir Ardakani &middot; Warren Gross</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4567" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://isip.ece.mcgill.ca/media/neurips_2019/slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://isip.ece.mcgill.ca/media/neurips_2019/video.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >The emergence of XNOR networks seek to reduce the model size and computational cost of neural networks for their deployment on specialized hardware requiring real-time processes with limited hardware resources. In XNOR networks, both weights and activations are binary, bringing great benefits to specialized hardware by replacing expensive multiplications with simple XNOR operations. Although XNOR convolutional and fully-connected neural networks have been successfully developed during the past few years, there is no XNOR network implementing commonly-used variants of recurrent neural networks such as long short-term memories (LSTMs). The main computational core of LSTMs involves vector-matrix multiplications followed by a set of non-linear functions and element-wise multiplications to obtain the gate activations and state vectors, respectively. Several previous attempts on quantization of LSTMs only focused on quantization of the vector-matrix multiplications in LSTMs while retaining the element-wise multiplications in full precision. In this paper, we propose a method that converts all the multiplications in LSTMs to XNOR operations using stochastic computing. To this end, we introduce a weighted finite-state machine and its synthesis method to approximate the non-linear functions used in LSTMs on stochastic bit streams. Experimental results show that the proposed XNOR LSTMs reduce the computational complexity of their quantized counterparts by a factor of 86x without any sacrifice on latency while achieving a better accuracy across various temporal tasks.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13584">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #149</div>
            <div class="maincardBody">Learning Deep Bilinear Transformation for Fine-grained Image Representation</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15661">
                    Applications -- Object Recognition</a>
                </div>
            
            <div class="maincardFooter">Heliang Zheng &middot; Jianlong Fu &middot; Zheng-Jun Zha &middot; Jiebo Luo</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-2401" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/open?id=1IBfLuHMZ5cUUDugVgcpupwwT7e5OneAu" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Bilinear feature transformation has shown the state-of-the-art performance in learning fine-grained image representations. However, the computational cost to learn pairwise interactions between deep feature channels is prohibitively expensive, which restricts this powerful transformation to be used in deep neural networks. In this paper, we propose a deep bilinear transformation (DBT) block, which can be deeply stacked in convolutional neural networks to learn fine-grained image representations. The DBT block can uniformly divide input channels into several semantic groups. As bilinear transformation can be represented by calculating pairwise interactions within each group, the computational cost can be heavily relieved. The output of each block is further obtained by aggregating intra-group bilinear features, with residuals from the entire input features. We found that the proposed network achieves new state-of-the-art in several fine-grained image recognition benchmarks, including CUB-Bird, Stanford-Car, and FGVC-Aircraft.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13958">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #170</div>
            <div class="maincardBody">Write, Execute, Assess: Program Synthesis with a REPL</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15662">
                    Applications -- Program Understanding and Generation</a>
                </div>
            
            <div class="maincardFooter">Kevin Ellis &middot; Maxwell Nye &middot; Yewen Pu &middot; Felix Sosa &middot; Josh Tenenbaum &middot; Armando Solar-Lezama</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4927" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=B3T_mEb2NGA&feature=youtu.be" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >  We present a neural program synthesis approach integrating components which write, execute, and assess code to navigate the search space of possible programs. We equip the search process with an interpreter or a read-eval-print-loop (REPL), which immediately executes partially written programs, exposing their semantics. The REPL addresses a basic challenge of program synthesis: tiny changes in syntax can lead to huge changes in semantics. We train a pair of models, a policy that proposes the new piece of code to write, and a value function that assesses the prospects of the code written so-far. At test time we can combine these models with a Sequential Monte Carlo algorithm. We apply our approach to two domains: synthesizing text editing programs and inferring 2D and 3D graphics programs.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13927">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #171</div>
            <div class="maincardBody">Seeing the Wind: Visual Wind Speed Prediction with a Coupled Convolutional and Recurrent Neural Network</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15663">
                    Applications -- Sustainability</a>
                </div>
            
            <div class="maincardFooter">Jennifer Cardona &middot; Michael Howland &middot; John Dabiri</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-4701" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://purl.stanford.edu/gj241kq9837" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://purl.stanford.edu/xx328hs4974" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Wind energy resource quantification, air pollution monitoring, and weather forecasting all rely on rapid, accurate measurement of local wind conditions. Visual observations of the effects of wind---the swaying of trees and flapping of flags, for example---encode information regarding local wind conditions that can potentially be leveraged for visual anemometry that is inexpensive and ubiquitous. Here, we demonstrate a coupled convolutional neural network and recurrent neural network architecture that extracts the wind speed encoded in visually recorded flow-structure interactions of a flag and tree in naturally occurring wind. Predictions for wind speeds ranging from 0.75-11 m/s showed agreement with measurements from a cup anemometer on site, with a root-mean-squared error approaching the natural wind speed variability due to atmospheric turbulence. Generalizability of the network was demonstrated by successful prediction of wind speed based on recordings of other flags in the field and in a controlled wind tunnel test. Furthermore, physics-based scaling of the flapping dynamics accurately predicts the dependence of the network performance on the video frame rate and duration.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14232">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #176</div>
            <div class="maincardBody">Recurrent Space-time Graph Neural Networks</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15665">
                    Applications -- Video Analysis</a>
                </div>
            
            <div class="maincardFooter">Andrei Nicolicioiu &middot; Iulia Duta &middot; Marius Leordeanu</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6993" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1betWf6eX_rqLwInyp2SzXJespuSW227S/view?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/15rNBDF2V-kTk9QGB-GzS5D8u0Bv-4WMJ/view?usp=sharing" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://drive.google.com/file/d/1OY4J4kJV6XF6kH0ZWIthsfUYFK138SMd/view?usp=sharing" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" > Learning in the space-time domain remains a very challenging problem in machine learning and computer vision. Current computational models for understanding spatio-temporal visual data are heavily rooted in the classical single-image based paradigm. It is not yet well understood how to integrate information in space and time into a single, general model. We propose a neural graph model, recurrent in space and time, suitable for capturing both the local appearance and the complex higher-level interactions of different entities and objects within the changing world scene. Nodes and edges in our graph have dedicated neural networks for processing information. Nodes operate over features extracted from local parts in space and time and over previous memory states. Edges process messages between connected nodes at different locations and spatial scales or between past and present time. Messages are passed iteratively in order to transmit information globally and establish long range interactions. Our model is general and could learn to recognize a variety of high level spatio-temporal concepts and be applied to different learning tasks. We demonstrate, through extensive experiments and ablation studies, that our model outperforms strong baselines and top published methods on recognizing complex activities in video. Moreover, we obtain state-of-the-art performance on the challenging Something-Something human-object interaction dataset.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13982">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #177</div>
            <div class="maincardBody">ObjectNet: A large-scale bias-controlled dataset for pushing the limits of object recognition models</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15666">
                    Data, Challenges, Implementations, and Software -- Data Sets or Data Repositories</a>
                </div>
            
            <div class="maincardFooter">Andrei Barbu &middot; David Mayo &middot; Julian Alverio &middot; William Luo &middot; Christopher Wang &middot; Dan Gutfreund &middot; Josh Tenenbaum &middot; Boris Katz</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-5037" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://objectnet.dev/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://objectnet.dev/slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://objectnet.dev/3-minute-video.avi" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We collect a large real-world test set, ObjectNet, for object recognition with controls where object backgrounds, rotations, and imaging viewpoints are random. Most scientific experiments have controls, confounds which are removed from the data, to ensure that subjects cannot perform a task by exploiting trivial correlations in the data. Historically, large machine learning and computer vision datasets have lacked such controls. This has resulted in models that must be fine-tuned for new datasets and perform better on datasets than in real-world applications. When tested on ObjectNet, object detectors show a 40-45% drop in performance, with respect to their performance on other benchmarks, due to the controls for biases. Controls make ObjectNet robust to fine-tuning showing only small performance increases. We develop a highly automated platform that enables gathering datasets with controls by crowdsourcing image capturing and annotation. ObjectNet is the same size as the ImageNet test set (50,000 images), and by design does not come paired with a training set in order to encourage generalization. The dataset is both easier than ImageNet (objects are largely centered and unoccluded) and harder (due to the controls). Although we focus on object recognition here, data with controls can be gathered at scale using automated tools throughout machine learning to generate datasets that exercise models in new ways thus providing valuable feedback to researchers. This work opens up new avenues for research in generalizable, robust, and more human-like computer vision and in creating datasets where results are predictive of real-world performance.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_13419">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #181</div>
            <div class="maincardBody">GENO -- GENeric Optimization for Classical Machine Learning</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15667">
                    Data, Challenges, Implementations, and Software -- Software Toolkits</a>
                </div>
            
            <div class="maincardFooter">Soeren Laue &middot; Matthias Mitterreiter &middot; Joachim Giesen</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-1294" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.geno-project.org/posterNeurIPS.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.geno-project.org/slidesNeurIPS.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="http://www.geno-project.org/videoNeurIPS.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Although optimization is the longstanding, algorithmic backbone of machine learning new models still require the time-consuming implementation of new solvers. As a result, there are thousands of implementations of optimization algorithms for machine learning problems. A natural question is, if it is always necessary to implement a new solver, or is there one algorithm that is sufficient for most models. Common belief suggests that such a one-algorithm-fits-all approach cannot work, because this algorithm cannot exploit model specific structure. At least, a generic algorithm cannot be efficient and robust on a wide variety of problems. Here, we challenge this common belief. We have designed and implemented the optimization framework GENO (GENeric Optimization) that combines a modeling language with a generic solver. GENO takes the declaration of an optimization problem and generates a solver for the specified problem class. The framework is flexible enough to encompass most of the classical machine learning problems. We show on a wide variety of classical but also some recently suggested problems that the automatically generated solvers are (1) as efficient as well engineered, specialized solvers, (2) more efficient by a decent margin than recent state-of-the-art solvers, and (3) orders of magnitude more efficient than classical modeling language plus solver approaches.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14602">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #185</div>
            <div class="maincardBody">On the Downstream Performance of Compressed Word Embeddings</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15668">
                    Deep Learning -- Embedding Approaches</a>
                </div>
            
            <div class="maincardFooter">Avner May &middot; Jian Zhang &middot; Tri Dao &middot; Christopher Ré</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-6320" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://avnermay.github.io/compressed_embeddings_neurips_2019_poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://avnermay.github.io/compressed_embeddings_neurips_2019_slides.pdf" class="btn btn-default btn-xs href_PDF" title="Slides"><i class="fa fa-file-pdf-o"></i> Slides</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://avnermay.github.io/compressed_embeddings_neurips_2019_video.mp4" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >Compressing word embeddings is important for deploying NLP models in memory-constrained settings. However, understanding what makes compressed embeddings perform well on downstream tasks is challenging---existing measures of compression quality often fail to distinguish between embeddings that perform well and those that do not. We thus propose the eigenspace overlap score as a new measure. We relate the eigenspace overlap score to downstream performance by developing generalization bounds for the compressed embeddings in terms of this score, in the context of linear and logistic regression. We then show that we can lower bound the eigenspace overlap score for a simple uniform quantization compression method, helping to explain the strong empirical performance of this method. Finally, we show that by using the eigenspace overlap score as a selection criterion between embeddings drawn from a representative set we compressed, we can efficiently identify the better performing embedding with up to 2x lower selection error rates than the next best measure of compression quality, and avoid the cost of training a separate model for each task of interest.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14243">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #202</div>
            <div class="maincardBody">Piecewise Strong Convexity of Neural Networks</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15631">
                    Deep Learning -- Optimization for Deep Networks</a>
                </div>
            
            <div class="maincardFooter">Tristan Milne</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-7101" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://www.youtube.com/watch?v=z89BTMQGVng" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We study the loss surface of a feed-forward neural network with ReLU non-linearities, regularized with weight decay. We show that the regularized loss function is piecewise strongly convex on an important open set which contains, under some conditions, all of its global minimizers. This is used to prove that local minima of the regularized loss function in this set are isolated, and that every differentiable critical point in this set is a local minimum, partially addressing an open problem given at the Conference on Learning Theory (COLT) 2015; our result is also applied to linear neural networks to show that with weight decay regularization, there are no non-zero critical points in a norm ball obtaining training error below a given threshold. We also include an experimental section where we validate our theoretical work and show that the regularized loss function is almost always piecewise strongly convex when restricted to stochastic gradient descent trajectories for three standard image classification problems.</p>
			</div>
			<hr>
		
			<div class="maincard narrower Tutorial">
				
    <div class="maincard narrower poster" id="maincard_14346">
            <div class='pull-right maincardHeader maincardType'>Poster</div>
            <div class="maincardHeader">{daterange} @ East Exhibition Hall B + C  #203</div>
            <div class="maincardBody">PowerSGD: Practical Low-Rank Gradient Compression for Distributed Optimization</div>
            
                <div class='pull-right maincardHeader maincardType'>In
                    <a href="/Conferences/2019/Schedule?showParentSession=15631">
                    Deep Learning -- Optimization for Deep Networks</a>
                </div>
            
            <div class="maincardFooter">Thijs Vogels &middot; Sai Praneeth Karimireddy &middot; Martin Jaggi</div>
            
                <div>
                    
                <span class="">
                    [<a href="http://papers.nips.cc/paper/by-source-2019-8002" class="btn btn-default btn-xs href_PDF" title="Paper"><i class="fa fa-file-pdf-o"></i> Paper</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://tvogels.nl/powersgd/poster.pdf" class="btn btn-default btn-xs href_PDF" title="Poster"><i class="fa fa-file-pdf-o"></i> Poster</a>]&nbsp;
                </span>
                <span class="">
                    [<a href="https://youtu.be/xVxSu7KGtHw" class="btn btn-default btn-xs href_Video" title="3 min Video"><i class="fa fa-video-camera"></i> 3 min Video</a>]&nbsp;
                </span>
                </div>
            
    </div>
    <br>
				<p class="abstract" >We study gradient compression methods to alleviate the communication bottleneck in data-parallel distributed optimization. Despite the significant attention received, current compression schemes either do not scale well, or fail to achieve the target test accuracy. We propose a low-rank gradient compressor that can i) compress gradients rapidly, ii) efficiently aggregate the compressed gradients using all-reduce, and iii) achieve test performance on par with SGD. The proposed algorithm is the only method evaluated that achieves consistent wall-clock speedups when benchmarked against regular SGD with an optimized communication backend. We demonstrate reduced training times for convolutional networks as well as LSTMs on common datasets.</p>
			</div>
			<hr>
		
	
</div>

<script>
$().ready(function () {
	$('.abstract').toggle();
})
</script>



        </main>
        <!--END BLOCK CONTENT-->


    </div><!--/row-->


</div><!--/Page.container-->


<!--Footer for the edit button-->

<script src="/static/core/bootstrap-wizard/src/bootstrap-wizard.js" type="text/javascript"></script>
<script>
    /*
      Set up the feedback button with the correct URL for this page.
    */

    /*Get the URL for this page and parse out just the path part*/


    feedbackPath = "/Help/Feedback?path=" + encodeURIComponent(location.protocol + "//" + location.hostname + ":" + location.port + location.pathname + location.search);


    /*Poke that as the hrefinto the button*/

    $("#feedback").attr("href", feedbackPath);

    $(function () {
        if ($(".editable").length == 0) {
            $("#editFooter").hide();
        }
    })
</script>

<!-- Bootstrap core JavaScript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->


<script src="/static/core/js/fastclick.min.js" type="text/javascript"></script>


<script>
    $(document).ready(function () {
        $('[data-toggle=offcanvas]').click(function () {
            $('.row-offcanvas').toggleClass('active');
        });
    });
</script>


<script src="/static/core/glyphicons_pro/glyphicons/web/html_css/scripts/modernizr.js" type="text/javascript"
        charset="utf-8"></script>


<!--We don't know if there are editable tags on the page until after the django template engine has rendered the page. So,
test in javascript for "editable" tags and if present, load the ckeditor engine dynamically. -->

<script>
  if (document.getElementsByClassName('editable').length > 0 ){
    var script   = document.createElement("script");
    script.type  = "text/javascript";
    script.src   = "/static/core/ckeditor/ckeditor.js";    // use this for linked script
    script.text  = "alert('voila!');"               // use this for inline script
    document.body.appendChild(script);
  }
  
</script>


<script>
function fetchContent(){
  $(".editable").each(function(index){
    var myself = this;
    var docvID = this.getAttribute('documentversion');
    var blurbtext = this.getAttribute("blurbtext");
    $.ajax({
       url: "/Admin/RetrieveDocumentVersion",
       type:"POST",
       data:{
           docvID : docvID,
           blurbtext : blurbtext,
           csrfmiddlewaretoken: csrftoken,
       },
       success: function(data, textStatus, jqXHR) {
           myself.setAttribute("contenteditable", "true");
           myself.innerHTML = data;
           CKEDITOR.inline(myself.id);
       },
    });
  })
}

$("#nopageedit").hide();
function start_edit(){

    $(".editable").addClass("warning-ring");

    //At the beginning of an edit, we need to replace the content of the
    //editable div with it's databased content in order to preserve the
    //template tags. We want the tag, not the rendered tag.

    /* You must remove any countdown.js timers on the page before replacing the page with it's
    document version otherwise, Javascript will throw an exception.  */


    jq2("[class$='-countdown']").parent().remove();
    fetchContent();
    $(".editable").attr("onblur", "ckeditorsave(this)");
    window.status.bold();
    window.status = "Click outside the editable area to save. Changes are LIVE!! Refresh page to discard changes.";
    $("#editpage").hide();
    $("#noeditpage").show();
}


function stop_edit(){
    $("#noeditpage").hide();
    $("#editpage").show();
    setTimeout(function () {window.location.reload();}, 150);

}
function ckeditorsave(event){
  for (var name in CKEDITOR.instances){
    if ( CKEDITOR.instances[name].checkDirty() ){
      editor = CKEDITOR.instances[name];
      saveEditable(editor);
    }
  }
}

function saveEditable(editor){
  var content = editor.getData();
  var contentId = editor.name;
  var pageId = window.location.pathname;
  var originalContent = "N/A";
  var documentversion = editor.container.getAttribute("documentversion");
  var blurbtext = editor.container.getAttribute("blurbtext");
  if ( contentId.match(/-aloha$/gi) ) {
    contentId = contentId.replace( /-aloha/gi, '' );
  }  /*I'm not sure what this does but it seems like it would matter*/
  var request = jQuery.ajax({
    url: "/Admin/SaveDocument",
    type: "POST",
    data: {
      content : content,
      originalContent: originalContent,
      contentId : contentId,
      pageId : pageId,
      documentversion:documentversion,
      blurbtext : blurbtext,
      csrfmiddlewaretoken: csrftoken
    },
    success: function(data){
        if (data['message']){
            alert(data['message']);
        }

    },
    error: function(xqXHR, textStatus){
        window.status = textStatus;
        debugger;
    }

  });

};




</script>

<script type="text/javascript">
       jQuery(document).ajaxSend(function(event, xhr, settings) {
           function getCookie(name) {
               var cookieValue = null;
               if (document.cookie && document.cookie != '') {
                   var cookies = document.cookie.split(';');
                   for (var i = 0; i < cookies.length; i++) {
                       var cookie = jQuery.trim(cookies[i]);
                       // Does this cookie string begin with the name we want?
                       if (cookie.substring(0, name.length + 1) == (name + '=')) {
                           cookieValue = decodeURIComponent(cookie.substring(name.length + 1));
                           break;
                       }
                   }
               }
               return cookieValue;
           }
           function sameOrigin(url) {
               // url could be relative or scheme relative or absolute
               var host = document.location.host; // host + port
               var protocol = document.location.protocol;
               var sr_origin = '//' + host;
               var origin = protocol + sr_origin;
               // Allow absolute or scheme relative URLs to same origin
               return (url == origin || url.slice(0, origin.length + 1) == origin + '/') ||
                   (url == sr_origin || url.slice(0, sr_origin.length + 1) == sr_origin + '/') ||
                   // or any other URL that isn't scheme relative or absolute i.e relative.
                   !(/^(\/\/|http:|https:).*/.test(url));
           }
           function safeMethod(method) {
               return (/^(GET|HEAD|OPTIONS|TRACE)$/.test(method));
           }

           if (!safeMethod(settings.type) && sameOrigin(settings.url)) {
               xhr.setRequestHeader("X-CSRFToken", getCookie('csrftoken'));
           }
       });
</script>


<script>
    window.addEventListener('load', function () {
        /*Minified*/
        var attachFastClick = Origami.fastclick;
        attachFastClick(document.body);
        /*Not minified*/
        /*FastClick.attach(document.body);*/
    }, false);


</script>

<!--Prevent links from opening externally-->



<div class='hidden'>Successful Page Load</div>
<div class='hidden'>Do not remove: This comment is monitored to verify that the site is working properly</div>


</body>
</html>
