[
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-3824",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/67974233917cea0e42a49a2fb7eb4cf4-Paper.pdf",
        "paper_title": "Updates of Equilibrium Prop Match Gradients of Backprop Through Time in an RNN with Static Input",
        "paper_author": "Maxence Ernoult &middot; Julie Grollier &middot; Damien Querlioz &middot; Yoshua Bengio &middot; Benjamin Scellier",
        "video_link": "https://www.youtube.com/watch?v=Xb5sM0NRy_0",
        "abstract": "Equilibrium Propagation (EP) is a biologically inspired learning algorithm for\n",
        "transcript": "this is a brief overview of a paper to appear at Europe's 2019 equilibrium propagation or egg drop is a very cleans by the alternative to back prop for computing error gradients it is similar to the contrast if a beam learning algorithm used to Train Boltzmann machines however it's continuous time formulation in terms very long simulation times our work proposes the discrete inversion effect prop that in specific conditions is equivalent to backpack through time and enables to Train convolutional architectures first and foremost what is egg prop like prop is used to Train islands which are fed ways that you can put eggs and minimize the energy to steady state est\u00e3o in this context training consists in making estar to coincide the best with a given target way to Train such a network we would generally perform a first full-time phase then perform by propagation through time but egg prop proceeds differently instead of propagating the arrow backward for the first phase the error is included as an elastic force that matches the system to a second steady state s theta star during a second phase the learning will consequently reads like the difference between the two equilibria we call this setting the energy base sitting to compute error gradients mac prep through time goes backward in time while egg prop goes forward in time and the effort looks very different still they are intimately related our theorem is the following provided that the first phase is converged the temporal updates of the system the second phase of egg-drop are equal to the gradients provided by back birth through time each temporal updated egg drop on the right is matched in the same color with the corresponding gradient computed by backward through time on the Left more formally we can define the gradients of Bagdad through time and the temporal update effect prop to rewrite the theorem we can numerically check this property when the system perfectly fulfills the conditions of the theorem now that all theorem all in a broader setting where the dynamics can be simply defined in terms of a primitive function Phi now what is this useful for interestingly this property can also be useful when the system does not exactly meet the requirements of our theorem this is the case for the full connected and convolutional architectures we have studied which do not exactly have a primitive function it turns out that even in this approximate setting the prediction of the theorem is still very well observed this encourages training experiences as anticipated or training results are the same that those we obtain with back prep through time our simplified equations accelerate simulations by a factor five to eight finally or convolutional architecture achieve the best performance ever reported with egg-drop on a list our work sheds new light on egg-drop and enables to train new networks with simplified equations still it has yet to be scaled to deeper architectures this study is one more step towards energy efficient implementations of backrub out of device physics see your paper for more details",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6214",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/05e97c207235d63ceb1db43c60db7bbb-Paper.pdf",
        "paper_title": "Uniform convergence may be unable to explain generalization in deep learning",
        "paper_author": "Vaishnavh Nagarajan &middot; J. Zico Kolter",
        "video_link": "https://www.youtube.com/watch?v=o3GfnEjTdIQ",
        "abstract": "Aimed at explaining the surprisingly good generalization behavior of overparameterized deep networks, recent works have developed a variety of generalization bounds for deep learning,  all  based on the fundamental learning-theoretic technique of uniform convergence. While\n",
        "transcript": "you may have come across these two papers that were published a few years ago highlighting a particular aspect of deep learning that we had all been taking for granted until then why do deep networks with so many parameters that are made to fit the training data to zero error learn a nice function that generalizes so well to unseen data conventional wisdom suggests that such complex models should learn a bad function that simply memorizes the labels on the training data this is a question that has caught the attention of both theoreticians and practitioners alike and has since become a pretty active area of research so what do these papers say mathematically speaking conventional bounds of the generalization gap like the VC dimension cannot explain this generalization puzzle as these bounds estimate the representational complexity of the network by its parameter count hence yielding vacuous generalization paths to this end these two papers proposed that we should derive more refined bounds by taking into account the fact that SGD implicitly controls the representational capacity of the network and this suggestion resulted in an exciting line of work that found new ways of deriving generalization bounds in deep learning using many different learning theoretic tools while these tools may look pretty different externally in essence they are all the same learning theoretic tool called uniform convergence unfortunately all these existing uniform convergence bounds are still either parameter account abandoned or requires some kinds of explicit modification or regularization to the network learn bias Chile in addition to these issues in our paper we bring to light some more concerning problems troubling these paths first is our finding that even though the true generalization gap decreases with training set size as expected these bounds in contrast increase with the training set size hence parameter count dependence is not the only problem plaguing these bounds next and more importantly we present some example binary classification tasks tasks and deep learning where we show that even though as Chile generalizes well it learns a decision boundary that is complex in a certain way that all uniform convergence bounds are vacuous in these settings that is uniform convergence provably fails to explain generalization in these cases through these two findings we call into question the current approach of using uniform convergence to understand generalization and deep learning perhaps it's time to look for a new tool",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-9024",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/952285b9b7e7a1be5aa7849f32ffff05-Paper.pdf",
        "paper_title": "Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks",
        "paper_author": "Aaron Voelker &middot; Ivana Kaji\u0107 &middot; Chris Eliasmith",
        "video_link": "https://docs.google.com/document/d/1uarYP9YqcKx2Qh7sHJJhrY87C-mVZbNTAVqRKVPDXmI/edit",
        "abstract": "We propose a novel memory cell for recurrent neural networks that dynamically maintains information across long windows of time using relatively few resources. The Legendre Memory Unit~(LMU) is mathematically derived to orthogonalize its continuous-time history -- doing so by solving $d$ coupled ordinary differential equations~(ODEs), whose phase space linearly maps onto sliding windows of time via the Legendre polynomials up to degree $d - 1$. Backpropagation across LMUs outperforms equivalently-sized LSTMs on a chaotic time-series prediction task, improves memory capacity by two orders of magnitude, and significantly reduces training and inference times. LMUs can efficiently handle temporal dependencies spanning $100\\text{,}000$ time-steps, converge rapidly, and use few internal state-variables to learn complex functions spanning long windows of time -- exceeding state-of-the-art performance among RNNs on permuted sequential MNIST. These results are due to the network&#x27;s disposition to learn scale-invariant features independently of step size. Backpropagation through the ODE solver allows each layer to adapt its internal time-step, enabling the network to learn task-relevant time-scales. We demonstrate that LMU memory cells can be implemented using $m$ recurrently-connected Poisson spiking neurons, $\\mathcal{O}( m )$ time and memory, with error scaling as $\\mathcal{O}( d / \\sqrt{m} )$. We discuss implementations of LMUs on analog and digital neuromorphic hardware.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-539",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/5737034557ef5b8c02c0e46513b98f90-Paper.pdf",
        "paper_title": "Point-Voxel CNN for Efficient 3D Deep Learning",
        "paper_author": "Zhijian Liu &middot; Haotian Tang &middot; Yujun Lin &middot; Song Han",
        "video_link": "https://pvcnn.mit.edu",
        "abstract": "We present Point-Voxel CNN (PVCNN) for efficient, fast 3D deep learning. Previous work processes 3D data using either voxel-based or point-based NN models. However, both approaches are computationally inefficient. The computation cost and memory footprints of the voxel-based models grow cubically with the input resolution, making it memory-prohibitive to scale up the resolution. As for point-based networks, up to 80% of the time is wasted on dealing with the sparse data which have rather poor memory locality, not on the actual feature extraction. In this paper, we propose PVCNN that represents the 3D input data in points to reduce the memory consumption, while performing the convolutions in voxels to reduce the irregular, sparse data access and improve the locality. Our PVCNN model is both memory and computation efficient. Evaluated on semantic and part segmentation datasets, it achieves much higher accuracy than the voxel-based baseline with 10\u00d7 GPU memory reduction; it also outperforms the state-of-the-art point-based models with 7\u00d7 measured speedup on average. Remarkably, the narrower version of PVCNN achieves 2\u00d7 speedup over PointNet (an extremely efficient model) on part and scene segmentation benchmarks with much higher accuracy. We validate the general effectiveness of PVCNN on 3D object detection: by replacing the primitives in Frustrum PointNet with PVConv, it outperforms Frustrum PointNet++ by 2.4% mAP on average with 1.5\u00d7 measured speedup and GPU memory reduction.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6138",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/b2ead76dfdc4ae56a2abd1896ec46291-Paper.pdf",
        "paper_title": "Identification of Conditional Causal Effects under Markov Equivalence",
        "paper_author": "Amin Jaber &middot; Jiji Zhang &middot; Elias Bareinboim",
        "video_link": "https://www.dropbox.com/s/qucyzi28s7ycka9/NeurIPS19-CID.m4v?dl=0",
        "abstract": "Causal identification is the problem of deciding whether a post-interventional distribution is computable from a combination of qualitative knowledge about the data-generating process, which is encoded in a causal diagram, and an observational distribution. A generalization of this problem restricts the qualitative knowledge to a class of Markov equivalent causal diagrams, which, unlike a single, fully-specified causal diagram, can be inferred from the observational distribution.\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-71",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/e2c420d928d4bf8ce0ff2ec19b371514-Paper.pdf",
        "paper_title": "Adversarial Examples Are Not Bugs, They Are Features",
        "paper_author": "Andrew Ilyas &middot; Shibani Santurkar &middot; Dimitris Tsipras &middot; Logan Engstrom &middot; Brandon Tran &middot; Aleksander Madry",
        "video_link": "https://youtu.be/-vhUWSHOqIM",
        "abstract": "Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features (derived from patterns in the data distribution) that are highly predictive, yet brittle and (thus) incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a {\\em misalignment} between the (human-specified) notion of robustness and the inherent geometry of the data.",
        "transcript": "this is a video summary of our paper adversarial examples aren't bugs they're features to appear at nerps 2019 the focus of our paper is on adversarial perturbations specifically we'd like to make progress towards answering why do these perturbations even exist one way that adversarial examples clear eyes this of our classifiers are unreasonably sensitive to useless patterns in the input pictorially suppose we think of our inputs as a collection of features here we have some useful features that the classifier is supposed to learn to do well on the classification task we also have some useless features that through some error and learning such as overfitting or sensitivity to label noise the classifier puts an unreasonably large weight on an adversary can change the decision of the classifier on any given input by just changing these sensitive features that don't make any sense to humans so with this model in mind let's try an experiment we'll start with the training set of a standard image classification task we'll then take a pre trained classifier for this data set and make an adversarial example for every training image after we make these adversarial examples we'll label every image with its adversarial class note that at this point the resulting data set consists entirely of adversarial examples and thus looks completely mislabeled to a human finally we'll train the classifier on this relabeled data set and test on the original test set surprisingly we get non-trivial accuracy on the unmodified test set this result indicates a flaw in our conceptual model of adversarial examples under that model crafting adversarial examples doesn't really change anything meaningful about the input and so learning anything about the true class boundary from adversarial examples would be impossible our experiment prompts us to think about adversarial examples in a different way resulting in what we'll call the robust features model the new trainings that we made in our experiment clearly had to have carried some information about how to distinguish dogs from cats on the other hand this information isn't something that humans can perceive since to us the data set just looked mislabeled this leads us to predict the existence of non robust features these are features that are actually indicative of the true label but can be easily manipulated by an adversary this conceptual model is actually pretty predictive using a pre trained robust model we tried removing non robust features from standard data sets and managed to construct training sets where standard non robust training yields robust classifiers for the original test sets in general her finding suggests that adversarial examples can arise from non robust features in the data that actually helped generalization but hurt robustness note that because these features help generalization simply learning better models may not be sufficient for fixing the problem of adversarial examples thanks for watching our paper summary you can find links here and in the description for our paper blog post and the robustness library our open source framework for module early training and manipulating standard in the robust classifiers you can also find a link to the summary video for our other NURBS 2019 paper showing the applications of robust classifiers to image synthesis tasks",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2823",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/46f76a4bda9a9579eab38a8f6eabcda1-Paper.pdf",
        "paper_title": "Empirically Measuring Concentration: Fundamental Limits on Intrinsic Robustness",
        "paper_author": "Saeed Mahloujifar &middot; Xiao Zhang &middot; Mohammad Mahmoody &middot; David Evans",
        "video_link": "https://drive.google.com/open?id=1z-97tgTqB5dH3WzQcE6kBOVJHizo5z7A",
        "abstract": "Many recent works have shown that adversarial examples that fool classifiers can be found by minimally perturbing a normal input. Recent theoretical results, starting with Gilmer et al. (2018b), show that if the inputs are drawn from a concentrated metric probability space, then adversarial examples with small perturbation are inevitable. A concentrated space has the property that any subset with \u2126(1) (e.g.,1/100) measure, according to the imposed distribution, has small distance to almost all (e.g.,  99/100) of the points in the space. It is not clear,  however,  whether these theoretical results apply to actual distributions such as images. This paper presents a method for empirically measuring and bounding the concentration of a concrete dataset which is proven to converge to the actual concentration. We use it to empirically estimate the intrinsic robustness to and L_2 and L_infinity perturbations of several image classification benchmarks. Code for our experiments is available at https://github.com/xiaozhanguva/Measure-Concentration.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5315",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/5ad742cd15633b26fdce1b80f7b39f7c-Paper.pdf",
        "paper_title": "A Game Theoretic Approach to Class-wise Selective Rationalization",
        "paper_author": "Shiyu Chang &middot; Yang Zhang &middot; Mo Yu &middot; Tommi Jaakkola",
        "video_link": "https://www.dropbox.com/s/tnr5emcp5a4wvig/video_final.mp4?dl=0",
        "abstract": "Selection of input features such as relevant pieces of text has become a common technique of highlighting how complex neural predictors operate. The selection can be optimized post-hoc for trained models or incorporated directly into the method itself (self-explaining). However, an overall selection does not properly capture the multi-faceted nature of useful rationales such as pros and cons for decisions. To this end, we propose a new game theoretic approach to class-dependent rationalization, where the method is specifically trained to highlight evidence supporting alternative conclusions. Each class involves three players set up competitively to find evidence for factual and counterfactual scenarios. We show theoretically in a simplified scenario how the game drives the solution towards meaningful class-dependent rationales. We evaluate the method in single- and multi-aspect sentiment classification tasks and demonstrate that the proposed method is able to identify both factual (justifying the ground truth label) and counterfactual (countering the ground truth label) rationales consistent with human rationalization.  The code for our method is publicly available. ",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1853",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/7503cfacd12053d309b6bed5c89de212-Paper.pdf",
        "paper_title": "Adversarial training for free!",
        "paper_author": "Ali Shafahi &middot; Mahyar Najibi &middot; Mohammad Amin Ghiasi &middot; Zheng Xu &middot; John Dickerson &middot; Christoph Studer &middot; Larry Davis &middot; Gavin Taylor &middot; Tom Goldstein",
        "video_link": "https://youtu.be/v8U9mM1Vwv0",
        "abstract": "Adversarial training, in which a network is trained on adversarial examples, is one of the few defenses against adversarial attacks that withstands strong attacks. Unfortunately, the high cost of generating strong adversarial examples makes standard adversarial training impractical on large-scale problems like ImageNet. We present an algorithm that eliminates the overhead cost of generating adversarial examples by recycling the gradient information computed when updating model parameters. Our &quot;free&quot; adversarial training algorithm achieves comparable robustness to PGD adversarial training on the CIFAR-10 and CIFAR-100 datasets at negligible additional cost compared to natural training, and can be 7 to 30 times faster than other strong adversarial training methods. Using a single workstation with 4 P100 GPUs and 2 days of runtime, we can train a robust model for the large-scale ImageNet classification task that maintains 40% accuracy against PGD attacks.",
        "transcript": "hi this is a summarization for the adversarial training for free paper in which we trained robust models efficiently in supervised machine learning we train models using labeled data let's say we want to build a classifier that can distinguish a panda from a pumpkin we start off with some images of pandas and also some images of pumpkins then usually we have a neural network and we use some optimization routine such as some variant of stochastic gradient descent to build this classifier this classifier works very well on natural images and also images which come from the same distribution as our training data however it is known that these classifiers work horribly on adversarial examples given a classifier F which Maps an image X to the label why we say another example X plus Delta is something which the classifier correctly classifies as something other than Y but we want our adversarial example X plus Delta to look like the clean example X and we can have different measures of this look like property and one more popular measure is having the perturbation the Delta which we're going to add two eggs be bounded by Epsilon in some penal their different LP norm perturbation bounce can result in different looking adversarial examples in this study we are going to focus on L infinity bounded adversarial examples note that other store examples can be realistic adversarial training is one of the few defenses which has not been broken and is known to make networks robust against adversarial perturbations a special training involves solving a min/max optimization problem where the Maximizer is the adversary which has access to these Delta perturbations which are going to be added to the clean image and the minimizer is the network which has access to the network parameters W the way that this is practically solved is by training on address show examples on the fly so we efficiently what we do is we make adversarial examples and we instead of training on natural examples we train on adversarial examples and this way we can become robust against that force early examples there are many ways that we can generate adversarial examples to train on and it is known that if we train on weak adversarial examples we will not be robust against a stronger adverse real examples so we usually do train on address or examples made in an iterative fashion such as the projected gradient descent method in KPG d adversarial training we take a mini batch and we have to produce a dresser examples for this mini batch so what we do is we forward pass this mini batch all the way to the classification layer and we backward pass that to compute the gradients with respect to the mini batch and that basically gives us one update on the adversary examples and we do this K times after K times we have a mini batch of adversarial examples which is here and what we do is we basically forward and backward pass this one last time and this time we do update the network weights and after this we go on to the next mini batch again we do K forward and backward passes without updating the network parameters to generate that versus aerial perturbations and then we train on these adversarial examples finally after these case steps so basically for every minimization update now we have an additional case forward and backward steps which we are taking without updating the network parameters this is why adversarial training has this K factor overhead where the K is the number of iterations used for generating the adversarial examples well adversarial training small data sets and small networks is feasible the question is whether it is practical to adversary train a large data set such as emission it note that to naturally sure in a resonant 50 we need four GPUs and two days so if you want to adversary train the same resonance 50 on image net data using a seven step PD attack now we need two weeks whether adversarial training is impractical for image net depends on how many GPUs one research lab hats so adversarial on imagenet was done before using hundreds of GPUs and even TP use we wanted to make a torso training doable for labs with small or limited number of computer resources so that's why we came up with add virtual training for free in adverse spell training for free we remove the additional K factor overhead from traditional adversarial training so that our training time is the same as natural training to do so every time that we do a backward pass on the network we use the gradients to update the network parameters so unlike adversarial training where we have this additional k4 and backward passes where we don't update the network parameters using them here we update the network parameters every time so we have this global perturbation which is initialized at zero and we add that to the first mini batch so this is the first step of training and we forward pass and then compute the gradients all the way to the input and we use all the gradients of the weights to update the weights and we use the gradient with respect to the input to update this global perturbation and then in the next minimization iteration we train on the same mini batch and we add this perturbation to the same mini batch and now again we do a forward and backward pass and we use the gradients of the weights to update the weights and we use the gradient of the perturbation to update the perturbation and we're going to replay the same mini batch 4m times the reason we do so is that if we move on to the next movie batch the gradient is computed for the previous mini batch or no longer that I created for this current mini batch after the M replay steps are over we basically add this perturbation computed on the last replace step of the previous mini batch to the next me batch note that this perturbation is acting as somewhat of a random perturbation and again using this next mini batch we do M replays and M for them backward passes and every time we simultaneously update the perturbation and also the network points so adversarial training for free is benefiting from the fact that we're updating both the perturbation under Network parameters in one pass simultaneously and it only has one hyper parameter this replay and this replay is somehow simulating the K steps of PGD adversarial training when we look at our results on the cypher 10 benchmark we can see that compared to the 7 step PD train model which is this last row we can train a lot faster and we have robustness which is comparable to that so every column here is referring to a different type of attack and every row here except for our last row is referring to one of our models with a different replay parameter note that for the replay plummer 8 we have more robustness compared to the adversary train model even though our training time is a lot less and it is comparable to a natural train model as Michelle training for free also has additional benefits which add virtual training hat for example our free method still maintains the interpretable gradients characteristics of robust models so for example if we look at this cat and we try to basically make this cat into something else for a robust model if we allow the perturbation to be large here we're allowing the perturbation to be 50 out of 255 then this cat would turn into this horse which is not true if we had a naturally trained model also our models have smooth and flat and lost surfaces if we look at the laws respect to the input we can see that compared to a natural trained model the robust models such as free our free end models have very smooth lost surfaces we use our outer sole training for free algorithm to train different models on imagenet similar to the case for C 410 we see that we can basically train robust models using different replay parameters and as we increase the replay parameter and our accuracy on natural examples drops but up to some point our robustness increases the good thing about that virtual training for free is that since it's a fast method for training robust models we can test a lot of hypotheses for example we can see that similar to the case which is well-known as we increase the networks capacity our robustness increases our original training for free code is available in both pi torch and tensorflow and can be found on our github repos thank you very much and we hope you liked this work",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2823",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/46f76a4bda9a9579eab38a8f6eabcda1-Paper.pdf",
        "paper_title": "Empirically Measuring Concentration: Fundamental Limits on Intrinsic Robustness",
        "paper_author": "Saeed Mahloujifar &middot; Xiao Zhang &middot; Mohammad Mahmoody &middot; David Evans",
        "video_link": "https://drive.google.com/open?id=1z-97tgTqB5dH3WzQcE6kBOVJHizo5z7A",
        "abstract": "Many recent works have shown that adversarial examples that fool classifiers can be found by minimally perturbing a normal input. Recent theoretical results, starting with Gilmer et al. (2018b), show that if the inputs are drawn from a concentrated metric probability space, then adversarial examples with small perturbation are inevitable. A concentrated space has the property that any subset with \u2126(1) (e.g.,1/100) measure, according to the imposed distribution, has small distance to almost all (e.g.,  99/100) of the points in the space. It is not clear,  however,  whether these theoretical results apply to actual distributions such as images. This paper presents a method for empirically measuring and bounding the concentration of a concrete dataset which is proven to converge to the actual concentration. We use it to empirically estimate the intrinsic robustness to and L_2 and L_infinity perturbations of several image classification benchmarks. Code for our experiments is available at https://github.com/xiaozhanguva/Measure-Concentration.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1034",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/bdb106a0560c4e46ccc488ef010af787-Paper.pdf",
        "paper_title": "Multi-marginal Wasserstein GAN",
        "paper_author": "Jiezhang Cao &middot; Langyuan Mo &middot; Yifan Zhang &middot; Kui Jia &middot; Chunhua Shen &middot; Mingkui Tan",
        "video_link": "http://caojiezhang.com/video/NeurIPS2019_MWGAN_video.mp4",
        "abstract": "Multiple marginal matching problem aims at learning mappings to match a source domain to multiple target domains and it has attracted great attention in many applications, such as multi-domain image translation. However, addressing this problem has two critical challenges: (i) Measuring the multi-marginal distance among different domains is very intractable; (ii) It is very difficult to exploit cross-domain correlations to match the target domain distributions. In this paper, we propose a novel Multi-marginal Wasserstein GAN (MWGAN) to minimize Wasserstein distance among domains. Specifically, with the help of multi-marginal optimal transport theory, we develop a new adversarial objective function with inner- and inter-domain constraints to exploit cross-domain correlations. Moreover, we theoretically analyze the generalization performance of MWGAN, and empirically evaluate it on the balanced and imbalanced translation tasks. Extensive experiments on toy and real-world datasets demonstrate the effectiveness of MWGAN.  ",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4985",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/785ca71d2c85e3f3774baaf438c5c6eb-Paper.pdf",
        "paper_title": "Correlation clustering with local objectives",
        "paper_author": "Sanchit Kalhan &middot; Konstantin Makarychev &middot; Timothy Zhou",
        "video_link": "https://www.youtube.com/watch?v=0s1LF5qL2Do",
        "abstract": "Correlation Clustering is a powerful graph partitioning model that aims to cluster items based on the notion of similarity between items. An instance of the Correlation Clustering problem consists of a graph G (not necessarily complete) whose edges are labeled by a binary classifier as\n",
        "transcript": "this video presents the paper correlation clustering with local objectives which describes improved approximation algorithms for several variants of the correlation clustering problem in machine learning correlation clustering is a general framework for doing cluster analysis given some objects and information about which pairs are similar it is similar we would like to group the objects into clusters so that similar objects are together and the similar ones are apart this problem is distinct from other problems such as k-means clustering because we don't make any assumptions about how many clusters there is that we would like to all come to discover this information by itself more formally we are given a graph G with n vertices and edges labeled according to whether their end points are similar or not suppose we cluster the vertices in some way an edge disagrees with the clustering if it is a similar edge across two clusters or the similar edge inside one the classical correlation clustering problem asks us to find a clustering which minimizes the total number of disagreements unfortunately this problem is np-hard so we probably can't find the best clustering to get around this difficulty we can design approximation algorithms which return a clustering with the cost within some small factor of the optimal cost there has been a significant amount of research on finding such algorithms in some applications however total disagreement might not be the best objective to think about suppose that the vertices represent products in Amazon and we use clustering to recommend similar products buyers if most of the disagreements are instant to a few courtesies then a few products will solve very poorly compared to the others we would like to make sure that the clustering is fair and this says that there are only a few disagreements at each vertex these considerations let the further research more local objectives such as minimizing the maximum disagreement on any single vertex although this minimax objective is more fair it completely ignores how much disagreement there is over all we would like an objective function which looks at both the global and local pictures to this end we define the disagreement vector which lists how many edges disagree with our clustering at each vertex then we can think about minimizing the norm of this vector in L Q space a classical correlation clustering problem minimizes the l1 norm while the minimax version minimizes the elephant any norm by looking at norms in between such as the l2 norm we find clusters that give a more balanced perspective on our data in our paper we give new results for correlation clustering in the lq norm for any queue on complete graphs and bipartite graphs we achieve a 5 approximation which improves over the previous 7 approximation we also get the first approximation algorithms for correlation clustering on arbitrary graphs in general lq norms in particular in the l2 norm we get a fourth root of n approximation finally there is another version of this problem which looks the maximum total disagreement inside a single cluster instead of over the entire graph for this objective we find a two approximation which improves over their previous log of n approximation for a detail description of our algorithms please check out our paper thank you for watching",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5511",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/3cc697419ea18cc98d525999665cb94a-Paper.pdf",
        "paper_title": "On Fenchel Mini-Max Learning",
        "paper_author": "Chenyang Tao &middot; Liqun Chen &middot; Shuyang Dai &middot; Junya Chen &middot; Ke Bai &middot; Dong Wang &middot; Jianfeng Feng &middot; Wenlian Lu &middot; Georgiy Bobashev &middot; Lawrence Carin",
        "video_link": "https://github.com/chenyang-tao/FML/tree/master/video",
        "abstract": "Inference, estimation, sampling and likelihood evaluation are four primary goals of probabilistic modeling. Practical considerations often force modeling approaches to make compromises between these objectives. We present a novel probabilistic learning framework, called Fenchel Mini-Max Learning (FML), that accommodates all four desiderata in a flexible and scalable manner. Our derivation is rooted in classical maximum likelihood estimation, and it overcomes a longstanding challenge that prevents unbiased estimation of unnormalized statistical models. By reformulating MLE as a mini-max game, FML enjoys an unbiased training objective that (i) does not explicitly involve the intractable normalizing constant and (ii) is directly amendable to stochastic gradient descent optimization. To demonstrate the utility of the proposed approach, we consider learning unnormalized statistical models, nonparametric density estimation and training generative models, with encouraging empirical results presented. ",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4340",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/61f3a6dbc9120ea78ef75544826c814e-Paper.pdf",
        "paper_title": "Solving Interpretable Kernel Dimensionality Reduction",
        "paper_author": "Chieh Wu &middot; Jared Miller &middot; Yale Chang &middot; Mario Sznaier &middot; Jennifer Dy",
        "video_link": "https://youtu.be/q1ETeX3HvPY",
        "abstract": "Kernel dimensionality reduction (KDR) algorithms find a low dimensional representation of the original data by optimizing kernel dependency measures that are capable of capturing nonlinear relationships. The standard strategy is to first map the data into a high dimensional feature space using kernels prior to a projection onto a low dimensional space. While KDR methods can be easily solved by keeping the most dominant eigenvectors of the kernel matrix, its features are no longer easy to interpret.  Alternatively, Interpretable KDR (IKDR) is different in that it projects onto a subspace \\textit{before} the kernel feature mapping, therefore, the projection matrix can indicate how the original features linearly combine to form the new features. Unfortunately, the IKDR objective requires a non-convex manifold optimization that is difficult to solve and can no longer be solved by eigendecomposition. Recently, an efficient iterative spectral (eigendecomposition) method (ISM) has been proposed for this objective in the context of alternative clustering. However, ISM only provides theoretical guarantees for the Gaussian kernel. This greatly constrains ISM&#x27;s usage since any kernel method using ISM is now limited to a single kernel. This work extends the theoretical guarantees of ISM to an entire family of kernels, thereby empowering ISM to solve any kernel method of the same objective. In identifying this family, we prove that each kernel within the family has a surrogate $\\Phi$ matrix and the optimal projection is formed by its most dominant eigenvectors. With this extension, we establish how a wide range of IKDR applications across different learning paradigms can be solved by ISM. To support reproducible results, the source code is made publicly available on  \\url{https://github.com/ANONYMIZED}.",
        "transcript": "hi everybody my name is J and this is the video presentation for nips 20 19 on how to solve interpretable kernel dimension reduction o source codes are available on github the purpose of dimension reduction is to reduce the number of features by keeping only the most important information this reduces the size of the data and make it easier to handle principal component analysis or PCA is currently by far the most popular dimension reduction technique given some data X PCA finds the W so that W X retains the most important information and most importantly it is actually interpreted well as you can see that we can see how the new features relate directly to the previous one for example if here we have a W we can see and interpret how the new features related to the old features unfortunately PCA only captures linear relationship so in this example when the relationship are actually not linear if you perform PCA it has tendency of grouping everything together so that you can't tell the blue and the green apart anymore ideally we will want something like this where the blue and the green are separated in the original image we want them to also be separated now this requires us to also capture the nonlinear relationship from the kernel community we know that if you first project the data to some higher dimensional feature space then if we do PCA after that we can now capture nonlinear relationship this technique is called kernel pca or just k pca now kpc is very powerful but you can't really use the labels help you guide the dimensional reduction and to since k pca is just PCA in the feature space it's not obvious what they mean for example here is the Gaussian kernel feature map as you look at this it's not too obvious what running PCA on these features mean therefore interpret about Colonel dimension reduction attempts to solve both both problems to perform dimension reduction K PCA first projects the data to the feature space before projecting onto a subspace W this makes the projection difficult to interpret alternatively i ka our first project the data onto a subspace W before the feature space since this is a linear projection that captures nonlinear relationship the result becomes interpretable commonly we use asic to achieve this Itzik maximizes the dependence between two variables in the feature space so here H SEC measures the dependence between X W and the label Y by finding the W that maximizes the dependency in the feature space i KD R can be accomplished although this approach make the solution interpretable it is actually a very difficult problem to solve if we just look at a generic ikd a problem gamma here is a symmetric positive semi definite matrix and ka here is the kernel matrix the kernel matrix here significantly complicates the objective here if we use the Gaussian kernel we can quickly see why this objective is so complex graphically even in low dimensions this problem is a highly non convex manifold we are trying to find the optimal point on this manifold that simultaneously intersect with this sphere which is a hyper sphere there are currently many existing ways to solve this problem however there are have performance problems too slow to difficult to implement or Annette stuck in the saddle point alternatively we propose is m to solve this problem it actually solves many of the problems with other approaches for is M we discovered that for a family of kernels each kernel has an she ate scaled covariance matrix Phi and just like PCA the solution W is the most dominant eigen vector of Phi here are some examples of kernels that's in the family we simply calculate Phi and set its most dominant eigen vector as the solution however as you may have noticed for certain kernels the Phi itself is the function of W for those cases we approximate the kernel via Taylor expansion to remove the W dependency let me show you what that looks like here we see an approximative version of Phi notice that none of them are dependent on W therefore by initially approximate Phi we can then initialize a w 0 and use this W to compute the next Phi we can repeat this process until W converges and this is the is M algorithm it's pretty simple although the is M algorithm itself looks simple the analysis required to guarantee its effectiveness was not here are all the theoretical guarantees that explains why this algorithm work to get into the detail will take too long but you can look up the proofs there in the appendices section besides the rigorous theoretical analysis yes this does work in practice and he has impact across many different domains here it is useful supervised classification problem notice that I am consistently achieves high accuracy on a 10-fold cross-validation 99% 100% 97 95 but what is most impressive is the speed difference notice that why he took other approaches almost two days I am was able to finish on the one second this enormous speed difference is repeated with other kernels as well here with a polynomial kernel below I kdr is also used for clustering again if you pause the video you will see a significant execution time improvement while getting better results besides supervised and unsupervised problems ikd I can also be used for alternative clustering here in the top image if we ask the algorithm to separate the pixels into two groups as black and white colors it will first yield this pattern however if you ask the algorithm to use a different perspective to separate the pixels the algorithm would then generate this picture notice how they both separate the pixels into black and white groups but the patterns they generate are completely different alternatively if we have pictures of people's faces and we ask the algorithm to group them the first clustering will put the same person into the same group that makes sense again if we ask them to regroup with a different perspective the algorithm would then regroup the picture based on the pose the direction which the person is facing if you have any more questions regarding to this work please come visit us on Europe's 2019 I'll post the number is four three four zero my advisor is Jennifer D and here's a picture of me thank you for watching this video and I will see you at the conference",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2137",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/9bb6dee73b8b0ca97466ccb24fff3139-Paper.pdf",
        "paper_title": "Exact Rate-Distortion in Autoencoders via Echo Noise",
        "paper_author": "Rob Brekelmans &middot; Daniel Moyer &middot; Aram Galstyan &middot; Greg Ver Steeg",
        "video_link": "http://bit.ly/2Wdm6St",
        "abstract": "Compression is at the heart of effective representation learning. However, lossy compression is typically achieved through simple parametric models like Gaussian noise to preserve analytic tractability, and the limitations this imposes on learning are largely unexplored.  Further, the Gaussian prior assumptions in models such as variational autoencoders (VAEs) provide only an upper bound on the compression rate in general.  We introduce a new noise channel, Echo noise, that admits a simple, exact expression for mutual information for arbitrary input distributions.  The noise is constructed in a data-driven fashion that does not require restrictive distributional assumptions.  With its complex encoding mechanism and exact rate regularization, Echo leads to improved bounds on log-likelihood and dominates beta-VAEs across the achievable range of rate-distortion trade-offs. Further, we show that Echo noise can outperform flow-based methods without the need to train additional distributional transformations.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-7205",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/75da5036f659fe64b53f3d9b39412967-Paper.pdf",
        "paper_title": "Communication-efficient Distributed SGD with Sketching",
        "paper_author": "Nikita Ivkin &middot; Daniel Rothchild &middot; Enayat Ullah &middot; Vladimir braverman &middot; Ion Stoica &middot; Raman Arora",
        "video_link": "http://enayatullah.github.io/sketchedsgd/video",
        "abstract": "Large-scale distributed training of neural networks is often limited by network bandwidth, wherein the communication time overwhelms the local computation time. Motivated by the success of sketching methods in sub-linear/streaming algorithms, we introduce Sketched-SGD, an algorithm for carrying out distributed SGD by communicating sketches instead of full gradients. We show that \\ssgd has favorable convergence rates on several classes of functions. When considering all communication -- both of gradients and of updated model weights -- Sketched-SGD reduces the amount of communication required compared to other gradient compression methods from $\\mathcal{O}(d)$ or $\\mathcal{O}(W)$ to $\\mathcal{O}(\\log d)$, where $d$ is the number of model parameters and $W$ is the number of workers participating in training. We run experiments on a transformer model, an LSTM, and a residual network, demonstrating up to a 40x reduction in total communication cost with no loss in final model performance. We also show experimentally that Sketched-SGD scales to at least 256 workers without increasing communication cost or degrading model performance.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-71",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/e2c420d928d4bf8ce0ff2ec19b371514-Paper.pdf",
        "paper_title": "Adversarial Examples Are Not Bugs, They Are Features",
        "paper_author": "Andrew Ilyas &middot; Shibani Santurkar &middot; Dimitris Tsipras &middot; Logan Engstrom &middot; Brandon Tran &middot; Aleksander Madry",
        "video_link": "https://youtu.be/-vhUWSHOqIM",
        "abstract": "Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features (derived from patterns in the data distribution) that are highly predictive, yet brittle and (thus) incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a {\\em misalignment} between the (human-specified) notion of robustness and the inherent geometry of the data.",
        "transcript": "this is a video summary of our paper adversarial examples aren't bugs they're features to appear at nerps 2019 the focus of our paper is on adversarial perturbations specifically we'd like to make progress towards answering why do these perturbations even exist one way that adversarial examples clear eyes this of our classifiers are unreasonably sensitive to useless patterns in the input pictorially suppose we think of our inputs as a collection of features here we have some useful features that the classifier is supposed to learn to do well on the classification task we also have some useless features that through some error and learning such as overfitting or sensitivity to label noise the classifier puts an unreasonably large weight on an adversary can change the decision of the classifier on any given input by just changing these sensitive features that don't make any sense to humans so with this model in mind let's try an experiment we'll start with the training set of a standard image classification task we'll then take a pre trained classifier for this data set and make an adversarial example for every training image after we make these adversarial examples we'll label every image with its adversarial class note that at this point the resulting data set consists entirely of adversarial examples and thus looks completely mislabeled to a human finally we'll train the classifier on this relabeled data set and test on the original test set surprisingly we get non-trivial accuracy on the unmodified test set this result indicates a flaw in our conceptual model of adversarial examples under that model crafting adversarial examples doesn't really change anything meaningful about the input and so learning anything about the true class boundary from adversarial examples would be impossible our experiment prompts us to think about adversarial examples in a different way resulting in what we'll call the robust features model the new trainings that we made in our experiment clearly had to have carried some information about how to distinguish dogs from cats on the other hand this information isn't something that humans can perceive since to us the data set just looked mislabeled this leads us to predict the existence of non robust features these are features that are actually indicative of the true label but can be easily manipulated by an adversary this conceptual model is actually pretty predictive using a pre trained robust model we tried removing non robust features from standard data sets and managed to construct training sets where standard non robust training yields robust classifiers for the original test sets in general her finding suggests that adversarial examples can arise from non robust features in the data that actually helped generalization but hurt robustness note that because these features help generalization simply learning better models may not be sufficient for fixing the problem of adversarial examples thanks for watching our paper summary you can find links here and in the description for our paper blog post and the robustness library our open source framework for module early training and manipulating standard in the robust classifiers you can also find a link to the summary video for our other NURBS 2019 paper showing the applications of robust classifiers to image synthesis tasks",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1100",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/1e6e0a04d20f50967c64dac2d639a577-Paper.pdf",
        "paper_title": "Neural networks grown and self-organized by noise",
        "paper_author": "Guruprasad Raghavan &middot; Matt Thomson",
        "video_link": "https://caltech.box.com/s/9tqfhrgo3cicoi5ue9z7qyhlsjfefdka",
        "abstract": "Living neural networks emerge through a process of growth and self-organization that begins with a single cell and results in a brain, an organized and functional computational device. Artificial neural networks, however, rely on human-designed, hand-programmed architectures for their remarkable performance. Can we develop artificial computational devices that can grow and self-organize without human intervention? In this paper, we propose a biologically inspired developmental algorithm that can \u2018grow\u2019 a functional, layered neural network from a single initial cell. The algorithm organizes inter-layer connections to construct retinotopic pooling layers. Our approach is inspired by the mechanisms employed by the early visual system to wire the retina to the lateral geniculate nucleus (LGN), days before animals open their eyes.  The key ingredients for robust self-organization are an emergent spontaneous spatiotemporal activity wave in the first layer and a local learning rule in the second layer that \u2018learns\u2019 the underlying activity pattern in the first layer.  The algorithm is adaptable to a wide-range of input-layer geometries, robust to malfunctioning units in the first layer, and so can be used to successfully grow and self-organize pooling architectures of different pool-sizes and shapes. The algorithm provides a primitive procedure for constructing layered neural networks through growth and self-organization. We also demonstrate that networks grown from a single unit perform as well as hand-crafted networks on MNIST. Broadly, our work shows that biologically inspired developmental algorithms can be applied to autonomously grow functional `brains&#x27; in-silico.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-3824",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/67974233917cea0e42a49a2fb7eb4cf4-Paper.pdf",
        "paper_title": "Updates of Equilibrium Prop Match Gradients of Backprop Through Time in an RNN with Static Input",
        "paper_author": "Maxence Ernoult &middot; Julie Grollier &middot; Damien Querlioz &middot; Yoshua Bengio &middot; Benjamin Scellier",
        "video_link": "https://www.youtube.com/watch?v=Xb5sM0NRy_0",
        "abstract": "Equilibrium Propagation (EP) is a biologically inspired learning algorithm for\n",
        "transcript": "this is a brief overview of a paper to appear at Europe's 2019 equilibrium propagation or egg drop is a very cleans by the alternative to back prop for computing error gradients it is similar to the contrast if a beam learning algorithm used to Train Boltzmann machines however it's continuous time formulation in terms very long simulation times our work proposes the discrete inversion effect prop that in specific conditions is equivalent to backpack through time and enables to Train convolutional architectures first and foremost what is egg prop like prop is used to Train islands which are fed ways that you can put eggs and minimize the energy to steady state est\u00e3o in this context training consists in making estar to coincide the best with a given target way to Train such a network we would generally perform a first full-time phase then perform by propagation through time but egg prop proceeds differently instead of propagating the arrow backward for the first phase the error is included as an elastic force that matches the system to a second steady state s theta star during a second phase the learning will consequently reads like the difference between the two equilibria we call this setting the energy base sitting to compute error gradients mac prep through time goes backward in time while egg prop goes forward in time and the effort looks very different still they are intimately related our theorem is the following provided that the first phase is converged the temporal updates of the system the second phase of egg-drop are equal to the gradients provided by back birth through time each temporal updated egg drop on the right is matched in the same color with the corresponding gradient computed by backward through time on the Left more formally we can define the gradients of Bagdad through time and the temporal update effect prop to rewrite the theorem we can numerically check this property when the system perfectly fulfills the conditions of the theorem now that all theorem all in a broader setting where the dynamics can be simply defined in terms of a primitive function Phi now what is this useful for interestingly this property can also be useful when the system does not exactly meet the requirements of our theorem this is the case for the full connected and convolutional architectures we have studied which do not exactly have a primitive function it turns out that even in this approximate setting the prediction of the theorem is still very well observed this encourages training experiences as anticipated or training results are the same that those we obtain with back prep through time our simplified equations accelerate simulations by a factor five to eight finally or convolutional architecture achieve the best performance ever reported with egg-drop on a list our work sheds new light on egg-drop and enables to train new networks with simplified equations still it has yet to be scaled to deeper architectures this study is one more step towards energy efficient implementations of backrub out of device physics see your paper for more details",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-539",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/5737034557ef5b8c02c0e46513b98f90-Paper.pdf",
        "paper_title": "Point-Voxel CNN for Efficient 3D Deep Learning",
        "paper_author": "Zhijian Liu &middot; Haotian Tang &middot; Yujun Lin &middot; Song Han",
        "video_link": "https://pvcnn.mit.edu",
        "abstract": "We present Point-Voxel CNN (PVCNN) for efficient, fast 3D deep learning. Previous work processes 3D data using either voxel-based or point-based NN models. However, both approaches are computationally inefficient. The computation cost and memory footprints of the voxel-based models grow cubically with the input resolution, making it memory-prohibitive to scale up the resolution. As for point-based networks, up to 80% of the time is wasted on dealing with the sparse data which have rather poor memory locality, not on the actual feature extraction. In this paper, we propose PVCNN that represents the 3D input data in points to reduce the memory consumption, while performing the convolutions in voxels to reduce the irregular, sparse data access and improve the locality. Our PVCNN model is both memory and computation efficient. Evaluated on semantic and part segmentation datasets, it achieves a much higher accuracy than the voxel-based baseline with 10x GPU memory reduction; it also outperforms the state-of-the-art point-based models with 7x measured speedup on average. Remarkably, the narrower version of PVCNN achieves 2x speedup over PointNet (an extremely efficient model) on part and scene segmentation benchmarks with much higher accuracy. We validate the general effectiveness of PVCNN on 3D object detection: by replacing the primitives in Frustrum PointNet with PVConv, it outperforms Frustrum PointNet++ by up to 2.4% mAP with 1.8x measured speedup and 1.4x GPU memory reduction.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-760",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/2ca65f58e35d9ad45bf7f3ae5cfd08f1-Paper.pdf",
        "paper_title": "Model Compression with Adversarial Robustness: A Unified Optimization Framework",
        "paper_author": "Shupeng Gui &middot; Haotao Wang &middot; Haichuan Yang &middot; Chen Yu &middot; Zhangyang Wang &middot; Ji Liu",
        "video_link": "https://github.com/shupenggui/ATMC/blob/master/materials/video.link",
        "abstract": "Deep model compression has been extensively studied, and state-of-the-art methods can now achieve high compression ratios with minimal accuracy loss. This paper studies model compression through a different lens: could we compress models without hurting their robustness to adversarial attacks, in addition to maintaining accuracy? Previous literature suggested that the goals of robustness and compactness might sometimes contradict. We propose a novel Adversarially Trained Model Compression (ATMC) framework. ATMC constructs a unified constrained optimization formulation, where existing compression means (pruning, factorization, quantization) are all integrated into the constraints. An efficient algorithm is then developed. An extensive group of experiments are presented, demonstrating that ATMC obtains remarkably more favorable trade-off among model size, accuracy and robustness, over currently available alternatives in various settings. The codes are publicly available at: https://github.com/shupenggui/ATMC.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2260",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/4cb811134b9d39fc3104bd06ce75abad-Paper.pdf",
        "paper_title": "A Prior of a Googol Gaussians: a Tensor Ring Induced Prior for Generative Models",
        "paper_author": "Maxim Kuznetsov &middot; Daniil Polykovskiy &middot; Dmitry Vetrov &middot; Alex Zhebrak",
        "video_link": "https://drive.google.com/file/d/1fDc9_BhTKT3gZAyCtuafL4tfuZivusia/view",
        "abstract": "Generative models produce realistic objects in many domains, including text, image, video, and audio synthesis. Most popular models\u2014Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs)\u2014usually employ a standard Gaussian distribution as a prior. Previous works show that the richer family of prior distributions may help to avoid the mode collapse problem in GANs and to improve the evidence lower bound in VAEs. We propose a new family of prior distributions\u2014Tensor Ring Induced Prior (TRIP)\u2014that packs an exponential number of Gaussians into a high-dimensional lattice with a relatively small number of parameters. We show that these priors improve Fr\u00e9chet Inception Distance for GANs and Evidence Lower Bound for VAEs. We also study generative models with TRIP in the conditional generation setup with missing conditions. Altogether, we propose a novel plug-and-play framework for generative models that can be utilized in any GAN and VAE-like architectures.\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-394",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/28f0b864598a1291557bed248a998d4e-Paper.pdf",
        "paper_title": "Differentiable Cloth Simulation for Inverse Problems",
        "paper_author": "Junbang Liang &middot; Ming Lin &middot; Vladlen Koltun",
        "video_link": "https://youtu.be/ipIM-c4lCJ0",
        "abstract": "We propose a differentiable cloth simulator that can be embedded as a layer in deep neural networks.  This approach provides an effective, robust framework for modeling cloth dynamics, self-collisions, and contacts. Due to the high dimensionality of the dynamical system in modeling cloth, traditional gradient computation for collision response can become impractical. To address this problem, we propose to compute the gradient directly using QR decomposition of a much smaller matrix. Experimental results indicate that our method can speed up backpropagation by two orders of magnitude. We demonstrate the presented approach on a number of inverse problems, including parameter estimation and motion control for cloth.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-7203",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/118921efba23fc329e6560b27861f0c2-Paper.pdf",
        "paper_title": "A Simple Baseline for Bayesian Uncertainty in Deep Learning",
        "paper_author": "Wesley Maddox &middot; Pavel Izmailov &middot; Timur Garipov &middot; Dmitry Vetrov &middot; Andrew Gordon Wilson",
        "video_link": "https://izmailovpavel.github.io/swag_video",
        "abstract": "We propose SWA-Gaussian (SWAG), a simple,  scalable,  and general purpose approach for uncertainty representation and calibration in deep learning. Stochastic Weight Averaging (SWA), which computes the first moment of stochastic gradient descent (SGD) iterates with a modified learning rate schedule, has recently been shown to improve generalization in deep learning. With SWAG, we fit a Gaussian using the SWA solution as the first moment and a low rank plus diagonal covariance also derived from the SGD iterates, forming an approximate posterior distribution over neural network weights; we then sample from this Gaussian distribution to perform Bayesian model averaging. We empirically find that SWAG approximates the shape of the true posterior, in accordance with results describing the stationary distribution of SGD iterates. Moreover, we demonstrate that SWAG performs well on a wide variety of tasks, including out of sample detection, calibration,  and transfer learning,  in comparison to many popular alternatives including variational inference, MC dropout, KFAC Laplace, and temperature scaling.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-9024",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/952285b9b7e7a1be5aa7849f32ffff05-Paper.pdf",
        "paper_title": "Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks",
        "paper_author": "Aaron Voelker &middot; Ivana Kaji\u0107 &middot; Chris Eliasmith",
        "video_link": "https://docs.google.com/document/d/1uarYP9YqcKx2Qh7sHJJhrY87C-mVZbNTAVqRKVPDXmI/edit",
        "abstract": "We propose a novel memory cell for recurrent neural networks that dynamically maintains information across long windows of time using relatively few resources. The Legendre Memory Unit~(LMU) is mathematically derived to orthogonalize its continuous-time history -- doing so by solving $d$ coupled ordinary differential equations~(ODEs), whose phase space linearly maps onto sliding windows of time via the Legendre polynomials up to degree $d - 1$. Backpropagation across LMUs outperforms equivalently-sized LSTMs on a chaotic time-series prediction task, improves memory capacity by two orders of magnitude, and significantly reduces training and inference times. LMUs can efficiently handle temporal dependencies spanning $100\\text{,}000$ time-steps, converge rapidly, and use few internal state-variables to learn complex functions spanning long windows of time -- exceeding state-of-the-art performance among RNNs on permuted sequential MNIST. These results are due to the network&#x27;s disposition to learn scale-invariant features independently of step size. Backpropagation through the ODE solver allows each layer to adapt its internal time-step, enabling the network to learn task-relevant time-scales. We demonstrate that LMU memory cells can be implemented using $m$ recurrently-connected Poisson spiking neurons, $\\mathcal{O}( m )$ time and memory, with error scaling as $\\mathcal{O}( d / \\sqrt{m} )$. We discuss implementations of LMUs on analog and digital neuromorphic hardware.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-9119",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/d921c3c762b1522c475ac8fc0811bb0f-Paper.pdf",
        "paper_title": "Reverse engineering recurrent networks for sentiment classification reveals line attractor dynamics",
        "paper_author": "Niru Maheswaranathan &middot; Alex Williams &middot; Matthew Golub &middot; Surya Ganguli &middot; David Sussillo",
        "video_link": "https://drive.google.com/open?id=1J-YIS9aSMNz1WX1ifBK4KlZaWhH32vXp",
        "abstract": "Recurrent neural networks (RNNs) are a widely used tool for modeling sequential data, yet they are often treated as inscrutable black boxes. Given a trained recurrent network, we would like to reverse engineer it--to obtain a quantitative, interpretable description of how it solves a particular task. Even for simple tasks, a detailed understanding of how recurrent networks work, or a prescription for how to develop such an understanding, remains elusive. In this work, we use tools from dynamical systems analysis to reverse engineer recurrent networks trained to perform sentiment classification, a foundational natural language processing task. Given a trained network, we find fixed points of the recurrent dynamics and linearize the nonlinear system around these fixed points. Despite their theoretical capacity to implement complex, high-dimensional computations, we find that trained networks converge to highly interpretable, low-dimensional representations. In particular, the topological structure of the fixed points and corresponding linearized dynamics reveal an approximate line attractor within the RNN, which we can use to quantitatively understand how the RNN solves the sentiment analysis task. Finally, we find this mechanism present across RNN architectures (including LSTMs, GRUs, and vanilla RNNs) trained on multiple datasets, suggesting that our findings are not unique to a particular architecture or dataset. Overall, these results demonstrate that surprisingly universal and human interpretable computations can arise across a range of recurrent networks.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-7516",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/bb836c01cdc9120a9c984c525e4b1a4a-Paper.pdf",
        "paper_title": "Explanations can be manipulated and geometry is to blame",
        "paper_author": "Ann-Kathrin Dombrowski &middot; Maximillian Alber &middot; Christopher Anders &middot; Marcel Ackermann &middot; Klaus-Robert M\u00fcller &middot; Pan Kessel",
        "video_link": "https://www.youtube.com/watch?v=xTAPZbQlq3A",
        "abstract": "Explanation methods aim to make neural networks more trustworthy and interpretable. In this paper, we demonstrate a property of explanation methods which is disconcerting for both of these purposes. Namely, we show that explanations can be manipulated arbitrarily by applying visually hardly perceptible perturbations to the input that keep the network&#x27;s output approximately constant. We establish theoretically that this phenomenon can be related to certain geometrical properties of neural networks. This allows us to derive an upper bound on the susceptibility of explanations to manipulations. Based on this result, we propose effective mechanisms to enhance the robustness of explanations.",
        "transcript": "In this video, we describe an analytic unification of two actions frequently used in graph reduction: the deletion of edges, often used in graph sparsification algorithms, and the contraction of edges (that is, the merging of two adjacent nodes), which is often used in graph coarsening algorithms. Prior to this work, sparsification and coarsening were treated as separate algorithmic primitives, with different objective functions. What you are seeing now  is our graph reduction algorithm in action, which uses this analytic unification to simultaneously sparsify and coarsen a graph. The actions of edge deletion and edge contraction are, in fact, dual operations. One manifestation of this duality is seen by considering a planar graph, shown here in blue. The planar dual of this graph, shown here in red, is created by first placing its red vertices in the regions formed by the planar embedding of the original graph. Then, one adds a red edge between each of these red vertices that share a blue border. Notice that the planar dual always has the same number of edges as the original graph, such that each edge in one graph crosses exactly one edge in the other graph. Now, if one of the blue edges is deleted, its corresponding red edge is contracted, merging the two red nodes into one. Likewise, if a blue edge were to be contracted, it would amount to deleting its corresponding red edge. This duality generalizes to non planar graphs by considering its associated graphic matroid and its dual. Algebraically, this duality is reflected in the graph Laplacian, a matrix operator related to diffusion throughout a graph, and whose spectrum reveals information about the graph's global structure. Indeed, many sparsification and coarsening algorithms aim to preserve properties associated with the graph Laplacian. Consider the heat equation,  a prototypical diffusive process. With respect to the dynamics of this differential equation, edge deletion corresponds to the limit of zero edge weight, while edge contraction corresponds to  the limit of infinite edge weight. However, this edge contraction limit requires some entries in the graph Laplacian to become infinite, making analytic treatment difficult. Our primary insight came from the fact that the  inverse of the graph Laplacian remains finite in both of these limits. And in fact, many relevant problems on graphs involve solving the equation Lx = b for x, so the solution is given by applying the inverse to b. Moreover, while the lowest eigenvalues of the Laplacian are associated with the graph's global structure, by inverting the spectrum, these correspond to the highest eigenvalues of the inverse Laplacian. Motivated by these considerations,  we developed a probabilistic graph reduction algorithm that preserves the inverse Laplacian in expectation and aims to minimize the expected squared error for a given amount of reduction. Thus, by preserving the inverse Laplacian, our algorithm is able to perform both edge deletion and edge contraction while preferentially retaining the large-scale structure of a graph. If this video piqued your interest please stop by our poster Wednesday from 5 to 7 p.m. in East Exhibition Hall B+C. Thanks for watching!",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1687",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/7fea637fd6d02b8f0adf6f7dc36aed93-Paper.pdf",
        "paper_title": "Fooling Neural Network Interpretations via Adversarial Model Manipulation",
        "paper_author": "Juyeon Heo &middot; Sunghwan Joo &middot; Taesup Moon",
        "video_link": "https://github.com/rmrisforbidden/Fooling_Neural_Network-Interpretations/blob/master/Materials/Video.md",
        "abstract": "We ask whether the neural network interpretation methods can be fooled via adversarial model manipulation, which is defined as a model fine-tuning step that aims to radically alter the explanations without hurting the accuracy of the original models, e.g., VGG19, ResNet50, and DenseNet121. By incorporating the interpretation results directly in the penalty term of the objective function for fine-tuning, we show that the state-of-the-art saliency map based interpreters, e.g., LRP, Grad-CAM, and SimpleGrad, can be easily fooled with our model manipulation. We propose two types of fooling, Passive and Active, and demonstrate such foolings generalize well to the entire validation set as well as transfer to other interpretation methods. Our results are validated by both visually showing the fooled explanations and reporting quantitative metrics that measure the deviations from the original explanations.  We claim that the stability of neural network interpretation method with respect to our adversarial model manipulation is an important criterion to check for developing robust and reliable neural network interpretation method.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1058",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/b4d168b48157c623fbd095b4a565b5bb-Paper.pdf",
        "paper_title": "Visualizing the PHATE of Neural Networks",
        "paper_author": "Scott Gigante &middot; Adam S Charles &middot; Smita Krishnaswamy &middot; Gal Mishne",
        "video_link": "http://mishne.ucsd.edu/m-phate-video.html",
        "abstract": "Understanding why and how certain neural networks outperform others is key to guiding future development of network architectures and optimization methods. To this end, we introduce a novel visualization algorithm that reveals the internal geometry of such networks: Multislice PHATE (M-PHATE), the first method designed explicitly to visualize how a neural network&#x27;s hidden representations of data evolve throughout the course of training. We demonstrate that our visualization provides intuitive, detailed summaries of the learning dynamics beyond simple global measures (i.e., validation loss and accuracy), without the need to access validation data. Furthermore, M-PHATE better captures both the dynamics and community structure of the hidden units as compared to visualization based on standard dimensionality reduction methods (e.g., ISOMAP, t-SNE). We demonstrate M-PHATE with two vignettes: continual learning and generalization. In the former, the M-PHATE visualizations display the mechanism of &quot;catastrophic forgetting&quot; which is a major challenge for learning in task-switching contexts. In the latter, our visualizations reveal how increased heterogeneity among hidden units correlates with improved generalization performance. An implementation of M-PHATE, along with scripts to reproduce the figures in this paper, is available at https://github.com/scottgigante/M-PHATE.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6138",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/b2ead76dfdc4ae56a2abd1896ec46291-Paper.pdf",
        "paper_title": "Identification of Conditional Causal Effects under Markov Equivalence",
        "paper_author": "Amin Jaber &middot; Jiji Zhang &middot; Elias Bareinboim",
        "video_link": "https://www.dropbox.com/s/qucyzi28s7ycka9/NeurIPS19-CID.m4v?dl=0",
        "abstract": "Causal identification is the problem of deciding whether a post-interventional distribution is computable from a combination of qualitative knowledge about the data-generating process, which is encoded in a causal diagram, and an observational distribution. A generalization of this problem restricts the qualitative knowledge to a class of Markov equivalent causal diagrams, which, unlike a single, fully-specified causal diagram, can be inferred from the observational distribution.\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2543",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/1b113258af3968aaf3969ca67e744ff8-Paper.pdf",
        "paper_title": "Successor Uncertainties: Exploration and Uncertainty in Temporal Difference Learning",
        "paper_author": "David Janz &middot; Jiri Hron &middot; Przemys\u0142aw Mazur &middot; Katja Hofmann &middot; Jos\u00e9 Miguel Hern\u00e1ndez-Lobato &middot; Sebastian Tschiatschek",
        "video_link": "djanz.org/successor_uncertainties/video",
        "abstract": "Posterior sampling for reinforcement learning (PSRL) is an effective method for balancing exploration and exploitation in reinforcement learning. Randomised value functions (RVF) can be viewed as a promising approach to scaling PSRL. However, we show that most contemporary algorithms combining RVF with neural network function approximation do not possess the properties which make PSRL effective, and provably fail in sparse reward problems. Moreover, we find that propagation of uncertainty, a property of PSRL previously thought important for exploration, does not preclude this failure. We use these insights to design Successor Uncertainties (SU), a cheap and easy to implement RVF algorithm that retains key properties of PSRL. SU is highly effective on hard tabular exploration benchmarks. Furthermore, on the Atari 2600 domain, it surpasses human performance on 38 of 49 games tested (achieving a median human normalised score of 2.09), and outperforms its closest RVF competitor, Bootstrapped DQN, on 36 of those.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4951",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/8cbe9ce23f42628c98f80fa0fac8b19a-Paper.pdf",
        "paper_title": "Sampling Networks and Aggregate Simulation for Online POMDP Planning",
        "paper_author": "Hao(Jackson) Cui &middot; Roni Khardon",
        "video_link": "https://youtu.be/IcC-O1AALXE",
        "abstract": "The paper introduces a new algorithm for planning in partially observable Markov decision processes (POMDP) based on the idea of aggregate simulation. The algorithm uses product distributions to approximate the belief state and shows how to build a representation graph of an approximate action-value function over belief space. The graph captures the result of simulating the model in aggregate under independence assumptions, giving a symbolic representation of the value function. The algorithm supports large observation spaces using sampling networks, a representation of the process of sampling values of observations, which is integrated into the graph representation. Following previous work in MDPs this approach enables action selection in POMDPs through gradient optimization over the graph representation. This approach complements recent algorithms for POMDPs which are based on particle representations of belief states and an explicit search for action selection. Our approach enables scaling to large factored action spaces in addition to large state spaces and observation spaces. An experimental evaluation demonstrates that the algorithm provides excellent performance relative to state of the art in large POMDP problems. ",
        "transcript": "this video gives a quick overview for paper presented at the Norris conference 2019 planning under uncertainty in mdps can be captured using a dynamic Bayesian network to chose the evolution of states over time from left to right conditioned on actions the goal is to find an assignment to action the orange nodes that maximizes the expected cumulative reward represented by the our node on the bottom right here it is assumed that the agent knows the state when choosing the next action in partially observable MDPs the agent does not know the state but instead has partial observations revealing some information as shown at the bottom in both images we emphasize that state's actions and observations are described by sets of variables so they all have exponentially many possible values planning in such factored BOM dps is computationally hard our main contribution is a new algorithm snap the tackles such problems it is an approximate solver suboptimal even when it has enough time but very effective on large problems where other algorithms are too slow snap uses the idea of aggregate simulation which was developed for MDP planning with a sub buffa system so gabbatha takes as input and symbolic representation of the domain model as in this example taken from a recent planning competition or the toy problem on the top left of this slide so Bopha translates the model to a computation graph is shown on the right where action variables the orange nodes are symbolic inputs and one node represents an approximation of the cumulative reward so buffer then optimizes action variables using automatic differentiation the forward computation was shown to be equivalent to belief propagation with no downstream evidence which means information only flows forward in the Cibola graph and no backward messages are used in bTW this fact is crucial for the Cibola construction unfortunately this breaks down for pom DPS because observation nodes shown at the bottom are downstream from actions and they serve as evidence our solution is to reorder the computations by enumerate in possible values for observations and conditioning on these values this works when there are only a few values in this example we have only two values and we generate two tracks in the graph the graph computes probabilities belief States and pom DP values the last portion computes the value of a belief state by using the Cibola construction on the nodes representing the belief stage in the graph when there are many observation values we sample a few the challenge is that we must generate a value at construction time which is sampled conditioned on the action which is only known during optimization time sampling networks achieve this and generate both the value and the node in the graph that calculates its probability to be used in other portions and this is embedded in the large construction optimization of action proceeds using automatic differentiation and gradient search experiments in the paper show that snap has excellent performance on the range of challenge problems with large state action and observation spaces please see the paper for more details on the algorithm and experiments",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-175",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/82161242827b703e6acf9c726942a1e4-Paper.pdf",
        "paper_title": "Chasing Ghosts: Instruction Following as Bayesian State Tracking",
        "paper_author": "Peter Anderson &middot; Ayush Shrivastava &middot; Devi Parikh &middot; Dhruv Batra &middot; Stefan Lee",
        "video_link": "https://www.panderson.me/images/vln-chasing-ghosts.mp4",
        "abstract": "A visually-grounded navigation instruction can be interpreted as a sequence of expected observations and actions an agent following the correct trajectory would encounter and perform. Based on this intuition, we formulate the problem of finding the goal location in Vision-and-Language Navigation (VLN) within the framework of Bayesian state tracking - learning observation and motion models conditioned on these expectable events. Together with a mapper that constructs a semantic spatial map on-the-fly during navigation, we formulate an end-to-end differentiable Bayes filter and train it to identify the goal by predicting the most likely trajectory through the map according to the instructions. The resulting navigation policy constitutes a new approach to instruction following that explicitly models a probability distribution over states, encoding strong geometric and algorithmic priors while enabling greater explainability. Our experiments show that our approach outperforms a strong LingUNet baseline when predicting the goal location on the map. On the full VLN task, i.e. navigating to the goal location, our approach achieves promising results with less reliance on navigation constraints.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6214",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/05e97c207235d63ceb1db43c60db7bbb-Paper.pdf",
        "paper_title": "Uniform convergence may be unable to explain generalization in deep learning",
        "paper_author": "Vaishnavh Nagarajan &middot; J. Zico Kolter",
        "video_link": "https://www.youtube.com/watch?v=o3GfnEjTdIQ",
        "abstract": "Aimed at explaining the surprisingly good generalization behavior of overparameterized deep networks, recent works have developed a variety of generalization bounds for deep learning,  all based on the fundamental learning-theoretic technique of uniform convergence. While\n",
        "transcript": "you may have come across these two papers that were published a few years ago highlighting a particular aspect of deep learning that we had all been taking for granted until then why do deep networks with so many parameters that are made to fit the training data to zero error learn a nice function that generalizes so well to unseen data conventional wisdom suggests that such complex models should learn a bad function that simply memorizes the labels on the training data this is a question that has caught the attention of both theoreticians and practitioners alike and has since become a pretty active area of research so what do these papers say mathematically speaking conventional bounds of the generalization gap like the VC dimension cannot explain this generalization puzzle as these bounds estimate the representational complexity of the network by its parameter count hence yielding vacuous generalization paths to this end these two papers proposed that we should derive more refined bounds by taking into account the fact that SGD implicitly controls the representational capacity of the network and this suggestion resulted in an exciting line of work that found new ways of deriving generalization bounds in deep learning using many different learning theoretic tools while these tools may look pretty different externally in essence they are all the same learning theoretic tool called uniform convergence unfortunately all these existing uniform convergence bounds are still either parameter account abandoned or requires some kinds of explicit modification or regularization to the network learn bias Chile in addition to these issues in our paper we bring to light some more concerning problems troubling these paths first is our finding that even though the true generalization gap decreases with training set size as expected these bounds in contrast increase with the training set size hence parameter count dependence is not the only problem plaguing these bounds next and more importantly we present some example binary classification tasks tasks and deep learning where we show that even though as Chile generalizes well it learns a decision boundary that is complex in a certain way that all uniform convergence bounds are vacuous in these settings that is uniform convergence provably fails to explain generalization in these cases through these two findings we call into question the current approach of using uniform convergence to understand generalization and deep learning perhaps it's time to look for a new tool",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6250",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/947018640bf36a2bb609d3557a285329-Paper.pdf",
        "paper_title": "Causal Confusion in Imitation Learning",
        "paper_author": "Pim de Haan &middot; Dinesh Jayaraman &middot; Sergey Levine",
        "video_link": "https://sites.google.com/view/causal-confusion",
        "abstract": "Behavioral cloning reduces policy learning to supervised learning by training a discriminative model to predict expert actions given observations. Such discriminative models are non-causal: the training procedure is unaware of the causal structure of the interaction between the expert and the environment. We point out that ignoring causality is particularly damaging because of the distributional shift in imitation learning. In particular, it leads to a counter-intuitive &quot;causal misidentification&quot; phenomenon: access to more information can yield worse performance. We investigate how this problem arises, and propose a solution to combat it through targeted interventions---either environment interaction or expert queries---to determine the correct causal model. We show that causal misidentification occurs in several benchmark control domains as well as realistic driving settings, and validate our solution against DAgger and other baselines and ablations.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1457",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/01d8bae291b1e4724443375634ccfa0e-Paper.pdf",
        "paper_title": "Asymmetric Valleys: Beyond Sharp and Flat Local Minima",
        "paper_author": "Haowei He &middot; Gao Huang &middot; Yang Yuan",
        "video_link": "https://youtu.be/zWwaJ3gbv_Q",
        "abstract": "Despite the non-convex nature of their loss functions, deep neural networks are known to generalize well when optimized with stochastic gradient descent (SGD). Recent work conjectures that SGD with proper con\ufb01guration is able to \ufb01nd wide and \ufb02at local minima, which are correlated with good generalization performance. In this paper, we observe that local minima of modern deep networks are more than being \ufb02at or sharp. Instead, at a local minimum there exist many asymmetric directions such that the loss increases abruptly along one side, and slowly along the opposite side \u2013 we formally de\ufb01ne such minima as asymmetric valleys. Under mild assumptions, we \ufb01rst prove that for asymmetric valleys, a solution biased towards the \ufb02at side generalizes better than the exact empirical minimizer. Then, we show that performing weight averaging along the SGD trajectory implicitly induces such biased solutions. This provides theoretical explanations for a series of intriguing phenomena observed in recent work [25, 5, 51]. Finally, extensive empirical experiments on both modern deep networks and simple 2 layer networks are conducted to validate our assumptions and analyze the intriguing properties of asymmetric valleys.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-98",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/ed3d2c21991e3bef5e069713af9fa6ca-Paper.pdf",
        "paper_title": "Imitation Learning from Observations by Minimizing Inverse Dynamics Disagreement",
        "paper_author": "Chao Yang &middot; Xiaojian Ma &middot; Wenbing Huang &middot; Fuchun Sun &middot; Huaping Liu &middot; Junzhou Huang &middot; Chuang Gan",
        "video_link": "https://sites.google.com/view/neurips19-iddm/home",
        "abstract": "This paper studies Learning from Observations (LfO) for imitation learning with access to state-only demonstrations. In contrast to Learning from Demonstration (LfD) that involves both action and state supervisions, LfO is more practical in leveraging previously inapplicable resources (e.g., videos), yet more challenging due to the incomplete expert guidance. In this paper, we investigate LfO and its difference with LfD in both theoretical and practical perspectives. We first prove that the gap between LfD and LfO actually lies in the disagreement of inverse dynamics models between the imitator and expert, if following the modeling approach of GAIL. More importantly, the upper bound of this gap is revealed by a negative causal entropy which can be minimized in a model-free way. We term our method as Inverse-Dynamics-Disagreement-Minimization (IDDM) which enhances the conventional LfO method through further bridging the gap to LfD. Considerable empirical results on challenging benchmarks indicate that our method attains consistent improvements over other LfO counterparts.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1955",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/378a063b8fdb1db941e34f4bde584c7d-Paper.pdf",
        "paper_title": "Implicit Generation and Modeling with Energy Based Models",
        "paper_author": "Yilun Du &middot; Igor Mordatch",
        "video_link": "https://sites.google.com/view/igebm",
        "abstract": "Energy based models (EBMs) are appealing due to their generality and simplicity in likelihood modeling, but have been traditionally difficult to train. We present techniques to scale MCMC based EBM training on continuous neural networks, and we show its success on the high-dimensional data domains of ImageNet32x32, ImageNet128x128, CIFAR-10, and robotic hand trajectories, achieving better samples than other likelihood models and nearing the performance of contemporary GAN approaches, while covering all modes of the data. We highlight some unique capabilities of implicit generation such as compositionality and corrupt image reconstruction and inpainting. Finally, we show that EBMs are useful models across a wide variety of tasks, achieving state-of-the-art out-of-distribution classification, adversarially robust classification, state-of-the-art continual online class learning, and coherent long term predicted trajectory rollouts.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5254",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/5d0d5594d24f0f955548f0fc0ff83d10-Paper.pdf",
        "paper_title": "Residual Flows for Invertible Generative Modeling",
        "paper_author": "Tian Qi Chen &middot; Jens Behrmann &middot; David Duvenaud &middot; Joern-Henrik Jacobsen",
        "video_link": "http://www.cs.toronto.edu/~rtqichen/posters/residual_flows_poster.pdf",
        "abstract": "Flow-based generative models parameterize probability distributions through an invertible transformation and can be trained by maximum likelihood. Invertible residual networks provide a flexible family of transformations where only Lipschitz conditions rather than strict architectural constraints are needed for enforcing invertibility. However, prior work trained invertible residual networks for density estimation by relying on biased log-density estimates whose bias increased with the network&#x27;s expressiveness. We give a tractable unbiased estimate of the log density, and reduce the memory required during training by a factor of ten. Furthermore, we improve invertible residual blocks by proposing the use of activation functions that avoid gradient saturation and generalizing the Lipschitz condition to induced mixed norms. The resulting approach, called Residual Flows, achieves state-of-the-art performance on density estimation amongst flow-based models, and outperforms networks that use coupling blocks at joint generative and discriminative modeling.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5115",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/d324a0cc02881779dcda44a675fdcaaa-Paper.pdf",
        "paper_title": "Guided Meta-Policy Search",
        "paper_author": "Russell Mendonca &middot; Abhishek Gupta &middot; Rosen Kralev &middot; Pieter Abbeel &middot; Sergey Levine &middot; Chelsea Finn",
        "video_link": "https://drive.google.com/file/d/1hwnb9TaY4uPTvsLv1C6WULqcVWMm9AIc/view?usp=sharing",
        "abstract": "Reinforcement learning (RL) algorithms have demonstrated promising results on complex tasks, yet often require impractical numbers of samples because they learn from scratch. Meta-RL aims to address this challenge by leveraging experience from previous tasks so as to more quickly solve new tasks. However, in practice, these algorithms generally also require large amounts of on-policy experience during the \\emph{meta-training} process, making them impractical for use in many problems. To this end, we propose to learn a reinforcement learning procedure in a federated way, where individual off-policy learners can solve the individual meta-training tasks, and then consolidate these solutions into a single meta-learner. Since the central meta-learner learns by imitating the solutions to the individual tasks, it can accommodate either the standard meta-RL problem setting, or a hybrid setting where some or all tasks are provided with example demonstrations. The former results in an approach that can leverage policies learned for previous tasks without significant amounts of on-policy data during meta-training, whereas the latter is particularly useful in cases where demonstrations are easy for a person to provide. Across a number of continuous control meta-RL problems, we demonstrate significant improvements in meta-RL sample efficiency in comparison to prior work as well as the ability to scale to domains with visual observations. ",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4792",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/4ff3e350028d0cfcb92c3a87a57585b1-Paper.pdf",
        "paper_title": "Parameter elimination in particle Gibbs sampling",
        "paper_author": "Anna Wigren &middot; Riccardo Sven Risuleo &middot; Lawrence Murray &middot; Fredrik Lindsten",
        "video_link": "https://www.it.uu.se/katalog/annwi999/Publications/Neurips2019",
        "abstract": "Bayesian inference in state-space models is challenging due to high-dimensional state trajectories. A viable approach is particle Markov chain Monte Carlo (PMCMC), combining MCMC and sequential Monte Carlo to form ``exact approximations&#x27;&#x27; to otherwise-intractable MCMC methods. The performance of the approximation is limited to that of the exact method. We focus on particle Gibbs (PG) and particle Gibbs with ancestor sampling (PGAS), improving their performance beyond that of the ideal Gibbs sampler (which they approximate) by marginalizing out one or more parameters. This is possible when the parameter(s) has a conjugate prior relationship with the complete data likelihood. Marginalization yields a non-Markov model for inference, but we show that, in contrast to the general case, the methods still scale linearly in time. While marginalization can be cumbersome to implement, recent advances in probabilistic programming have enabled its automation. We demonstrate how the marginalized methods are viable as efficient inference backends in probabilistic programming, and demonstrate with examples in ecology and epidemiology.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-7901",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/3e883840fee4384dd3d2afea5e822517-Paper.pdf",
        "paper_title": "Learning Positive Functions with Pseudo Mirror Descent",
        "paper_author": "Yingxiang Yang &middot; Haoxiang Wang &middot; Negar Kiyavash &middot; Niao He",
        "video_link": "https://www.dropbox.com/sh/veks5wyi9p1s4wd/AACfKZ-D-gjlorqfqT_bH_Gea?dl=0",
        "abstract": "The nonparametric learning of positive-valued functions appears widely in machine learning, especially in the context of estimating intensity functions of point processes. Yet, existing approaches either require computing expensive projections or semidefinite relaxations, or lack convexity and theoretical guarantees after introducing nonlinear link functions. In this paper, we propose a novel algorithm, pseudo mirror descent, that performs efficient estimation of positive functions within a Hilbert space without expensive projections. The algorithm guarantees positivity by performing mirror descent with an appropriately selected Bregman divergence, and a pseudo-gradient is adopted to speed up the gradient evaluation procedure in practice. We analyze both asymptotic and nonasymptotic convergence of the algorithm. Through simulations, we show that pseudo mirror descent outperforms the state-of-the-art benchmarks for learning intensities of Poisson and multivariate Hawkes processes, in terms of both computational efficiency and accuracy.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6771",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/195f15384c2a79cedf293e4a847ce85c-Paper.pdf",
        "paper_title": "Hindsight Credit Assignment",
        "paper_author": "Anna Harutyunyan &middot; Will Dabney &middot; Thomas Mesnard &middot; Mohammad Gheshlaghi Azar &middot; Bilal Piot &middot; Nicolas Heess &middot; Hado van Hasselt &middot; Gregory Wayne &middot; Satinder Singh &middot; Doina Precup &middot; Remi Munos",
        "video_link": "https://youtu.be/2EnckznIV2o",
        "abstract": "We consider the problem of efficient credit assignment in reinforcement learning. In order to efficiently and meaningfully utilize new data, we propose to explicitly assign credit to past decisions based on the likelihood of them having led to the observed outcome. This approach uses new information in hindsight, rather than employing foresight. Somewhat surprisingly, we show that value functions can be rewritten through this lens, yielding a new family of algorithms. We study the properties of these algorithms, and empirically show that they successfully address important credit assignment challenges, through a set of illustrative tasks.",
        "transcript": "this is a video for the paper called hindsight credit assignment the question that credit assignment asks is how did my past actions influence the future outcomes the way that the reinforcement learning agent usually goes about this question is by relying on the MDP structure of the world and in particular by taking time as being the main proxy for credit relevance for example here we have credit assignment in RL or Carl who looks at the weather forecast in the morning and has to decide whether or not to take an umbrella to work Carl decides not to take the umbrella goes to work and it ends up raining now Carl has to figure out what it was in his day that made this happen because Carl is an aural algorithm he goes through his day in the backward chronological order until eventually after many trials and iterations he figures out that in fact it was the umbrella now what we would like to happen instead is for the credit to be moved directly from the rain to the umbrella so the key intuition that we proposed in his paper is to instead of relying on the standard MPP assumptions to explicitly learn the credit relevance structure in particular we consider the probability of a past action given the state that he was taken and some form of the future outcome which has measured as a function of the future trajectory that starts from that state and action in particular in this paper we take this function to be a future state or a future return and it turns out that this is not just a heuristic and that we can actually rewrite our usual value functions in these terms in particular now in the usual discounted sum we can additionally wait each reward by this probability ratio of the probability of the action whose value were estimating that is conditioned on reaching the state that is giving us the reward divided by the probability of just taking that action and this ratio explicitly how relevant was the past action in achieving the state and consequently the reward so in the family of HCA algorithms were proposed to learn an estimate for this probability P and then use it to sample this expectation and follow the policy gradients accordingly we devised a set of diagnostic tasks that illustrate the issues of when standard credit assignment in RL and show that HCA is able to tackle them for the complete details please read the paper",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-8295",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/d202ed5bcfa858c15a9f383c3e386ab2-Paper.pdf",
        "paper_title": "Qsparse-local-SGD: Distributed SGD with Quantization, Sparsification and Local Computations",
        "paper_author": "Debraj Basu &middot; Deepesh Data &middot; Can Karakus &middot; Suhas Diggavi",
        "video_link": "https://youtu.be/UxXdAdkyAF0",
        "abstract": "Communication bottleneck has been identified as a significant issue in distributed optimization of large-scale learning models. Recently, several approaches to mitigate this problem have been proposed, including different forms of gradient compression or computing local models and mixing them iteratively. In this paper we propose Qsparse-local-SGD algorithm, which combines aggressive sparsification with quantization and local computation along with error compensation, by keeping track of the difference between the true and compressed gradients. We propose both synchronous and asynchronous implementations of Qsparse-local-SGD. We analyze convergence for Qsparse-local-SGD in the distributed case, for smooth non-convex and convex objective functions. We demonstrate that Qsparse-local-SGD converges at the same rate as vanilla distributed SGD for many important classes of sparsifiers and quantizers. We use Qsparse-local-SGD to train ResNet-50 on ImageNet, and show that it results in significant savings over the state-of-the-art, in the number of bits transmitted to reach target accuracy.",
        "transcript": "hi I'm Dave Raj and I'll be talking about our work on communication efficient distributed learning the goal is to perform empirical risk minimization using data which is distributed over worker nodes which communicate over bandwidth limited networks traditionally this is solved iteratively by communicating stochastic gradients from workers to a parameter server which returns the aggregated gradient each volt precision exchange uses 32 bits per dimension which could amount to gigabytes of data being transmitted in training language models as an example therefore to mitigate this cost techniques such as quantization specification of gradients and increased local computations have been previously proposed we first proposed a novel class of cue sparse operators which combines either general stochastic quantizers or deterministic sign based quantizers with either top K or random K specification together with our compensation we have a distributed algorithm called Q sparse SGD which mitigates the communication bottleneck to some extent furthermore we propose an algorithm called Q sparse local SGD which combines the benefits of RQ sparse operators with increased local iterations while incurring little penalty in convergence rates here the workers perform local iterations independently until the next synchronization step in which this parts of I and quantize the sum of the net local updates since the last synchronization together with the historical error this is sent to the parameter server which returns the aggregated updates we also analyze an asynchronous operation in which each worker has its own synchronization schedule therefore only a subset of workers chooses to communicate with the parameter server in each iteration the workers compensate for the compression error in future iterations by storing it in local memory as a result of error compensation we recover convergence at rates matching vanilla SGD for both our synchronous and asynchronous operations despite biased updates resulting from quantization specification together with in frequent communication we also characterize the asymptotic limits of local iterations as well as the minimum iterations for converging rates matching vanilla SGD both in non convex and strongly convex settings recovering previously known bounds for local SGD when the compression coefficient gamma is 1 as well as for centralized stop k SGD when the synchronization period H is equal to 1 our robot implementation of Q sparse local HDD was used to train resonate 50 on imagenet and they clearly see the gains on combining the three techniques by a factor of over 15 to 20 times as compared to quantization specification and local HDD being individually used without incurring significant penalty in convergence rates we also validate a scheme in a convex setting by training a soft max classifier with l2 regularization on the MS data set in which we also observe the superiority of q sparse local HDD over the other baselines such as top k HDD sign SGD local HDD all of which are also in fact specializations of our algorithm",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5115",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/d324a0cc02881779dcda44a675fdcaaa-Paper.pdf",
        "paper_title": "Guided Meta-Policy Search",
        "paper_author": "Russell Mendonca &middot; Abhishek Gupta &middot; Rosen Kralev &middot; Pieter Abbeel &middot; Sergey Levine &middot; Chelsea Finn",
        "video_link": "https://drive.google.com/file/d/1hwnb9TaY4uPTvsLv1C6WULqcVWMm9AIc/view?usp=sharing",
        "abstract": "Reinforcement learning (RL) algorithms have demonstrated promising results on complex tasks, yet often require impractical numbers of samples because they learn from scratch. Meta-RL aims to address this challenge by leveraging experience from previous tasks so as to more quickly solve new tasks. However, in practice, these algorithms generally also require large amounts of on-policy experience during the \\emph{meta-training} process, making them impractical for use in many problems. To this end, we propose to learn a reinforcement learning procedure in a federated way, where individual off-policy learners can solve the individual meta-training tasks, and then consolidate these solutions into a single meta-learner. Since the central meta-learner learns by imitating the solutions to the individual tasks, it can accommodate either the standard meta-RL problem setting, or a hybrid setting where some or all tasks are provided with example demonstrations. The former results in an approach that can leverage policies learned for previous tasks without significant amounts of on-policy data during meta-training, whereas the latter is particularly useful in cases where demonstrations are easy for a person to provide. Across a number of continuous control meta-RL problems, we demonstrate significant improvements in meta-RL sample efficiency in comparison to prior work as well as the ability to scale to domains with visual observations. ",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-7901",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/3e883840fee4384dd3d2afea5e822517-Paper.pdf",
        "paper_title": "Learning Positive Functions with Pseudo Mirror Descent",
        "paper_author": "Yingxiang Yang &middot; Haoxiang Wang &middot; Negar Kiyavash &middot; Niao He",
        "video_link": "https://www.dropbox.com/sh/veks5wyi9p1s4wd/AACfKZ-D-gjlorqfqT_bH_Gea?dl=0",
        "abstract": "The nonparametric learning of positive-valued functions appears widely in machine learning, especially in the context of estimating intensity functions of point processes. Yet, existing approaches either require computing expensive projections or semidefinite relaxations, or lack convexity and theoretical guarantees after introducing nonlinear link functions. In this paper, we propose a novel algorithm, pseudo mirror descent, that performs efficient estimation of positive functions within a Hilbert space without expensive projections. The algorithm guarantees positivity by performing mirror descent with an appropriately selected Bregman divergence, and a pseudo-gradient is adopted to speed up the gradient evaluation procedure in practice. We analyze both asymptotic and nonasymptotic convergence of the algorithm. Through simulations, we show that pseudo mirror descent outperforms the state-of-the-art benchmarks for learning intensities of Poisson and multivariate Hawkes processes, in terms of both computational efficiency and accuracy.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2434",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/f708f064faaf32a43e4d3c784e6af9ea-Paper.pdf",
        "paper_title": "On Adversarial Mixup Resynthesis",
        "paper_author": "Christopher Beckham &middot; Sina Honari &middot; Alex Lamb &middot; Vikas Verma &middot; Farnoosh Ghadiri &middot; R Devon Hjelm &middot; Yoshua Bengio &middot; Chris Pal",
        "video_link": "https://www.youtube.com/watch?v=ezbC3_VZeNY",
        "abstract": "In this paper, we explore new approaches to combining information encoded within the learned representations of auto-encoders. We explore models that are capable of combining the attributes of multiple inputs such that a resynthesised output is trained to fool an adversarial discriminator for real versus synthesised data. Furthermore, we explore the use of such an architecture in the context of semi-supervised learning, where we learn a mixing function whose objective is to produce interpolations of hidden states, or masked combinations of latent representations that are consistent with a conditioned class label. We show quantitative and qualitative evidence that such a formulation is an interesting avenue of research.",
        "transcript": "Hello there, welcome to our video presentation on adversarial mixup resynthesis  This was recently accepted into NeurIPS 2019 as a conference poster  I hope you'll enjoy it Okay, to start off, adversarial mixup resynthesis, which we'll just call 'AMR' -- it's the abbreviation -- is basically a technique to improve representations learned by auto-encoders  Autoencoders being one of the most fundamental building blocks that we have in unsupervised learning So just to give an example: in an autoencoder we have an input x, it could be an image, it could be text whatever, and then we're going to run it through an encoding function 'f' to produce a representation here Now commonly this representation is going to be much smaller in dimensionality than x because here we want to capture the most salient features, the most important features to basically reconstruct x  And we reconstructed it by having a decoder function 'g' which puts it back into the original space so 'x tilde' here denotes the reconstruction of x and so we're basically training this  We're going to update its parameters so as to minimise the reconstruction loss which is the L2 norm between x and 'x tilde' which in this case would just be x minus the decoder of the encoder of x like so So in deep learning in general -- not just an unsupervised learning -- data augmentation is actually an extremely useful thing to do and in the case of images it's really easy to do right  So the reason why we're doing this is you can think about it as like you're trying to artificially augment your training set which is usually quite small in the grand scheme of things and so for instance we have a bunch of images here, these five images and we can perform various transformations like here maybe we can randomly rotate the image, we can blur it a bit, we can play with the contrast and vice versa and so and for instance if you were training and classifier to classify these images then you'd be making the classifier a lot more robust It would see this image in different lighting conditions or different angles so just in general it's a really good idea to do and it's really effective Another example is actually this thing called a denoising auto-encoder so here we're dealing with MNIST digits and we can see this two has been corrupted with noise and so the idea is that if it's being corrupted with this sort of noise we can run it through the encoder and it's actually going to produce the original image and so what we're doing is that we're training this auto-encoder to learn to separate signal from noise and so the objective that we'd be minimizing here would actually be this L2 norm between 'x' and 'g' of 'f' of 'x' plus epsilon where epsilon is this noise  So for instance this could be sampled from a Gaussian and so each pixel would have an epsilon sampled from it  So this is called the denoising auto-encoder and it's much more robust than the one that we explained in the previous slide  So here we're going to talk about another data augmentation algorithm called 'mixup' which is proposed by Zhang et al in 2017 Now our technique actually uses a form of this but just for the sake of this slide we're going to explain the original algorithm in the context of supervised learning  And so mixup is actually really simple, it's only a few lines of code really and basically what we're going to do is that we're going to construct random convex combinations between random pairs of examples and their labels in the data set  So for instance imagine we are looping through let's just say D1 and D2 where these are the same training set but they have different orderings, they're shuffled differently  We could say you know for (x_i, y_i) and and (x_j, y_j) in D1, D2 we're going to construct this x_mix to be alpha times x_i plus one minus alpha times x_j where alpha let's say is going to be sampled from say -- sorry -- a uniform distribution and y_mix it's the same thing it's going to be alpha times y_i plus 1 minus alpha times y_j and now we have this new pseudo example here (x_mix, y_mix) and we're going to train our classifier on that  So what does this do? Well, oops sorry -- the text is above the diagram -- but here's an example here so if we look at this diagram we had these two classes, we have orange as one class and green as the other class and blue, this blue shading here is the probability that y equals one so we can see that you know it's not so smooth at so it's a pretty sharp decision boundary but when we do mixup we get something that's a lot smoother in this region here  So here's an example here we're using some some random images from CIFAR10 and so if we just look at the top row for now  We have this this truck x1 and we have this deer x2 and as we're moving from from left to right where we're traversing that convex combination so for instance you know this second image here would be something like you know let's just say 0.9 of x_1 and 0.1 of x_2 and this would be the opposite, this would be like 0.1 of x1 and 0.9 of x_2 and in the middle this would be about 50/50  So we can see here what we can see here is this assumption that we're making that when we interpolate between these images in pixel space that were also going to interpolate their probabilities right so this would have a class but let's just say there are only two classes right this would be [1, 0] the one-hot vector and this would be [0, 1] and what we're saying is that this class here would would be [0.5, 0.5] so the classifier is going to say well you know I'm half confident that it's a truck and I'm half confident that it's a deer but there are some problems The main one is that these interpolations they don't really look like they're representative of the training set so you could easily have a case of underfitting But they're also not really semantically meaningful If we were interpolating between two cars for example we wouldn't expect to see some you know this novel combination that looks realistic, it would just be these cars that have been halfway faded so it's not 'semantic' mixing it's just mixing in pixel space But to address this issue recently we proposed a paper called 'manifold mixup' this is actually from Verma et al which was recently accepted in ICML 2019 and this basically does the mixing in the hidden space of a classifier so now you have these semantic mixes  AMR does something similar but in the case of unsupervised learning and so we'll get to that really So our technique -- which we'll get through quite shortly -- can be motivated in part at least by a statistical way of looking at the problem and so we have these faces here you know we can imagine there being this complicated function p(x) and so you know these x's are samples from p(x) and in unsupervised learning what we're really interested in is this inference of function p(z|x) right you know what are the latent variables which explain or generated this data x  So in the cases of faces let's just say we might have a lot of these latent variables z_1, z_2, to z_m, there may be a lot of these and they all you know come together and basically influence or generate x so for instance this could be something like you know hair colour, skin colour, age, eye colour and vice versa Now let's just say for example that your m was 32 well you know if these are all binary variables Well you know 2 to the power of m you'd be 2 to the power 32 which would be 4.2 billion which is a very large number, a very large configuration space of these variables and most likely we're not going to have 4.2 billion images and even so there's going to be a lot of redundancy so we can see that you there are a lot of possible configurations of these latent variables to generate this x  So just as an example, suppose we're training an auto-encoder and let's just say this lady here is x_1 and this guy is x_2 and we're gonna encode both of these images with the encoder function and you can imagine the auto-encoder having extracted -- having learned -- some of these these latent factors and let's just say for example it just so happens speed at and our training set we've got no guys with red hair but we have woman with red hair Well depending on how we combine these latents -- how we mix these latent variables we might end up getting the same guy with orange hair so we can produce configurations of latent variables as a form of data augmentation configurations of latent variables which may not be initially present in our training set and really that's the whole idea behind AMR Okay just to explain that again just in a better slide  We have these two images here x_1 and x_2 and we're training an autoencoder and so you know we're going to encode using this encoding function some representation here h_1 and we also have x_2 which we're going to encode into some latent representation h_2  Now because this is an autoencoder right we're going to -- you know -- still do the reconstruction so this would be x_1 tilde and we're minimising L2 norm here and same thing for x_2 and its reconstruction here right and we have this norm Okay so the mixing happens at h_1 h_2 right so we're going to feed both of these through some mixing function and it's going to produce some mix between h1 and h2 and it's going to output some h_mix and then we're going to decode this mix with 'g' and get some x_mix  Now if you do this with say a regular auto-encoder it's not guaranteed that this mix is going to look realistic it could be something that's completely gibberish But what we're doing in order for this algorithm to work we're gonna use generative adversarial networks  I won't go into it you know too much but basically what we do is -- just selecting a different colour -- we have this discriminator function here and basically it's going to This discriminator is trained to say that this is fake and that you know these two images here are real and the auto- encoder is going to try to fool this discriminator so basically it's going to try to it's going to update as parameters so as to producing mixes that could plausibly look like they come from the data distribution  Okay so what is this mixing function?  Well the first one that comes to mind would just be mixup I'm just putting it in quotes to say this is this is the original mixup you know using the original paper and used in manifold mixup and also in some related work  So let's just say here this is you know this is h_1 so this is basically an encoding of x_1, it's a bunch of feature maps, so we have four feature maps and we also have h_2 which is the encoding of x_2, also a bunch of feature maps  So what we can say is that well we could sample some scalar alpha from say some uniform distribution and just literally multiply, produce this convex combination so alpha times h_1 plus one minus alpha times h_2 and then we get some some combination here h_mix which we've then decode into some x_mix So another one actually we propose that specific to our work is this thing called 'Bernoulli mixup' in which we do discrete mixes so to explain this again we have h_1 and h_2 and just to present it a bit better I'm just flattening these out, these feature maps So what we're doing is that we're actually going to sample from a Bernoulli distribution So for each index -- because there are four feature maps -- we're gonna sample some let's just say some 'm' from some Bernoulli distribution parameterised by 'p' and this could be 0.5 for example and so maybe for the first one you know it samples 0 and then maybe for this one when we sample that m we're going to get 0 and maybe for this one we get 1 and maybe for this one we get 1  So what that means is that because these are 0 we're gonna retain these feature maps and because these are 1 and we're going to retain these feature maps and then we're gonna do this discrete swapping so we have the first two feature maps of this guy and the last two feature maps of this guy and again we're going to basically decode that into an x_mix, so that's discrete mixing In the previous two examples we were just mixing up two examples at a time but you know one question you might ask us we know can we mix between multiple examples, can we mix between three examples, four examples and vice-versa? And absolutely  So if we just go back to the case let's say we're k=2 to where we were mixing with two examples you know we have these two mixing coefficients alpha_1 and alpha_2 but really we only need one alpha right because alpha_1 is just alpha and alpha_2 is just 1 minus alpha but we can visualize this as like line segments right so here would be alpha_1 and you know this would be [1, 0] and here's alpha 2 with [0, 1] and you know we can sort of draw a line segment between them and so this halfway point would be you know [0.5, 0.5] And so we can imagine you know drawing these alphas from this line segment Now in the case of k=3 now you know we have alpha_1, alpha_2, alpha_3 and yeah we have this constraint that you know these alphas have to sum to 1 and again you know we can sort of draw let's say the corners of this vector, so this one here would be use [1, 0, 0] so alpha_1 equals 1, alpha_2 equals 0, alpha_3 equals 0 This is another corner [0, 1, 0] and this is another corner [0, 0, 1] right and so this actually forms a triangle and so this midpoint here would be [0.33, 0.33, 0.33] and so you know we're drawing these alphas from this triangle So by the way this is called a '1-simplex' and this is called a '2-simplex' right and you can generalize this through more dimensions so in k=4 you know it would be something like a tetrahedron Just to give some animations to further illustrate the point in this case we have mix-up with k=2 and so you can imagine this being like a three dimensional latent space and red these are the real points latent states for real examples and these blue dots are the interpolations and so we can see that you know we're taking random pairs of these real points and interpolating along their lines This is mixup with k=3 Same thing now but we're actually taking random triplets so here's a use of these three real examples and we're interpolating between them, interpolating in their triangle Here's Bernoulli mixup for k=2 This is a bit less intuitive visually but you can also see the type of interpolation that's imposed by doing this Bernoulli mixing It's also useful to talk about some related work There are actually two papers that are very similar in nature Adversarially constrained autoencoder interpolation which we'll call 'ACAI' which is a recently published in ICLR 2019 and 'generative adversarial interpolative auto-encoding' otherwise known as 'GAIA' So there are some differences between the works  In ACAI what's going on is that they're using mixup in the k=2 case but when the discriminator gets that x_mix the discriminator now is actually going to try to predict the mixing coefficient alpha right so it wants to predict you know to what extent to what extent let's just say h_1 was mixed and what extent h_2 was mixed and so the auto-encoder's objective is to try to make the discriminator think that that the mixing coefficient for x_mix is either 0 or 1 and so the output of this discriminator is tied to the mixing function that's used but in that case they only try mixup with k=2  In GAIA they use a mixing function which is based on a Gaussian so if we have h_1, h_2 we're actually gonna sample an h_mix from a Gaussian distribution which is just the the midpoint of h_1 and h_2 with some variance sigma squared so you know if h_1 was here and h_2 was here we're basically sampling is Gaussian which is at the midpoint so you're more likely to sample interpolations that are really in the middle of these two points but again it's in the k=2 case In particular what we're interested in is just mixing functions in general, just evaluating you know different types of mixing functions like Bernoulli mixup, mixup for k>2 and just really think about what these specific mixing functions are actually doing and what their implications are on the resulting representation So here I'm just showing some qualitative results finally  This is on the Zappos shoe dataset so you know we have one type of shoe x_1 we have another type of shoe here x_2 and this row is basically pixel space interpolation, this one is just a regular auto-encoder -- interpolating in the latent space of a regular auto-encoder sorry -- this is ACAI and this is a AMR so we can see that for these top two rows there's a lot of ghosting and these interpolations it doesn't look very realistic  Same thing for the auto-encoder but for ACAI and AMR things look a lot better especially in this case for our technique, there's not really much ghosting going on and again this is due to the fact that any interpolations produced by the auto-encoder have to look realistic, they have to fool a discriminator so it's going to want to get rid of this ghosting because that ghosting isn't present in the original data set  Also this is just for k=2 with just regular mixup Here's another example of a more high-res version This is actually the first figure in the paper, we have this x_1 here and we have this x_2 here So these are kinda like two completely different shoes, this is a wedge sandal and this is a boot and we're doing these interpolations but what you will notice in some of the figures is that there are sometimes it can seem like the jump -- it's a pretty big jump -- between these interpolations and this seems to be at least in part a consequence of doing this adversarial thing so just to elaborate let's just suppose that we have this space here and you know h_1 lies here and h2 utilize here we're gonna do an interpolation right in the middle and let's just say you know we decode it into some x_mix you know we might find it when we re-encode it -- gonna draw the same diagram again -- it might be sort of let's say more closer to one of the original h's so it's kind of you know analogous to a denoising autoencoder right like these shoes are completely different and maybe it can't seem to  produce something that's really in between the two shoes and so it pushes it in either direction so again the seems to be a natural consequence of just you know doing this adversarial game but in order to -- actually -- if you wanted to mitigate this you could do something which is called a 'consistency loss'  I won't go into it for this video but you can read a bit about it in the appendix of the paper So here it is an example of some interpretations with Bernoulli mixup up and so what we're doing is doing a discrete mixing between feature maps so for example well let's just say this is x_1 -- or its encoding is h1 -- and this guy's encoding is h2  Well let's just say for this one you know we want to keep most of the future maps from this guy and and we want a few feature maps from this guy so we might say I'm gonna sample a vector, a mask vector from Bernoulli and let's just make it maybe 0.9 right so this is actually a vector a binary vector you know m_1 m_2 up to let's just say we have 'p' feature maps and then the interpolation simply going to be m times h_1 plus 1 minus m times h_2 where m is this this binary mask for instance  Now for here for example maybe we want roughly half the feature maps from this guy and roughly half from this guy and so you know we might sample a Bernoulli mask from something like 0.5 and then we'll do the same thing m times h_1 plus 1 minus M times h_2 and vice versa  And this guy here will have most of his feature maps from this guy and a few from this guy So here's another interesting example, this is actually a mixing function which is an MLP that's trained in a supervised manner, so if we look here for example we're just considering there are three attributes male makeup and lipstick and so our guy here Kiefer Sutherland you know his attribute vector is [1, 0, 0] so yeah he's male but he doesn't have makeup and he doesn't have lipstick and this lady here, well her attribute vector is the opposite it's actually [0, 1, 1] so not male, she's female but has makeup and has lipstick and basically yeah we learn this mixing function which is an MLP which basically you condition on say a vector like this, so not male , makeup and lipstick, and it's going to try to figure out what feature maps does it have to take from this guy and this woman in order to produce a mix which satisfies this classification here right and so we do that using an 'ACGAN' -- an auxiliary classifier GAN -- which is just one supervised variant of a GAN and so not only does this this mix here have to look realistic it also has to satisfy this classification here  And so you can see in this row we're showing different versions of Kiefer Sutherland with these different attribute vectors which is pretty neat  So to actually evaluate these representations like how how 'good' they are we're gonna do sign it's similar to what they did in the ACAI paper and we're actually going to train a linear classifier on top of these and coatings So let's just say we you know we're training our AMR auto-encoder and you know we encode some x into some h and you know and there is also the reconstruction, this is the encoder, this is the decoder, we're gonna branch so during training we have a linear classifier p(y|x) which is branching off this encoding here and we're actually going to train it to predict the class from h But what's very important to note is that we're not backpropping the gradients from this back into the auto-encoder right so this is this is cut-off here So you know this auto-encoder is trained completely unsupervised -- it doesn't see the labels -- but this part is trained supervised  And it doesn't have to be a linear classifier per se it could also be a deep neural network but it just so happens to be that linear classifiers are fast to train and it really makes a difference when you're training / running hundreds of experiments and so you know we're going to train this and we're gonna evaluate its accuracy on both the validation and test sets  As well as that each experiment we run we we run it three times so we get two repeats and so for each of these trials we're gonna find basically the epoch corresponding to the point at which the validation performance was highest and then we're gonna evaluate at that point on the test set and so basically we're actually we're gonna get you know three test set numbers and then we're just going to take the mean and variance of that and that's what we report  In terms of hyperparameters there is 'lambda' the reconstruction loss so this also affects how much weighting you give to the GAN loss because essentially the order auto-encoder is trying to minimise let's just say you know the loss here would be your reconstruction plus the scan loss would be lambda times reconstruction plus this GAN loss where this is the loss that tries to fool the discriminator with the mixes and so you know the higher this lambda is relatively speaking the less weighting that the GAN loss gets so you really have to tune this  The mixing function, so we explore just mixup and Bernoulli  Unfortunately due to time and resource constraints we couldn't explore this as rigorously but really we do have a lot of experiments on mixup which is good  And for that there's also the k value so how many examples do we mix between at a time? Do we mix two, three four, six, eight, ..., and and vice versa  Okay so here are our first set of experiments that we ran we actually ran some experiments on MNIST, KMNIST, and SVHN and so this is the test set performance and we're also showing the values of lambda, the best performing lambdas for those experiments, and so if you look row by row the first one we have is auto-encoder plus GAN so this is just an auto-encoder with a GAN on the reconstruction so there's no mixing but the reason why we put this on the reconstruction is so that you get nicer reconstructions -- ones that aren't blurry -- this is a common problem if you just train a regular auto-encoder Now for AMR these are the experiments that we ran so there's mixup with k=2 Bernoulli with k=2 and mixup with k=3  For ACAI we we did our own implementation of ACAI as well and here just in this little this little box here we're showing we're showing the results from the ACAI paper quoting them directly So for MNIST it actually performs -- our implementation of ACAI -- performs the best, same thing for KMNIST but fortunately I guess for SVHN the slightly more complicated dataset we actually achieve a big win here, we've actually 47.34% compared to the baseline which is ~37% Our implementation ACAI which is ~34% and their's which is ~34% and we actually get this with a k=3 which is nice so for our second set of experiments we actually did an ablation so we're just looking at SVHN The encoding size is still 32 but what we're doing is that we're basically reducing the size of the training set so in this case for example we've taken a thousand -- randomly selected a thousand examples in the training set -- and decided to use that as the training set For here we randomly selected 5000 and decide to use that and vice versa, 10,000 and 20,000 And this is really just to see you know what the behaviour of these algorithms are and the sort of 'low data regime'  So if we look at 1k the lowest well okay ACAI here performs best For 5k you know we you know perform the best here but actually you know partly because of this low data regime were operating in this is a pretty high variance whereas ACAI here actually performs only slightly less but with a much lower variance  For 10,000 and we achieve the best result for mixup with k=3 with a reasonable variance And here for 20k we achieve ~37% although the variance here is a bit big as well But things in general do look pretty good for mixup k=3 So here are some more results again on SVHN but now we also have CIFAR1 Here the encoding size is actually 256 So corresponds to 16 feature maps now with basically a 4x4 spatial dimension so that's 256 and this is really just to see what results we get you know when we beef up the size of encoding [but also because ACAI did it] For 1024 we're actually using 64 feature maps of 4x4 so that would be 1024  And so you know here we actually explore what happens when you go beyond k=3 so you know we have k=4, k=6 and k=8 and so if we look at SVHN with the 256 size encoding we actually get a pretty impressive 75.71% for k=8 But actually the quoted ACAI result is 85.14% which is really impressive so I'm not really sure what the reason for that difference is [#reproducibility], it may be the case that we needed to run our experiments for longer, but you know, time and resource constraints! :-( For our CIFAR10 for 256 we achieve the best result here 54.94% with k=3 And for CIFAR10 with the big bottle bottleneck dimension 1024 we get 61.72% with k=4 As you can see it's not always the case that a higher k corresponds to a better accuracy, this is something that needs to be looked at in more detail Maybe there are some theoretical things you can say about the choice of k but either way there will be a brief discussion on this in the appendix if you want to know more about it  Lastly we evaluate our algorithm in the context of disentanglement  There's a data set called 'DSprite' it's basically just this one sprite which can take on various positions, rotations, shapes and it's basically used in the context of measuring disentanglement  So if we look at the ground truth latent factors of this data set you have six, or really it's five -- because the only color you have is white -- but you have these five latent variables: the shape of the sprite, the scale, the orientation, the x position, the y position, and they all take on various ranges of values and so if you take all possible latent configurations you get this dataset here and so this animations is showing you know all the possible configurations and so for instance you know we might want to try to recover these latent factors in an unsupervised manner so what we could do is say well you know if we could train this auto-encoder and maybe this auto- encoder -- well let's just say it's a five dimension -- we want each of these units to encode the latent factors like shape scale, orientation, x-position, y-position, but we also want it to encode these latent factors such that there's 'disentanglement' so now if you're only going to change x for example it shouldn't change anything else or if you're gonna change scale -- if you're gonna vary this dimension -- it shouldn't change anything else when you decode into the image  And so there are two metrics that were proposed recently to measure this this disentanglement and one is the 'Beta-VAE' paper but an improved version of that metric was proposed in 'Factor-VAE' and so we use this in our evaluation  So if we look at our table of results this accuracy is this disentanglement metric and we have a 'Beta-VAE' just a finely-tuned baseline, and we have our auto-encoder and we have AMR and so actually the finely-tuned VAE -- the Beta-VAE -- actually performs the best with a disentanglement accuracy of 68%  For us it turns out that Bernoulli with k=3 actually performed the second best followed by Bernoulli with k=2 which is interesting so maybe there is something interesting about using Bernoulli mixup in the context of this dataset Again this really requires further exploration It would be good to know better what some of the implications are of using say regular mixup versus Bernoulli and also what happens when you play with the value of k So in conclusion we perform an exploration mixup in the context of unsupervised learning and so one of the motivating reasons was this idea that we can imagine the encoding of our auto-encoder trying to learn these latent factors that represent the data and that we can generate novel combinations of these by performing mixing and in making these novel mixes look realistic through an adversarial GAN framework, and we looked at it in the context of the mixing function so we tried different functions like mixup, Bernoulli, supervised Bernoulli --so this is the example where we did attribute swapping for celebrity faces --  and also mixing with k greater than two Qualitatively compared to to our baselines we achieved more realistic interpolations quantitatively we found that a mixup k>2 generally performs really well, it was for the the tasks where we branched a linear classifier off the encoding and try to predict the class Unfortunately due to time and resource constraints we weren't able to explore Bernoulli mixup as rigorously but at the same time we found some evidence that it might be useful in the context of disentanglement, the results that we presented on the DSprite dataset said  For future work be nicer to have a better theoretical understanding of these mixing functions, a better 'theoretical framework' and also maybe looking at mixup from a more biological point of view It is interesting to note that well if we look at say Bernoulli mixup this could be seen as being somewhat analogous to biological crossover in which we're swapping over different segments of DNA and also what's interesting is that recently genetic algorithms have become sort of more widely used in deep reinforcement learning under this this idea called 'evolutionary strategies' as an alternate alternative way to train reinforcement learning algorithms so there might be something interesting to see from this point of view  Well thank you for watching this presentation! If you have any questions or comments or whatever can email me at this address or tweet me I'll put the link to the code and the paper below so you can look at them easily and again thank you very much for watching! FIN",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2585",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/36e729ec173b94133d8fa552e4029f8b-Paper.pdf",
        "paper_title": "Symmetry-Based Disentangled Representation Learning requires Interaction with Environments",
        "paper_author": "Hugo Caselles-Dupr\u00e9 &middot; Michael Garcia Ortiz &middot; David Filliat",
        "video_link": "https://youtu.be/jyN3ZQNH1GI",
        "abstract": "Finding a generally accepted formal definition of a disentangled representation in the context of an agent behaving in an environment is an important challenge towards the construction of data-efficient autonomous agents. Higgins et al. recently proposed Symmetry-Based Disentangled Representation Learning, a definition based on a characterization of symmetries in the environment using group theory. We build on their work and make observations, theoretical and empirical, that lead us to argue that Symmetry-Based Disentangled Representation Learning cannot only be based on static observations: agents should interact with the environment to discover its symmetries. Our experiments can be reproduced in Colab and the code is available on GitHub.",
        "transcript": "i'ma go kacy Despres and i will present our paper symmetry based disentangle representation learning requires interaction with environments so we do first a quick recap on symmetry bases integral representation on e SPN DSB DRL then we'll present our contribution and then we'll talk about discussion in future work so motivation is disentangle representation learning where we try to iterate factors of valuation and data but the problem is that design the government needs a proper definition which is not the case at the moment so SB TRL tries to define what this entanglement is through the use of symmetries and group theory in their definition they use an underlying work state W and the use symmetries like translation or rotation and they try to build representation Z such that the effect of transformation on W will be the same as on Z so that's the definition of symmetry based organization and then they define disentitlement as the fact that the symmetries can be decomposed into different subgroups that do not affect each other such that a transformation will affect only serve groups subspaces of the representation in Z so this is the definition of disentangle presentations in SBT RL and in their paper they learn representation using only still observation and we try to make a bunch that SVD area requires transition and that still samples because for example the transformation can have a camera effect in the words that in different ways regarding what our physics in the world so we are able to prove that using 0 & 1 and for practical options we show that there are two options that you can do to learn as B it isn't a good representations so the first one would be Arabic models well while you would learn representation and then you would learn the power the transformation after distance for this presentation and then you can also do your end-to-end learning strategy where you would learn both at the same time we show that both approaches works in practice in a small toy example which is pretty much the same as the use in the killings paper and then we also test if the neural representation can be useful for learning those three tasks which is the case in our example so there are many open questions about SBT RL and one of them is how do you learn the subgroups of transformations and maybe we can associate these with actions that's one of the possibilities to go so in conclusion a formal definition of descent amendment is needed as the GRI tries to you know to find one and then we make the points that improve that trainer as B as B gr n needs transition is not and not still supposed to be learning practice so our current is a variable on : and on kita and we make sure you check out the paper on pocket thank you",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1955",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/378a063b8fdb1db941e34f4bde584c7d-Paper.pdf",
        "paper_title": "Implicit Generation and Modeling with Energy Based Models",
        "paper_author": "Yilun Du &middot; Igor Mordatch",
        "video_link": "https://sites.google.com/view/igebm",
        "abstract": "Energy based models (EBMs) are appealing due to their generality and simplicity in likelihood modeling, but have been traditionally difficult to train. We present techniques to scale MCMC based EBM training on continuous neural networks, and we show its success on the high-dimensional data domains of ImageNet32x32, ImageNet128x128, CIFAR-10, and robotic hand trajectories, achieving better samples than other likelihood models and nearing the performance of contemporary GAN approaches, while covering all modes of the data. We highlight some unique capabilities of implicit generation such as compositionality and corrupt image reconstruction and inpainting. Finally, we show that EBMs are useful models across a wide variety of tasks, achieving state-of-the-art out-of-distribution classification, adversarially robust classification, state-of-the-art continual online class learning, and coherent long term predicted trajectory rollouts.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5254",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/5d0d5594d24f0f955548f0fc0ff83d10-Paper.pdf",
        "paper_title": "Residual Flows for Invertible Generative Modeling",
        "paper_author": "Tian Qi Chen &middot; Jens Behrmann &middot; David Duvenaud &middot; Joern-Henrik Jacobsen",
        "video_link": "http://www.cs.toronto.edu/~rtqichen/posters/residual_flows_poster.pdf",
        "abstract": "Flow-based generative models parameterize probability distributions through an invertible transformation and can be trained by maximum likelihood. Invertible residual networks provide a flexible family of transformations where only Lipschitz conditions rather than strict architectural constraints are needed for enforcing invertibility. However, prior work trained invertible residual networks for density estimation by relying on biased log-density estimates whose bias increased with the network&#x27;s expressiveness. We give a tractable unbiased estimate of the log density, and reduce the memory required during training by a factor of ten. Furthermore, we improve invertible residual blocks by proposing the use of activation functions that avoid gradient saturation and generalizing the Lipschitz condition to induced mixed norms. The resulting approach, called Residual Flows, achieves state-of-the-art performance on density estimation amongst flow-based models, and outperforms networks that use coupling blocks at joint generative and discriminative modeling.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2300",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/46a558d97954d0692411c861cf78ef79-Paper.pdf",
        "paper_title": "Limitations of the empirical Fisher approximation for natural gradient descent",
        "paper_author": "Frederik Kunstner &middot; Philipp Hennig &middot; Lukas Balles",
        "video_link": "https://www.youtube.com/watch?v=f0jeOi4pW_A",
        "abstract": "Natural gradient descent, which preconditions a gradient descent update\n",
        "transcript": "gradient descent is a great algorithm for optimization but one of its shortcomings is that it can be slower when the function is ill-conditioned the curvature behaves very differently in different directions and the gradient is not 1 towards the minimum of the function one approach to this problem is the second order information to correct a direction an increasingly popular method is the natural gradient of Amaury it adapts to the geometry of the problem using the Fisher information matrix but many implementations of natural gradient methods in machine learning do not compute the Fisher instead they often use the outer product of gradients which has been called the empirical Fisher the twin pieces look similar but some authors have warned against this approximation our work looks at the relationship between those two matrices in more details we showed that even on very simple problems using the empirical Fisher can lead to very bad results the main difference between those two expression is that the Fisher uses the probability distribution of the model to sample outputs but the empirical vivir uses samples from the training data it loses the connection to Fisher information unless the two distributions are equal this is not possible when the parameters have not been fit to the data as is the case during optimization on different problems where gradient descent struggles but natural gradient converges quickly preconditioning with the empirical Fisher does not guarantee the same improvement looking at the angle between the empirical Fisher direction and the natural gradient median said that you can even be opposite the situation improves at the minimum but even there at the empirical Fisher need specific conditions to equal the Fisher the models needs to be correctly specified which is the case on this classification and regression problem but this is often understood just as being a good model correct specification is more subtle and small deviations that are difficult to know in practice lead to very different outcomes our paper provides an overview of the non connection between the Fisher information and other quantities used in second order optimization such as the Hessian and the journalist Goss Newton matrix and we provide a detailed criticism of existing argument strong connections between those quantities and the empirical failure",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-3487",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/944a5ae3483ed5c1e10bbccb7942a279-Paper.pdf",
        "paper_title": "Maximum Mean Discrepancy Gradient Flow",
        "paper_author": "Michael Arbel &middot; Anna Korba &middot; Adil Salim &middot; Arthur Gretton",
        "video_link": "https://michaelarbel.github.io/materials/MMD_flow.mp4",
        "abstract": "  We construct a Wasserstein gradient flow of the maximum mean discrepancy (MMD) and study its convergence properties.\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1973",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/deb54ffb41e085fd7f69a75b6359c989-Paper.pdf",
        "paper_title": "Tight Dimension Independent Lower Bound on the Expected Convergence Rate for Diminishing Step Sizes in SGD",
        "paper_author": "Ha Nguyen &middot; Lam Nguyen &middot; Marten van Dijk",
        "video_link": "https://drive.google.com/file/d/18st_NJYsYWUimP3HhM1UW-LTALupQ-ms/view?usp=sharing",
        "abstract": "We study the convergence of Stochastic Gradient Descent (SGD) for strongly convex  objective functions. We prove for all $t$ a lower bound on the expected convergence rate after the $t$-th SGD iteration; the lower bound is over all possible sequences of diminishing step sizes. It implies that recently proposed sequences of step sizes at ICML 2018 and ICML 2019 are {\\em universally} close to optimal in that the expected convergence rate after {\\em each} iteration is within a factor $32$ of our lower bound. This factor is independent of dimension $d$. We offer a framework for comparing with lower bounds in state-of-the-art literature and when applied to SGD for strongly convex objective functions our lower bound is a significant factor $775\\cdot d$ larger compared to existing work.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1457",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/01d8bae291b1e4724443375634ccfa0e-Paper.pdf",
        "paper_title": "Asymmetric Valleys: Beyond Sharp and Flat Local Minima",
        "paper_author": "Haowei He &middot; Gao Huang &middot; Yang Yuan",
        "video_link": "https://youtu.be/zWwaJ3gbv_Q",
        "abstract": "Despite the non-convex nature of their loss functions, deep neural networks are known to generalize well when optimized with stochastic gradient descent (SGD). Recent work conjectures that SGD with proper con\ufb01guration is able to \ufb01nd wide and \ufb02at local minima, which are correlated with good generalization performance. In this paper, we observe that local minima of modern deep networks are more than being \ufb02at or sharp. Instead, at a local minimum there exist many asymmetric directions such that the loss increases abruptly along one side, and slowly along the opposite side \u2013 we formally de\ufb01ne such minima as asymmetric valleys. Under mild assumptions, we \ufb01rst prove that for asymmetric valleys, a solution biased towards the \ufb02at side generalizes better than the exact empirical minimizer. Then, we show that performing weight averaging along the SGD trajectory implicitly induces such biased solutions. This provides theoretical explanations for a series of intriguing phenomena observed in recent work [25, 5, 51]. Finally, extensive empirical experiments on both modern deep networks and simple 2 layer networks are conducted to validate our assumptions and analyze the intriguing properties of asymmetric valleys.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2038",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/2557911c1bf75c2b643afb4ecbfc8ec2-Paper.pdf",
        "paper_title": "Painless Stochastic Gradient: Interpolation, Line-Search, and Convergence Rates",
        "paper_author": "Sharan Vaswani &middot; Aaron Mishkin &middot; Issam Laradji &middot; Mark Schmidt &middot; Gauthier Gidel &middot; Simon Lacoste-Julien",
        "video_link": "https://github.com/IssamLaradji/sls/tree/master/Video",
        "abstract": "Recent works have shown that stochastic gradient descent (SGD) achieves the fast convergence rates of full-batch gradient descent for over-parameterized models satisfying certain interpolation conditions. However, the step-size used in these works depends on unknown quantities and SGD&#x27;s practical performance heavily relies on the choice of this step-size. We propose to use line-search techniques to automatically set the step-size when training models that can interpolate the data. In the interpolation setting, we prove that SGD with a stochastic variant of the classic Armijo line-search attains the deterministic convergence rates for both convex and strongly-convex functions. Under additional assumptions, SGD with Armijo line-search is shown to achieve fast convergence for non-convex functions. Furthermore, we show that stochastic extra-gradient with a Lipschitz line-search attains linear convergence for an important class of non-convex functions and saddle-point problems satisfying interpolation. To improve the proposed methods&#x27; practical performance, we give heuristics to use larger step-sizes and acceleration. We compare the proposed algorithms against numerous optimization methods on standard classification tasks using both kernel methods and deep networks. The proposed methods result in competitive performance across all models and datasets, while being robust to the precise choices of hyper-parameters. For multi-class classification using deep networks, SGD with Armijo line-search results in both faster convergence and better generalization. ",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-7995",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/2d44e06a7038f2dd98f0f54c4be35e22-Paper.pdf",
        "paper_title": "Integrating Markov processes with structural causal modeling enables counterfactual inference in complex systems",
        "paper_author": "Robert Ness &middot; Kaushal Paneri &middot; Olga Vitek",
        "video_link": "http://bit.ly/MarkovP2SCM",
        "abstract": "This manuscript contributes a general and practical framework for casting a Markov process model of a system at equilibrium as a structural causal model, and carrying out counterfactual inference. Markov processes mathematically describe the mechanisms in the system, and predict the system\u2019s equilibrium behavior upon intervention, but do not support counterfactual inference. In contrast, structural causal models support counterfactual inference, but do not identify the mechanisms. This manuscript leverages the benefits of both approaches. We define the structural causal models in terms of the parameters and the equilibrium dynamics of the Markov process models, and counterfactual inference flows from these settings. The proposed approach alleviates the identifiability drawback of the structural causal models, in that the counterfactual inference is consistent with the counterfactual trajectories simulated from the Markov process model. We showcase the benefits of this framework in case studies of complex biomolecular systems with nonlinear dynamics. We illustrate that, in presence of Markov process model misspecification, counterfactual inference leverages prior data, and therefore estimates the outcome of an intervention more accurately than a direct simulation.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6256",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/a87c11b9100c608b7f8e98cfa316ff7b-Paper.pdf",
        "paper_title": "The Case for Evaluating Causal Models Using Interventional Measures and Empirical Data",
        "paper_author": "Amanda Gentzel &middot; Dan Garant &middot; David Jensen",
        "video_link": "https://agentzel.github.io/publications/neurips-2019-video.m4v",
        "abstract": "Causal inference is central to many areas of artificial intelligence, including complex reasoning, planning, knowledge-base construction, robotics, explanation, and fairness. An active community of researchers develops and enhances algorithms that learn causal models from data, and this work has produced a series of impressive technical advances.  However, evaluation techniques for causal modeling algorithms have remained somewhat primitive, limiting what we can learn from experimental studies of algorithm performance, constraining the types of algorithms and model representations that researchers consider, and creating a gap between theory and practice.  We argue for more frequent use of evaluation techniques that examine interventional measures rather than structural or observational measures, and that evaluate those measures on empirical data rather than synthetic data.  We survey the current practice in evaluation and show that the techniques we recommend are rarely used in practice. We show that such techniques are feasible and that data sets are available to conduct such evaluations.  We also show that these techniques produce substantially different results than using structural measures and synthetic data.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4792",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/4ff3e350028d0cfcb92c3a87a57585b1-Paper.pdf",
        "paper_title": "Parameter elimination in particle Gibbs sampling",
        "paper_author": "Anna Wigren &middot; Riccardo Sven Risuleo &middot; Lawrence Murray &middot; Fredrik Lindsten",
        "video_link": "https://www.it.uu.se/katalog/annwi999/Publications/Neurips2019",
        "abstract": "Bayesian inference in state-space models is challenging due to high-dimensional state trajectories. A viable approach is particle Markov chain Monte Carlo (PMCMC), combining MCMC and sequential Monte Carlo to form ``exact approximations&#x27;&#x27; to otherwise-intractable MCMC methods. The performance of the approximation is limited to that of the exact method. We focus on particle Gibbs (PG) and particle Gibbs with ancestor sampling (PGAS), improving their performance beyond that of the ideal Gibbs sampler (which they approximate) by marginalizing out one or more parameters. This is possible when the parameter(s) has a conjugate prior relationship with the complete data likelihood. Marginalization yields a non-Markov model for inference, but we show that, in contrast to the general case, the methods still scale linearly in time. While marginalization can be cumbersome to implement, recent advances in probabilistic programming have enabled its automation. We demonstrate how the marginalized methods are viable as efficient inference backends in probabilistic programming, and demonstrate with examples in ecology and epidemiology.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6250",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/947018640bf36a2bb609d3557a285329-Paper.pdf",
        "paper_title": "Causal Confusion in Imitation Learning",
        "paper_author": "Pim de Haan &middot; Dinesh Jayaraman &middot; Sergey Levine",
        "video_link": "https://sites.google.com/view/causal-confusion",
        "abstract": "Behavioral cloning reduces policy learning to supervised learning by training a discriminative model to predict expert actions given observations. Such discriminative models are non-causal: the training procedure is unaware of the causal structure of the interaction between the expert and the environment. We point out that ignoring causality is particularly damaging because of the distributional shift in imitation learning. In particular, it leads to a counter-intuitive &quot;causal misidentification&quot; phenomenon: access to more information can yield worse performance. We investigate how this problem arises, and propose a solution to combat it through targeted interventions---either environment interaction or expert queries---to determine the correct causal model. We show that causal misidentification occurs in several benchmark control domains as well as realistic driving settings, and validate our solution against DAgger and other baselines and ablations.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6805",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/5faf461eff3099671ad63c6f3f094f7f-Paper.pdf",
        "paper_title": "When to Trust Your Model: Model-Based Policy Optimization",
        "paper_author": "Michael Janner &middot; Justin Fu &middot; Marvin Zhang &middot; Sergey Levine",
        "video_link": "https://people.eecs.berkeley.edu/~janner/mbpo/",
        "abstract": "Designing effective model-based reinforcement learning algorithms is difficult because the ease of data generation must be weighed against the bias of model-generated data. In this paper, we study the role of model usage in policy optimization both theoretically and empirically. We first formulate and analyze a model-based reinforcement learning algorithm with a guarantee of monotonic improvement at each step. In practice, this analysis is overly pessimistic and suggests that real off-policy data is always preferable to model-generated on-policy data, but we show that an empirical estimate of model generalization can be incorporated into such analysis to justify model usage. Motivated by this analysis, we then demonstrate that a simple procedure of using short model-generated rollouts branched from real data has the benefits of more complicated model-based algorithms without the usual pitfalls. In particular, this approach surpasses the sample efficiency of prior model-based methods, matches the asymptotic performance of the best model-free algorithms, and scales to horizons that cause other model-based methods to fail entirely.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2815",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/f5b1b89d98b7286673128a5fb112cb9a-Paper.pdf",
        "paper_title": "On the Utility of Learning about Humans for Human-AI Coordination",
        "paper_author": "Micah Carroll &middot; Rohin Shah &middot; Mark Ho &middot; Tom Griffiths &middot; Sanjit Seshia &middot; Pieter Abbeel &middot; Anca Dragan",
        "video_link": "https://drive.google.com/file/d/13XjCGQ-suZGQOmCZQNbSiL1rMfExnKGj/view?usp=sharing",
        "abstract": "While we would like agents that can coordinate with humans, current algorithms such as self-play and population-based training create agents that can coordinate with themselves. Agents that assume their partner to be optimal or similar to them can converge to coordination protocols that fail to understand and be understood by humans. To demonstrate this, we introduce a simple environment that requires challenging coordination, based on the popular game Overcooked, and learn a simple model that mimics human play. We evaluate the performance of agents trained via self-play and population-based training. These agents perform very well when paired with themselves, but when paired with our human model, they are significantly worse than agents designed to play with the human model. An experiment with a planning algorithm yields the same conclusion, though only when the human-aware planner is given the exact human model that it is playing with. A user study with real humans shows this pattern as well, though less strongly. Qualitatively, we find that the gains come from having the agent adapt to the human&#x27;s gameplay. Given this result, we suggest several approaches for designing agents that learn about humans in order to better coordinate with them. Code is available at https://github.com/HumanCompatibleAI/overcooked_ai.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6771",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/195f15384c2a79cedf293e4a847ce85c-Paper.pdf",
        "paper_title": "Hindsight Credit Assignment",
        "paper_author": "Anna Harutyunyan &middot; Will Dabney &middot; Thomas Mesnard &middot; Mohammad Gheshlaghi Azar &middot; Bilal Piot &middot; Nicolas Heess &middot; Hado van Hasselt &middot; Gregory Wayne &middot; Satinder Singh &middot; Doina Precup &middot; Remi Munos",
        "video_link": "https://youtu.be/2EnckznIV2o",
        "abstract": "We consider the problem of efficient credit assignment in reinforcement learning. In order to efficiently and meaningfully utilize new data, we propose to explicitly assign credit to past decisions based on the likelihood of them having led to the observed outcome. This approach uses new information in hindsight, rather than employing foresight. Somewhat surprisingly, we show that value functions can be rewritten through this lens, yielding a new family of algorithms. We study the properties of these algorithms, and empirically show that they successfully address important credit assignment challenges, through a set of illustrative tasks.",
        "transcript": "this is a video for the paper called hindsight credit assignment the question that credit assignment asks is how did my past actions influence the future outcomes the way that the reinforcement learning agent usually goes about this question is by relying on the MDP structure of the world and in particular by taking time as being the main proxy for credit relevance for example here we have credit assignment in RL or Carl who looks at the weather forecast in the morning and has to decide whether or not to take an umbrella to work Carl decides not to take the umbrella goes to work and it ends up raining now Carl has to figure out what it was in his day that made this happen because Carl is an aural algorithm he goes through his day in the backward chronological order until eventually after many trials and iterations he figures out that in fact it was the umbrella now what we would like to happen instead is for the credit to be moved directly from the rain to the umbrella so the key intuition that we proposed in his paper is to instead of relying on the standard MPP assumptions to explicitly learn the credit relevance structure in particular we consider the probability of a past action given the state that he was taken and some form of the future outcome which has measured as a function of the future trajectory that starts from that state and action in particular in this paper we take this function to be a future state or a future return and it turns out that this is not just a heuristic and that we can actually rewrite our usual value functions in these terms in particular now in the usual discounted sum we can additionally wait each reward by this probability ratio of the probability of the action whose value were estimating that is conditioned on reaching the state that is giving us the reward divided by the probability of just taking that action and this ratio explicitly how relevant was the past action in achieving the state and consequently the reward so in the family of HCA algorithms were proposed to learn an estimate for this probability P and then use it to sample this expectation and follow the policy gradients accordingly we devised a set of diagnostic tasks that illustrate the issues of when standard credit assignment in RL and show that HCA is able to tackle them for the complete details please read the paper",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-98",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/ed3d2c21991e3bef5e069713af9fa6ca-Paper.pdf",
        "paper_title": "Imitation Learning from Observations by Minimizing Inverse Dynamics Disagreement",
        "paper_author": "Chao Yang &middot; Xiaojian Ma &middot; Wenbing Huang &middot; Fuchun Sun &middot; Huaping Liu &middot; Junzhou Huang &middot; Chuang Gan",
        "video_link": "https://sites.google.com/view/neurips19-iddm/home",
        "abstract": "This paper studies Learning from Observations (LfO) for imitation learning with access to state-only demonstrations. In contrast to Learning from Demonstration (LfD) that involves both action and state supervisions, LfO is more practical in leveraging previously inapplicable resources (e.g., videos), yet more challenging due to the incomplete expert guidance. In this paper, we investigate LfO and its difference with LfD in both theoretical and practical perspectives. We first prove that the gap between LfD and LfO actually lies in the disagreement of inverse dynamics models between the imitator and expert, if following the modeling approach of GAIL. More importantly, the upper bound of this gap is revealed by a negative causal entropy which can be minimized in a model-free way. We term our method as Inverse-Dynamics-Disagreement-Minimization (IDDM) which enhances the conventional LfO method through further bridging the gap to LfD. Considerable empirical results on challenging benchmarks indicate that our method attains consistent improvements over other LfO counterparts.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4552",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/f8905bd3df64ace64a68e154ba72f24c-Paper.pdf",
        "paper_title": "Multiclass Learning from Contradictions",
        "paper_author": "Sauptik Dhar &middot; Vladimir Cherkassky &middot; Mohak Shah",
        "video_link": "https://youtu.be/6TayjC7qqPg",
        "abstract": "We introduce the notion of learning from contradictions, a.k.a Universum learning, for multiclass problems and propose a novel formulation for multiclass universum SVM (MU-SVM). We show that learning from contradictions (using MU-SVM) incurs lower sample complexity compared to multiclass SVM (M-SVM) by deriving the Natarajan dimension for sample complexity for PAC-learnability of MU-SVM. We also propose an analytic span bound for MU-SVM and demonstrate its utility for model selection resulting in $\\sim 2-4 \\times$ faster computation times than standard resampling techniques. We empirically demonstrate the efficacy of MU- SVM on several real world datasets achieving $&gt;$ 20\\% improvement in test accuracies compared to M-SVM. Insights into the underlying behavior of MU-SVM using a histograms-of-projections method are also provided.",
        "transcript": "multi-class learning from contradictions we focus on the problem of learning with high dimensional data especially when access to labeled samples is limited most algorithms designed for such problems involve inductive settings one approach specifically designed for high dimensional problems uses large margin classifiers a popular example is the multi-class SVM or M SVM introduced by Cramer and Sigma unfortunately the performance of most such approaches is suboptimal when the label data is limited for high dimensional problems this motivates the need for advanced learning settings once a setting is learning from contradiction or Universal learning where the algorithm can exploit unlabeled samples from the same domain but belong to none of the classes being learned for example consider the task of gender classification from images here the labeled examples are male and female faces while the universal CentOS can be facing ages there are neither male nor female under the universal learning setting we then built a classifier which explains the training samples well and also maximizes the contradiction on universim samples the idea was originally introduced for binary classification problems and has been shown to be very effective in high dimensional settings this paper extends the universe of learning framework to multi class setting as presented in definition - we show that maximum contradiction for MSDN can be achieved when the universal samples like close to the decision boundary of each class we use this insight to formalize multi-class SVM for universal settings called nu SVM where we use large margin laws same as M SVM for training samples and Delta insensitive loss for universal samples we derive several useful properties for the musm formulation and show that mus am is solvable through any state of art M is lim solvers we also analyze the sample complexity for Peck learnability of mus I am using the most widely adopted capacity measure for multi class problems the Natarajan dimension we show that the sample complexity for MU SVM is smaller than M SVM this indicates that musm can achieve better test accuracies for problems with high dimensional limited label samples our empirical results confirm this by demonstrating 20% improvement over em svm the proposed HIV visualization method provides further insights into the performance finally we derive a new computationally efficient span bound for live on out error there also allows for efficient model selection a results show up to four times speed up against five fold CV and over 100 times speed up against naman art model selection in conclusion we formalized Universal learning for multi class learning provided several useful properties for the formulation analyzed a sample complexity for pac learnability and derived an efficient analytic bound there also enables model selection finally we provide exhaustive results in support of our methodology additional details are available in the paper accompanying codes are provided in the video description thank you",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-667",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/b5dc4e5d9b495d0196f61d45b26ef33e-Paper.pdf",
        "paper_title": "Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations",
        "paper_author": "Vincent Sitzmann &middot; Michael Zollhoefer &middot; Gordon Wetzstein",
        "video_link": "https://vsitzmann.github.io/srns/video/",
        "abstract": "Unsupervised learning with generative models has the potential of discovering rich representations of 3D scenes. While geometric deep learning has explored 3D-structure-aware representations of scene geometry, these models typically require explicit 3D supervision. Emerging neural scene representations can be trained only with posed 2D images, but existing methods ignore the three-dimensional structure of scenes. We propose Scene Representation Networks (SRNs), a continuous, 3D-structure-aware scene representation that encodes both geometry and appearance. SRNs represent scenes as continuous functions that map world coordinates to a feature representation of local scene properties. By formulating the image formation as a differentiable ray-marching algorithm, SRNs can be trained end-to-end from only 2D images and their camera poses, without access to depth or shape. This formulation naturally generalizes across scenes, learning powerful geometry and appearance priors in the process. We demonstrate the potential of SRNs by evaluating them for novel view synthesis, few-shot reconstruction, joint shape and appearance interpolation, and unsupervised discovery of a non-rigid face model.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6628",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/1c336b8080f82bcc2cd2499b4c57261d-Paper.pdf",
        "paper_title": "Calibration tests in multi-class classification: A unifying framework",
        "paper_author": "David Widmann &middot; Fredrik Lindsten &middot; Dave Zachariah",
        "video_link": "https://vimeo.com/369295144",
        "abstract": "In safety-critical applications a probabilistic model is usually required to be calibrated, i.e., to capture the uncertainty of its predictions accurately. In multi-class classification, calibration of the most confident predictions only is often not sufficient. We propose and study calibration measures for multi-class classification that generalize existing measures such as the expected calibration error, the maximum calibration error, and the maximum mean calibration error. We propose and evaluate empirically different consistent and unbiased estimators for a specific class of measures based on matrix-valued kernels. Importantly, these estimators can be interpreted as test statistics associated with well-defined bounds and approximations of the p-value under the null hypothesis that the model is calibrated, significantly improving the interpretability of calibration measures, which otherwise lack any meaningful unit or scale.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-9031",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/e2e14235335d2c0aa5f6855e339233d9-Paper.pdf",
        "paper_title": "Fast structure learning with modular regularization",
        "paper_author": "Greg Ver Steeg &middot; Hrayr Harutyunyan &middot; Daniel Moyer &middot; Aram Galstyan",
        "video_link": "http://bit.ly/2N9IJ66",
        "abstract": "Estimating graphical model structure from high-dimensional and undersampled data is a fundamental problem in many scientific fields.\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-9031",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/e2e14235335d2c0aa5f6855e339233d9-Paper.pdf",
        "paper_title": "Fast structure learning with modular regularization",
        "paper_author": "Greg Ver Steeg &middot; Hrayr Harutyunyan &middot; Daniel Moyer &middot; Aram Galstyan",
        "video_link": "http://bit.ly/2N9IJ66",
        "abstract": "Estimating graphical model structure from high-dimensional and undersampled data is a fundamental problem in many scientific fields.\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6658",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/8ca01ea920679a0fe3728441494041b9-Paper.pdf",
        "paper_title": "Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with Dirichlet calibration",
        "paper_author": "Meelis Kull &middot; Miquel Perello Nieto &middot; Markus K\u00e4ngsepp &middot; Telmo Silva Filho &middot; Hao Song &middot; Peter Flach",
        "video_link": "https://dirichletcal.github.io/documents/neurips2019/video/",
        "abstract": "Class probabilities predicted by most multiclass classifiers are uncalibrated, often tending towards over-confidence. With neural networks, calibration can be improved by temperature scaling, a method to learn a single corrective multiplicative factor for inputs to the last softmax layer. On non-neural models the existing methods apply binary calibration in a pairwise or one-vs-rest fashion. We propose a natively multiclass calibration method applicable to classifiers from any model class, derived from Dirichlet distributions and generalising the beta calibration method from binary classification. It is easily implemented with neural nets since it is equivalent to log-transforming the uncalibrated probabilities, followed by one linear layer and softmax. Experiments demonstrate improved probabilistic predictions according to multiple measures (confidence-ECE, classwise-ECE, log-loss, Brier score) across a wide range of datasets and classifiers. Parameters of the learned Dirichlet calibration map\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6628",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/1c336b8080f82bcc2cd2499b4c57261d-Paper.pdf",
        "paper_title": "Calibration tests in multi-class classification: A unifying framework",
        "paper_author": "David Widmann &middot; Fredrik Lindsten &middot; Dave Zachariah",
        "video_link": "https://vimeo.com/369295144",
        "abstract": "In safety-critical applications a probabilistic model is usually required to be calibrated, i.e., to capture the uncertainty of its predictions accurately. In multi-class classification, calibration of the most confident predictions only is often not sufficient. We propose and study calibration measures for multi-class classification that generalize existing measures such as the expected calibration error, the maximum calibration error, and the maximum mean calibration error. We propose and evaluate empirically different consistent and unbiased estimators for a specific class of measures based on matrix-valued kernels. Importantly, these estimators can be interpreted as test statistics associated with well-defined bounds and approximations of the p-value under the null hypothesis that the model is calibrated, significantly improving the interpretability of calibration measures, which otherwise lack any meaningful unit or scale.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-8301",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/1e79596878b2320cac26dd792a6c51c9-Paper.pdf",
        "paper_title": "Likelihood Ratios for Out-of-Distribution Detection",
        "paper_author": "Jie Ren &middot; Peter Liu &middot; Emily Fertig &middot; Jasper Snoek &middot; Ryan  Poplin &middot; Mark Depristo &middot; Joshua V Dillon &middot; Balaji Lakshminarayanan",
        "video_link": "https://youtu.be/-FduW9ZWAR4",
        "abstract": "Discriminative neural networks offer little or no performance guarantees when deployed on data not generated by the same process as the training distribution. On such out-of-distribution (OOD) inputs, the prediction may not only be erroneous, but confidently so, limiting the safe deployment of classifiers in real-world applications. One such challenging application is bacteria identification based on genomic sequences, which holds the promise of early detection of diseases, but requires a model that can output low confidence predictions on OOD genomic sequences from new bacteria that were not present in the training data. We introduce a genomics dataset for OOD detection that allows other researchers to benchmark progress on this important problem. We investigate deep generative model based approaches for OOD detection and observe that the likelihood score is heavily affected by population level background statistics. We propose a likelihood ratio method for deep generative models which effectively corrects for these confounding background statistics. We benchmark the OOD detection performance of the proposed method against existing approaches on the genomics dataset and show that our method achieves state-of-the-art performance. Finally, we demonstrate the generality of the proposed method by showing that it significantly improves OOD detection when applied to deep generative models of images.",
        "transcript": "hello here is a presentation of the paper likelihood ratios for out of distribution detection this is a trying to work with people in Google ai and deepmind bacteria net vacation is an important problem in medical diagnosis given a DNA sequence we would like to predict which bacteria is from this can be regarded as a classification problem we train a classifier with high accuracy on cross-validation but when we deploy the classifier to real data we found it performs poorly the reason is that a lot of real did have belong to unknown bacteria that is those bacteria are not in the training data distribution we call this out of distribution data OD surprisingly the classifier can assign high confident predictions to those all the inputs that say I don't know so we need an accurate OD detection master to ensure the safety ployment one popular strategy is to use a generative model to model the input distribution and evaluate the likelihood of new inputs however that's being observed that a generative model can assign even higher likelihood to all the inputs for example a generative model trained for feminists can say higher like equal to illness we observe a similar failure mode and genomic data so why is that here is an image from Amnesty when we interpret the image we humans in an easily ignore the background and focus primarily on semantics but the likelihood P of X calculates for all pixels in an image including both semantics and background though we want to just focus our semantics the likelihood can be dominated by the background so we propose a likely for the racial method we train a background model unperturbed includes the right amount reservation can corrupt the semantic structure in the data and capture only the background now way model the likelihood ratio between the full model and the background model and the background component is canceled out only likelihood for semantics remains so likelihood ratio is apt a quantitative score that captures the significance of the semantics compared waste of that word to call it eight him they evaluate the difference between the likelihood and likelihood ratio we plot their values for each pixel likelihood is dominated by the background pixels as we can see well the likelihood ratio focuses more on semantic pixels applying our method to the genomic data said we found likely for the ratio corrects for the background GC bias and it achieved the state of art to sum up we found the raw likelihood can be confirmed by the background we do I politely put the ratios that the corrects for the background and other forms the row like it would are all detection the new benchmark data set a new code is available and either sense for your attention",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4757",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/d80126524c1e9641333502c664fc6ca1-Paper.pdf",
        "paper_title": "Modelling heterogeneous distributions with an Uncountable Mixture of Asymmetric Laplacians",
        "paper_author": "Axel Brando &middot; Jose A Rodriguez &middot; Jordi Vitria &middot; Alberto Rubio Mu\u00f1oz",
        "video_link": "https://vimeo.com/369179175/a17d3de911",
        "abstract": "In regression tasks, aleatoric uncertainty is commonly addressed by considering a parametric distribution of the output variable, which is based on strong assumptions such as symmetry, unimodality or by supposing a restricted shape. These assumptions are too limited in scenarios where complex shapes, strong skews or multiple modes are present. In this paper, we propose a generic deep learning framework that learns an Uncountable Mixture of Asymmetric Laplacians (UMAL), which will allow us to estimate heterogeneous distributions of the output variable and we show its connections to quantile regression. Despite having a fixed number of parameters, the model can be interpreted as an infinite mixture of components, which yields a flexible approximation for heterogeneous distributions. Apart from synthetic cases, we apply this model to room price forecasting and to predict financial operations in personal bank accounts. We demonstrate that UMAL produces proper distributions, which allows us to extract richer insights and to sharpen decision-making.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6422",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/ee0c1616bbc82804b2f4b635d4a055fb-Paper.pdf",
        "paper_title": "Prediction of Spatial Point Processes: Regularized Method with Out-of-Sample Guarantees",
        "paper_author": "Muhammad Osama &middot; Dave Zachariah &middot; Peter Stoica",
        "video_link": "https://youtu.be/pg3Z3HEKHjc",
        "abstract": "A spatial point process can be characterized by an intensity function which predicts the number of events that occur across space. In this paper, we develop a method to infer predictive intensity intervals by learning a spatial model using a regularized criterion. We prove that the proposed method exhibits out-of-sample prediction performance guarantees which, unlike standard estimators, are valid even when the spatial model is misspecified. The method is demonstrated using synthetic as well as real spatial data.",
        "transcript": "so in this book we basically address the problem of prediction and special point browsers so suppose we observe events along the space as per some underlying intensity function and our goal is to predict counts why in a given region extent and we also want to produce intervals capital lambda of X in units of counts per unit area so that we can have validity as described in equation 1 but intervals produced by traditional parametric models are not valid if the assumed model class is wrong but in this work we want to produce intervals that will be valid even if the model is misses specified so in our approach we assume a space to be discretized into our regions which converts the event data into region and count pairs from some unknown distribution and we want to now learn a conditional distribution for counts given regions we assume the Poisson model class for the counts in every region where the mean is parametrized by theta we define the loss as the per sample KL divergence and the best model is the one that minimizes the smalls now suppose somehow from the data using some criteria we learn a model to eat ahead then you can use this model along with the conformal prediction frameworks to produce intensity intervals that are valid even under model misses pacification but to get intervals that are tight and informative you need a criteria that will give you a loss at theta hat which is close to the optimum loss so we propose the following criteria and this criteria leads to this provable out-of-sample accuracy guarantee so we can prove that the loss at theta hat learn using equation 3 would be close to the optimal loss according to equation 4 and this theorem basically leads to tired intervals so here we have a case where we generate count data using negative binomial distribution for three different intensity functions and the data in this region is missing so you can see that the average interval size for the proposed method in blue is four times less than the average intervals has produced by maximum likelihood moreover the empirical coverage is greater than the set 80 percent coverage probability for all the intensity functions here are some examples in one and two dimensions where we can see that the interval size also grows in Mason regions to reflect the inherent uncertainty so we basically proposed a method for producing valid intervals by using a Poisson model class which has an EZ which has a out-of-sample accuracy guarantee and board guarantees are valid even under model misses classification for more details you can look at our paper thank you",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-159",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/140f6969d5213fd0ece03148e62e461e-Paper.pdf",
        "paper_title": "Joint-task Self-supervised Learning for Temporal Correspondence",
        "paper_author": "Xueting Li &middot; Sifei Liu &middot; Shalini De Mello &middot; Xiaolong Wang &middot; Jan Kautz &middot; Ming-Hsuan Yang",
        "video_link": "https://www.youtube.com/watch?v=Rfy3dG3lRpM",
        "abstract": "This paper proposes to learn reliable dense correspondence from videos in a self-supervised manner. Our learning process integrates two highly related tasks: tracking large image regions and establishing fine-grained pixel-level associations between consecutive video frames. We exploit the synergy between both tasks through a shared inter-frame affinity matrix, which simultaneously models transitions between video frames at both the region- and pixel-levels. While region-level localization helps reduce ambiguities in fine-grained matching by narrowing down search regions; fine-grained matching provides bottom-up features to facilitate region-level localization. Our method outperforms the state-of-the-art self-supervised methods on a variety of visual correspondence tasks, including video-object and part-segmentation propagation, keypoint tracking, and object tracking. Our self-supervised method even surpasses the fully-supervised affinity feature representation obtained from a ResNet-18 pre-trained on the ImageNet.",
        "transcript": "in this work we learn real importance correspondence from videos in self supposed manner our learning process integrate two highly related tasks our children level matching which locates a local image region randomly cropped from a reference frame at another nearby frame and finally matching which establishes pixel level associations between these two widow friends although highly related in the previous work the object level organization and find when matching tasks are certainly served together due to the different optimization goals we on the other hand demonstrate that these two tasks benefit each other by sharing honorable into a friend affinity matrix that associates the content of the two images the rating level organization helps to reduce the ambiguities in fine-grained merging by narrowing down the search in regions where the fine grain merchant provides bottom-up features to facilitate reading level localization the two tasks is jointly trained and progressively benefit to each other specifically given two frames refers to randomly sample of hash from the first frame recorders up offering a sauce patch and a second frame as a jockey frame the seal and the learners image representations are features of pasta sauce pan and at a keyframe the affinity matrix is computed to represent the similarity between these two filaments but modified affinity matrix with the standard gray code in the matrix we are able to locate the source patch in a key frame as shown in the yellow boxes the localize the pair share common content with the sauce patch we call dispatch the target patch at final stage and then will emerge to walk the cat information from the source patch to the taki patch since the taki patch is a local region of the target frame a sub affinity matrix can be extracted accordingly we use this opportunity to work the color channels of the sauce patch well the differences between the predicted target patch and the Guangzhou's page serves as the spoliation signal with the shared affinity as the bridge the serum that's gradient from both tasks during the joint training process once the feature representation has involved the battle organization will be obtained where the color matching can be learned between a better aligned patches so the two stages improve each other and jointly benefit the sealants representation learning yourself civilized manner presentation will use to learn affinity matrix between consecutive frames to propagate various informations from the first frame to the rest of the video here we show the propagation of instrumentation masks on the dailies 17 - the set where the initial mask of the true object instances are provided at the first frame our method is able to preserve more details through propagation process sense to the learnt dance of vanity metrics and the joint training of region and pixel level matching the qualitative lead has to the user segmentation performance which shows that our model performs favorably against a stay of our messages more importantly our results surpass the feature which is super wisely learned on the large-scale internet data set beside segmentation masks we can also use the learned affinity matrix to propagate human hosts key points through the videos human opposed imitations in the first frame Republic eight the key points to the rest of the frames in traditional examples on human part publication but operating small possibly cross more fine queen details compared to populating the incense masks or model is still able to achieve decent result as shown in this video and here is another example",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-405",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/bbcbff5c1f1ded46c25d28119a85c6c2-Paper.pdf",
        "paper_title": "Learning Conditional Deformable Templates with Convolutional Networks",
        "paper_author": "Adrian Dalca &middot; Marianne Rakic &middot; John Guttag &middot; Mert Sabuncu",
        "video_link": "http://voxelmorph.mit.edu/atlas_creation/files/cr_video.mp4",
        "abstract": "\tWe develop a learning framework for building deformable templates, which play a fundamental role in many image analysis and computational anatomy tasks. Conventional methods for template creation and image alignment to the template have undergone decades of rich technical development. In these frameworks, templates are constructed using an iterative process of template estimation and alignment, which is often computationally very expensive. Due in part to this shortcoming, most methods compute a single template for the entire population of images, or a few templates for  specific sub-groups of the data. In this work, we present a probabilistic model and efficient learning strategy that yields either universal or \\textit{conditional} templates, jointly with a neural network that provides efficient alignment of the images to these templates. We demonstrate the usefulness of this method on a variety of domains, with a special focus on neuroimaging. This is particularly useful for clinical applications where a pre-existing template does not exist, or creating a new one with traditional methods can be prohibitively expensive. Our code and atlases are available online as part of the VoxelMorph library at http://voxelmorph.csail.mit.edu.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-667",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/b5dc4e5d9b495d0196f61d45b26ef33e-Paper.pdf",
        "paper_title": "Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations",
        "paper_author": "Vincent Sitzmann &middot; Michael Zollhoefer &middot; Gordon Wetzstein",
        "video_link": "https://vsitzmann.github.io/srns/video/",
        "abstract": "Unsupervised learning with generative models has the potential of discovering rich representations of 3D scenes. While geometric deep learning has explored 3D-structure-aware representations of scene geometry, these models typically require explicit 3D supervision. Emerging neural scene representations can be trained only with posed 2D images, but existing methods ignore the three-dimensional structure of scenes. We propose Scene Representation Networks (SRNs), a continuous, 3D-structure-aware scene representation that encodes both geometry and appearance. SRNs represent scenes as continuous functions that map world coordinates to a feature representation of local scene properties. By formulating the image formation as a differentiable ray-marching algorithm, SRNs can be trained end-to-end from only 2D images and their camera poses, without access to depth or shape. This formulation naturally generalizes across scenes, learning powerful geometry and appearance priors in the process. We demonstrate the potential of SRNs by evaluating them for novel view synthesis, few-shot reconstruction, joint shape and appearance interpolation, and unsupervised discovery of a non-rigid face model.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4493",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/438124b4c06f3a5caffab2c07863b617-Paper.pdf",
        "paper_title": "Learning-In-The-Loop Optimization: End-To-End Control And Co-Design Of Soft Robots Through Learned Deep Latent Representations",
        "paper_author": "Andrew Spielberg &middot; Allan Zhao &middot; Yuanming Hu &middot; Tao Du &middot; Wojciech Matusik &middot; Daniela Rus",
        "video_link": "https://youtu.be/umWPhw9o968",
        "abstract": "Soft robots have continuum solid bodies that can deform in an infinite number of ways. Controlling soft robots is very challenging as there are no closed form solutions.  We present a learning-in-the-loop co-optimization algorithm in which a latent state representation is learned as the robot figures out how to solve the task. Our solution marries hybrid particle-grid-based simulation with deep, variational convolutional autoencoder architectures that can capture salient features of robot dynamics with high efficacy. We demonstrate our dynamics-aware feature learning algorithm on both 2D and 3D soft robots, and show that it is more robust and faster converging than the dynamics-oblivious baseline.  We validate the behavior of our algorithm with visualizations of the learned representation.",
        "transcript": "we present a novel method for optimizing and controlling soft robots while simultaneously learning a compact representation of the robots state one of the largest challenges in modeling motion planning and control of soft robots is expressing their high dimensional state space with a lower dimensional representation that is tractable for control existing methods such as modal analysis can introduce modeling error and do not consider how a task will be completed our solution is to iteratively learn a latent space while simultaneously optimizing robot design parameters control parameters or both we build upon recent work in differentiable soft body physics engines which produce a fully differentiable simulations for optimization and differentially handle contact because these simulations are fully expressed on a grid we can apply deep convolutional neural networks to grid States and Lorna Li in space this control architecture is also fully differentiable meaning the entire system can be optimized via gradient based optimization techniques we demonstrate our algorithm our model robots this 2d biped must walk as far to the right as possible here is an optimized biped in both materials and control blue regions represent stiffer material you Center of the cross marked section on the the arm needs to reach the green circle this arm is relatively stiff compared to the amount of actuation that can receive and so it must optimize a controller that can swing back and forth to build up velocity to reach its target the center of the cross mark section on this 2d elephant needs to reach the green circle the elephant must optimize controller so that it can reach the target circle in this bunny task the robot must walk forward and its two upper arms or ears must reach the two circles this is a challenging task that cannot be solved with 100% accuracy this 2d rhinoceros robot was created directly from a dot PNG image to demonstrate that our algorithm is capable of handling unstructured inputs with curved sections in this extension to 3d this 3d quadruped it must run as far to the right as possible in the allotted time this variation preserves a curved analog of our boxier Khwaja pod and presents similar performance in forward locomotion this hexapod which also must run as far to the right as possible represents our most dynamically complex 3d example with 24 actuators thank you for your time",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1488",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/8a146f1a3da4700cbf03cdc55e2daae6-Paper.pdf",
        "paper_title": "Third-Person Visual Imitation Learning via Decoupled Hierarchical Controller",
        "paper_author": "Pratyusha Sharma &middot; Deepak Pathak &middot; Abhinav Gupta",
        "video_link": "https://youtu.be/eWBkDuNFEKA",
        "abstract": "We study a generalized setup for learning from demonstration to build an agent that can manipulate novel objects in unseen scenarios by looking at only a single video of human demonstration from a third-person perspective. To accomplish this goal, our agent should not only learn to understand the intent of the demonstrated third-person video in its context but also perform the intended task in its environment configuration. Our central insight is to enforce this structure explicitly during learning by decoupling what to achieve (intended task) from how to perform it (controller). We propose a hierarchical setup where a high-level module learns to generate a series of first-person sub-goals conditioned on the third-person video demonstration, and a low-level controller predicts the actions to achieve those sub-goals. Our agent acts from raw image observations without any access to the full state information. We show results on a real robotic platform using Baxter for the manipulation tasks of pouring and placing objects in a box. Project video is available at https://pathak22.github.io/hierarchical-imitation/",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1385",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf",
        "paper_title": "Multiview Aggregation for Learning Category-Specific Shape Reconstruction",
        "paper_author": "Srinath Sridhar &middot; Davis Rempe &middot; Julien Valentin &middot; Bouaziz Sofien &middot; Leonidas Guibas",
        "video_link": "https://geometry.stanford.edu/projects/xnocs",
        "abstract": "We investigate the problem of learning category-specific 3D shape reconstruction from a variable number of RGB views of previously unobserved object instances. Most approaches for multiview shape reconstruction operate on sparse shape representations, or assume a fixed number of views. We present a method that can estimate dense 3D shape, and aggregate shape across multiple and varying number of input views. Given a single input view of an object instance, we propose a representation that encodes the dense shape of the visible object surface as well as the surface behind line of sight occluded by the visible surface. When multiple input views are available, the shape representation is designed to be aggregated into a single 3D shape using an inexpensive union operation. We train a 2D CNN to learn to predict this representation from a variable number of views (1 or more). We further aggregate multiview information by using permutation equivariant layers that promote order-agnostic view information exchange at the feature level. Experiments show that our approach is able to produce dense 3D reconstructions of objects that improve in quality as more views are added.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-9052",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/1fa6269f58898f0e809575c9a48747ef-Paper.pdf",
        "paper_title": "TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines",
        "paper_author": "Jingxiang Lin &middot; Unnat Jain &middot; Alex Schwing",
        "video_link": "https://youtu.be/FS66skIlIYQ",
        "abstract": "Reasoning is an important ability that we learn from a very early age. Yet, reasoning is extremely hard for algorithms. Despite impressive recent progress that has been reported on tasks that necessitate reasoning, such as visual question answering and visual dialog, models often exploit biases in datasets. To develop models with better reasoning abilities, recently, the new visual commonsense reasoning (VCR) task has been introduced. Not only do models have to answer questions, but also do they have to provide a reason for the given answer. The proposed baseline achieved compelling results, leveraging a meticulously designed model composed of LSTM modules and attention nets. Here we show that a much simpler model obtained by ablating and pruning the existing intricate baseline can perform better with half the number of trainable parameters. By associating visual features with attribute information and better text to image grounding, we obtain further improvements for our simpler &amp; effective baseline, TAB-VCR. We show that this approach results in a 5.3%, 4.4% and 6.5% absolute improvement over the previous state-of-the-art on question answering, answer justification and holistic VCR. Webpage: https://deanplayerljx.github.io/tabvcr/",
        "transcript": "hi I'm Dean champ presenting our work on Tabrizi our tags and attributes based visual common-sense reasoning based on the shakaama sense reasoning consists of two related subtasks the first subtask is question answering note that for each image object detection czar provided by the test data set this deductions are directly referred to in the text missing tags targets are represented by the indices of the detected upon e boxes for example the question how did the lady and the man get here has two tags planning to corresponding person detections in image for this question the correct answer is the travelling a cart the second the results of the task is answer justification for this given question and the correct answer the model needs to choose a cracker rationale from four options here the crack formation is recorded to recite them is likely their mode of transportation we improved over previous methods on a ratio task using simple and effective baselines particularly our contributions are threefold first we use a simple base network with just half of the number of trainable parameters with this a patient will have work alone we improve over previous state of the art second we leverage attribute information about objects to augment the image features used by our network third we improve image tax funding by finding new tags and adding them to data set here is the architecture for simpler based Network we first take the detected objects and represent them using frasassi and features then we represent each word of a given sentence using protein-protein weddings next we concatenate each word inviting with their detection feature then the past base concatenated image text representations through an OST M we pulled out hood of ours TM together journey buddy for the image in the sentence the query and the options are represented using embeddings obtained via this approach each option is scored using a two layer MLP the internet work is Trina and to end using a cross entropy loss we further improve the models reasoning ability by augmenting image feature with corresponding object attribute information we achieve this by using a fuzzy and Virginia with an auxiliary task of predicting object attributes here are the models predicted attributes the model assign squared with hi is married to a woman and snelling to men this provides richer information for better reasoning also we found that the bcad Rosetta contains many words which are pointing to their corresponding detections in image for example the cart which is important for choosing the correct option was in fact not tacked to sub days we developed a simple algorithm for finding the additional tax here is the output of our algorithm on this example note that the word cart is not crack recorded which supports the reasoning process we quantitatively show that our simple base network also performs a model proposed by in the data we see our paper we also show that both are true edge words and new tags help improve performance on the BCR tasks we are operating with significantly fewer general parameters thank you",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-8215",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/1e0feeaff84a19bf3936e693311fa66d-Paper.pdf",
        "paper_title": "Deep Multi-State Dynamic Recurrent Neural Networks Operating on Wavelet Based Neural Features for Robust Brain Machine Interfaces",
        "paper_author": "Benyamin Allahgholizadeh Haghi &middot; Spencer Kellis &middot; Sahil Shah &middot; Maitreyi Ashok &middot; Luke Bashford &middot; Daniel Kramer &middot; Brian Lee &middot; Charles Liu &middot; Richard Andersen &middot; Azita Emami",
        "video_link": "https://www.youtube.com/watch?v=VbgM-hO_fQ0",
        "abstract": "We present a new deep multi-state Dynamic Recurrent Neural Network (DRNN) architecture for Brain Machine Interface (BMI) applications. Our DRNN is used to predict Cartesian representation of a computer cursor movement kinematics from open-loop neural data recorded from the posterior parietal cortex (PPC) of a human subject in a BMI system. We design the algorithm to achieve a reasonable trade-off between performance and robustness, and we constrain memory usage in favor of future hardware implementation. We feed the predictions of the network back to the input to improve prediction performance and robustness. We apply a scheduled sampling approach to the model in order to solve a statistical distribution mismatch between the ground truth and predictions. Additionally, we configure a small DRNN to operate with a short history of input, reducing the required buffering of input data and number of memory accesses. This configuration lowers the expected power consumption in a neural network accelerator. Operating on wavelet-based neural features, we show that the average performance of DRNN surpasses other state-of-the-art methods in the literature on both single- and multi-day data recorded over 43 days. Results show that multi-state DRNN has the potential to model the nonlinear relationships between the neural data and kinematics for robust BMIs.",
        "transcript": "hello I'm Benjamin Hockey and I'm presenting or paper with titled deep multi-state dynamic recurrent neural networks operating on wavelet based neural features for robots brain machine interfaces brain machine interfaces have many different applications in its most basic form they translate the neural data to useful control signals if we want to design a tiny chip and put it inside the brain so that this chip can decode the neural data for example here a tetraplegic patient is moving a robotic limb on the screen to a target but as you see he has some bulky devices and long wires on his head by designing this tiny chip we can get rid of these devices or goal is to use high-performance and robust machine learning algorithms to design low power and low area chip to minimize the treatment cost but the challenges or variability of the neural data and very limited data that we can record from a human subject we have shown in our paper that or DRN and outperforms other algorithms the key is that you are passing its own predictions to the next level to do the next prediction so the inputs are neural data and the previous prediction since we can assume that the movement is a continuous trajectory and then it does another prediction but then by flipping a coin we decide whether we pass the ground truth or its previous prediction at the beginning that the network hasn't learned how to do well they mostly pass the ground truth but after a while we pass its own prediction the other difference of our algorithm and compared to El SEM and ordinal is that we added a derivative state that the derivative of s is related to s and all that also exists in an RSS lsdm an Oran so this is architecture of our system first we are doing feature extraction from a IP and behave five regions of the brain and then by doing some data cleaning feature selection by X abuse and PCA of your decoding neural data to movement kinematics we are extracting wavelet based Fourier based and sparks features here are the results of the single day analysis of different quarters on wavelet based features as we see or do renin is doing smooth predictions and it outperforms others here the are performed or D or Ihnen on different features and we see that the ordinary wavelet feature is still out performing other features and then we evaluated different decoders with mid frequency wavelet feature and again we see that or Ihnen has better performance and then other decoders so in summary we are designing high performance algorithms by using informative features to implement them on an icy and implanted inside the brain I want to thank our team and then our code and our paper and supplementary material available online thank you",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4758",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/0bfce127947574733b19da0f30739fcd-Paper.pdf",
        "paper_title": "Learning Macroscopic Brain Connectomes via Group-Sparse Factorization",
        "paper_author": "Farzane Aminmansour &middot; Andrew Patterson &middot; Lei Le &middot; Yisu  Peng &middot; Daniel  Mitchell &middot; Franco Pestilli &middot; Cesar F Caiafa &middot; Russell Greiner &middot; Martha White",
        "video_link": "https://github.com/framinmansour/Learning-Macroscopic-Brain-Connectomes-via-Group-Sparse-Factorization/raw/master/video/3minute_presentation.mp4",
        "abstract": "Mapping structural brain connectomes for living human brains typically requires expert analysis and rule-based models on diffusion-weighted magnetic resonance imaging. A data-driven approach, however, could overcome limitations in such rule-based approaches and improve precision mappings for individuals. In this work, we explore a framework that facilitates applying learning algorithms to automatically extract brain connectomes. Using a tensor encoding, we design an objective with a group-regularizer that prefers biologically plausible fascicle structure. We show that the objective is convex and has unique solutions, ensuring identifiable connectomes for an individual. We develop an efficient optimization strategy for this extremely high-dimensional sparse problem, by reducing the number of parameters using a greedy algorithm designed specifically for the problem. We show that this greedy algorithm significantly improves on a standard greedy algorithm, called Orthogonal Matching Pursuit. We conclude with an analysis of the solutions found by our method, showing we can accurately reconstruct the diffusion information while maintaining contiguous fascicles with smooth direction changes.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1331",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/e077e1a544eec4f0307cf5c3c721d944-Paper.pdf",
        "paper_title": "Disentangled behavioural representations",
        "paper_author": "Amir Dezfouli &middot; Hassan Ashtiani &middot; Omar Ghattas &middot; Richard Nock &middot; Peter Dayan &middot; Cheng Soon Ong",
        "video_link": "https://vimeo.com/368702071",
        "abstract": "Individual characteristics in human decision-making are often\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-3508",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/7d2be41b1bde6ff8fe45150c37488ebb-Paper.pdf",
        "paper_title": "From voxels to pixels and back: Self-supervision in natural-image reconstruction from fMRI",
        "paper_author": "Roman Beliy &middot; Guy Gaziv &middot; Assaf Hoogi &middot; Francesca Strappini &middot; Tal Golan &middot; Michal Irani",
        "video_link": "https://www.youtube.com/watch?v=h2JhDAdaa-Q",
        "abstract": "Reconstructing observed images from fMRI brain recordings is challenging. Unfortunately, acquiring sufficient &#x27;&#x27;labeled&#x27;&#x27; pairs of {Image, fMRI} (i.e., images with their corresponding fMRI responses) to span the huge space of natural images is prohibitive for many reasons. We present a novel approach which, in addition to the scarce labeled data (training pairs), allows to train fMRI-to-image reconstruction networks also on &quot;unlabeled&quot; data (i.e., images without fMRI recording, and fMRI recording without images). The proposed model utilizes both an Encoder network (image-to-fMRI) and a Decoder network (fMRI-to-image). Concatenating these two networks back-to-back (Encoder-Decoder &amp; Decoder-Encoder) allows augmenting the training data with both types of unlabeled data. Importantly, it allows training on the unlabeled test-fMRI data. This self-supervision adapts the reconstruction network to the new input test-data, despite its deviation from the statistics of the scarce training data.",
        "transcript": "hello and welcome to this video summary of our work from voxels to pixels and back self supervision in natural image reconstruction from fMRI to be published at nori peace 2019 i'm gigas eve beach the candidate from the Mahalo Roni lab at the Weizmann Institute of Science and I'm going to walk you through the main contributions and results from this paper in this work we demonstrate highly accurate reconstruction of images observed by a subject using nothing but his recorded brain activity captured via fMRI we achieved this for two very different fMRI data set using a novel self supervised method the available data for the task consists of about a thousand pairs of images and their corresponding fMRI scans traditionally this paired or labeled data is used to learn the mapping between the visual stimuli and their brain activity representation however since the data is limited and cannot spend the huge space of natural images and natural fMRI samples such decoders are prone to poor generalization to new held out data we propose to put back-to-back an encoder model which Maps images to their fMRI and a decoder model which captures the inverse mapping the following training configuration imposes that images returned to themselves under transformation IDI encoder decoder this enables to train on additional data of any unlabeled images those can be images for which we don't have an fMRI recording at all in our case we used additional 50,000 natural images from image net validation set this introduces adaptation to the statistics of natural images moreover we can also cast a de encoder and the decoder the other way around imposing that unlabeled fMRI samples are mapped to themselves under transformation decoder encoder de once again you have the liberty to choose here your unlabeled data to train on importantly our approach encourages to use here the unlabeled fMRI samples from the test data but without using any of their corresponding images since those images are never used in it is perfectly legal to train on those tests have memorized samples which are just the samples from the decoders input space importantly this training configuration adapts the decoder to the statistics of your test fMRI data this is the main performance gain factor of our method we conduct training in two phases in the first phase we train the encoder alone in a supervised way this enables the encoder to converge first and serve as strong guidance for the decoder which is trained next in the second phase the encoders weights are fixed and we train the decoder on three objectives simultaneously within each single batch these objectives include supervised training on label training data and supervised training on unlabeled natural images and unsupervised training on unlabeled tests fMRI data let's see the effects of each of these components on the test three constructions so these are five test images never used in training this is what we get when we employ the decoder supervised training alone one can observe that the reconstructions are quite blurry adding the training on unlabeled images indeed introduces someone over F natural image statistics however the main leap appears when adding the training on unlabeled tests fMRI this highlights the importance of training on the input test data here the unlabeled test fMRI adaptation to test data makes our method reconstruct impressively not only selected few test examples but many of them all of which are included in the paper in addition our method is also easily applied to other very different Fri datasets under the same configuration and hyper parameters we also favorably compete against gun based methods which oftentimes produce natural-looking images but not as faithful as ours to the underlying fMRI and its corresponding ground truth image log on to our project website for more information about the project I'm going as Eve and thank you for watching",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6220",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/90cc440b1b8caa520c562ac4e4bbcb51-Paper.pdf",
        "paper_title": "Structured Graph Learning Via Laplacian Spectral Constraints",
        "paper_author": "Sandeep Kumar &middot; Jiaxi Ying &middot; Jose Vinicius de Miranda Cardoso &middot; Daniel Palomar",
        "video_link": "https://youtu.be/klAqFvyQx7k",
        "abstract": "Learning a graph with a specific structure is essential for interpretability and identification of the relationships among data. But structured graph learning from observed samples is an NP-hard combinatorial problem. In this paper, we first show, for a set of important graph families it is possible to convert the combinatorial constraints of structure into eigenvalue constraints of the graph Laplacian matrix. Then we introduce a unified graph learning framework lying at the integration of the spectral properties of the Laplacian matrix with Gaussian graphical modeling, which is capable of learning structures of a large class of graph families. The proposed algorithms are provably convergent and practically amenable for big-data specific tasks. Extensive numerical experiments with both synthetic and real datasets demonstrate the effectiveness of the proposed methods. An R package containing codes for all the experimental results is submitted as a supplementary file.",
        "transcript": "hello everyone you are watching a promotional video of our recent work accepted at new ribs 2019 structural graph learning viola plus in spectral constraints the existing state-of-the-art methods learn and directed Gaussian graphical models under the Gaussian Markov random field assumption by including laplacian constraints into the graph colossal framework however they fall short when it comes to include additional knowledge on the structure of the underlying graph which makes them unable to learn practical models such as key component grabs to an able learning of more complex structures we make use of the spectral constraints on the eigenvalues of the laplacian matrix however in this way the problem becomes intractable therefore we approximate the previous problem by adding a spectral regularization term to the objective function together with the constraints on the vector lambda the spectral regularization term can be thought of as a prior information on the graph structure unlike existing methods this formulation is able to learn structures that often appear in a supervised in machine learning tasks such as clustering here we see a few results on toi datasets we can verify that our algorithm is able to correctly cluster those e spatial datasets as for real datasets our algorithm achieves almost 100% accuracy in the Cancer Genome Atlas dataset which contains about 800 nodes each of which with 20,000 features the code for the paper is available online on github and Surin to see more come to our poster at no ribs 2019 thank you",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5017",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/0af787945872196b42c9f73ead2565c8-Paper.pdf",
        "paper_title": "Language as an Abstraction for Hierarchical Deep Reinforcement Learning",
        "paper_author": "YiDing Jiang &middot; Shixiang (Shane) Gu &middot; Kevin Murphy &middot; Chelsea Finn",
        "video_link": "https://drive.google.com/open?id=1tvJ6CsEdskbRIA2BFLxSgDqjbm1BaaRt",
        "abstract": "Solving complex, temporally-extended tasks is a long-standing problem in reinforcement learning (RL). We hypothesize that one critical element of solving such problems is the notion of compositionality. With the ability to learn sub-skills that can be composed to solve longer tasks, i.e. hierarchical RL, we can acquire temporally-extended behaviors. However, acquiring effective yet general abstractions for hierarchical RL is remarkably challenging. In this paper, we propose to use language as the abstraction, as it provides unique compositional structure, enabling fast learning and combinatorial generalization, while retaining tremendous flexibility, making it suitable for a variety of problems. Our approach learns an instruction-following low-level policy and a high-level policy that can reuse abstractions across tasks, in essence, permitting agents to reason using structured language. To study compositional task learning, we introduce an open-source object interaction environment built using the MuJoCo physics engine and the CLEVR engine. We find that, using our approach, agents can learn to solve to diverse, temporally-extended tasks such as object sorting and multi-object rearrangement, including from raw pixel observations. Our analysis find that the compositional nature of language is critical for learning and systematically generalizing sub-skills in comparison to non-compositional abstractions that use the same supervision.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1504",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/49b8b4f95f02e055801da3b4f58e28b7-Paper.pdf",
        "paper_title": "Learning Robust Options by Conditional Value at Risk Optimization",
        "paper_author": "Takuya Hiraoka &middot; Takahisa Imagawa &middot; Tatsuya Mori &middot; Takashi Onishi &middot; Yoshimasa Tsuruoka",
        "video_link": "https://drive.google.com/file/d/1DRmIaK5VomCey70rKD_5DgX2Jm_1rFlo/view",
        "abstract": "Options are generally learned by using an inaccurate environment model (or simulator), which contains uncertain model parameters.\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4994",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/1fd09c5f59a8ff35d499c0ee25a1d47e-Paper.pdf",
        "paper_title": "Multiclass Performance Metric Elicitation",
        "paper_author": "Gaurush Hiranandani &middot; Shant Boodaghians &middot; Ruta Mehta &middot; Sanmi Koyejo",
        "video_link": "https://drive.google.com/drive/folders/1AWZ6xvSUwNGQYeYzI2yf-MYPvgnba8YJ?usp=sharing",
        "abstract": "Metric Elicitation is a principled framework for selecting the performance metric that best reflects implicit user preferences. However, available strategies have so far been limited to binary classification. In this paper, we propose novel strategies for eliciting multiclass classification performance metrics using only relative preference feedback. We also show that the strategies are robust to both finite sample and feedback noise. ",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5517",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/6c7cd904122e623ce625613d6af337c4-Paper.pdf",
        "paper_title": "Poincar\u00e9 Recurrence, Cycles and Spurious Equilibria in Gradient-Descent-Ascent for Non-Convex Non-Concave Zero-Sum Games",
        "paper_author": "Emmanouil-Vasileios Vlatakis-Gkaragkounis &middot; Lampros Flokas &middot; Georgios Piliouras",
        "video_link": "http://www.cs.columbia.edu/~emvlatakis/Videos/Poincare_Recurrence_Cycles_and_Spurious_Equilibria_in_Gradient-Descent-Ascent_for_Non-Convex_Non-Concave_Zero-Sum_Games.html",
        "abstract": "We study a wide class of non-convex non-concave min-max games that generalizes over standard bilinear zero-sum games. In this class, players control the inputs of a smooth function whose output is being applied to a bilinear zero-sum game. This class of games is motivated by the  indirect nature of the competition in\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5823",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/658bbbdef9415ba5e2ff857f1146ba6e-Paper.pdf",
        "paper_title": "McDiarmid-Type Inequalities for Graph-Dependent Variables and Stability Bounds",
        "paper_author": "Rui (Ray) Zhang &middot; Xingwu Liu &middot; Yuyi Wang &middot; Liwei Wang",
        "video_link": "https://rui-ray-zhang.github.io/NIPS/NIPS.mp4",
        "abstract": "A crucial assumption in most statistical learning theory is that samples are independently and identically distributed (i.i.d.). However, for many real applications, the i.i.d. assumption does not hold. We consider learning problems in which examples are dependent and their dependency relation is characterized by a graph. To establish algorithm-dependent generalization theory for learning with non-i.i.d. data, we first prove novel McDiarmid-type concentration inequalities for Lipschitz functions of graph-dependent random variables. We show that concentration relies on the forest complexity of the graph, which characterizes the strength of the dependency. We demonstrate that for many types of dependent data, the forest complexity is small and thus implies good concentration. Based on our new inequalities we are able to build stability bounds for learning from graph-dependent data.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-3960",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/ac52c626afc10d4075708ac4c778ddfc-Paper.pdf",
        "paper_title": "Optimal Sparse Decision Trees",
        "paper_author": "Xiyang Hu &middot; Cynthia Rudin &middot; Margo Seltzer",
        "video_link": "https://www.youtube.com/watch?v=UMjMQaH508M",
        "abstract": "Decision tree algorithms have been among the most popular algorithms for interpretable (transparent) machine learning since the early 1980&#x27;s. The problem that has plagued decision tree algorithms since their inception is their lack of optimality, or lack of guarantees of closeness to optimality: decision tree algorithms are often greedy or myopic, and sometimes produce unquestionably suboptimal models. Hardness of decision tree optimization is both a theoretical and practical obstacle, and even careful mathematical programming approaches have not been able to solve these problems efficiently. This work introduces the first practical algorithm for optimal decision trees for binary variables. The algorithm is a co-design of analytical bounds that reduce the search space and modern systems techniques, including data structures and a custom bit-vector library. We highlight possible steps to improving the scalability and speed of future generations of this algorithm based on insights from our theory and experiments.",
        "transcript": "decision tree algorithms have been popular since the very beginning of machine learning the main problem that's always plagued decision tree algorithms is their lack of optimality because they've historically been greedy myopic algorithms like see four point five in cart and these algorithms construct trees from the top downward and then greedily prune them back afterward the problem is that if a greedy algorithm chooses the wrong split at the top of the tree there's no way to undo it so these greedy algorithms produce suboptimal trees but it's hard to improve over the greedy methods because decision tree optimization is hard both theoretically and practically right there's a combinatorial explosions in the number of possible trees we could consider and even careful modern approaches haven't been able to solve these problems efficiently our work provides the first practical algorithm for producing optimal sparse binary split decision trees we minimize the miss classification error regularized by the number of leaves in the tree we don't use greedy splitting and pruning instead we developed a specialized branch and bound method to solve the problem to optimality leveraging computational caching and when we solve it to optimality we get sparse accurate trees like this one on the Florida rear ass data our approach uses several important insights first we have a collection of analytical bounds that reduce the size of the search space and these bounds allow us to prove that certain partial trees can never be extended to form optimal full trees and these bounds tell us that the leaves of optimal trees must capture enough data and be accurate enough and if they're not we can eliminate that tree and its descendants and some of the bounds tell us that when the tree has too many leaves to be optimal then we can eliminate that tree and its descendants and there are several other bounds too we represent each tree only by its collection of leaves and this is a very convenient way to work with trees and restore balance and intermediate results within each leaf we also maintain a permutation map which lets us figure out whether we've already seen a different permutation of the leaves in a different tree that we've already explored and we can also detect when we create a leaf we've used before and avoid recomputing the bounds for that leaf again additionally we store a bit vector indicating which data points have features corresponding to the features described by the leaf and this lets us use fast bit vector operations to compute bounds and the bounds and bit vectors in each leaf also let us use incremental computation to evaluate the children of the leaf should we decide to split it these features the strong analytical bounds are representation the permutation map computational caching and incremental computation combined to make our implementation really really fast which lets us produce truly optimal and sparse decision trees thank you",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-3960",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/ac52c626afc10d4075708ac4c778ddfc-Paper.pdf",
        "paper_title": "Optimal Sparse Decision Trees",
        "paper_author": "Xiyang Hu &middot; Cynthia Rudin &middot; Margo Seltzer",
        "video_link": "https://www.youtube.com/watch?v=UMjMQaH508M",
        "abstract": "Decision tree algorithms have been among the most popular algorithms for interpretable (transparent) machine learning since the early 1980&#x27;s. The problem that has plagued decision tree algorithms since their inception is their lack of optimality, or lack of guarantees of closeness to optimality: decision tree algorithms are often greedy or myopic, and sometimes produce unquestionably suboptimal models. Hardness of decision tree optimization is both a theoretical and practical obstacle, and even careful mathematical programming approaches have not been able to solve these problems efficiently. This work introduces the first practical algorithm for optimal decision trees for binary variables. The algorithm is a co-design of analytical bounds that reduce the search space and modern systems techniques, including data structures and a custom bit-vector library. Our experiments highlight advantages in scalability, speed, and proof of optimality.",
        "transcript": "decision tree algorithms have been popular since the very beginning of machine learning the main problem that's always plagued decision tree algorithms is their lack of optimality because they've historically been greedy myopic algorithms like see four point five in cart and these algorithms construct trees from the top downward and then greedily prune them back afterward the problem is that if a greedy algorithm chooses the wrong split at the top of the tree there's no way to undo it so these greedy algorithms produce suboptimal trees but it's hard to improve over the greedy methods because decision tree optimization is hard both theoretically and practically right there's a combinatorial explosions in the number of possible trees we could consider and even careful modern approaches haven't been able to solve these problems efficiently our work provides the first practical algorithm for producing optimal sparse binary split decision trees we minimize the miss classification error regularized by the number of leaves in the tree we don't use greedy splitting and pruning instead we developed a specialized branch and bound method to solve the problem to optimality leveraging computational caching and when we solve it to optimality we get sparse accurate trees like this one on the Florida rear ass data our approach uses several important insights first we have a collection of analytical bounds that reduce the size of the search space and these bounds allow us to prove that certain partial trees can never be extended to form optimal full trees and these bounds tell us that the leaves of optimal trees must capture enough data and be accurate enough and if they're not we can eliminate that tree and its descendants and some of the bounds tell us that when the tree has too many leaves to be optimal then we can eliminate that tree and its descendants and there are several other bounds too we represent each tree only by its collection of leaves and this is a very convenient way to work with trees and restore balance and intermediate results within each leaf we also maintain a permutation map which lets us figure out whether we've already seen a different permutation of the leaves in a different tree that we've already explored and we can also detect when we create a leaf we've used before and avoid recomputing the bounds for that leaf again additionally we store a bit vector indicating which data points have features corresponding to the features described by the leaf and this lets us use fast bit vector operations to compute bounds and the bounds and bit vectors in each leaf also let us use incremental computation to evaluate the children of the leaf should we decide to split it these features the strong analytical bounds are representation the permutation map computational caching and incremental computation combined to make our implementation really really fast which lets us produce truly optimal and sparse decision trees thank you",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5350",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/fd0a5a5e367a0955d81278062ef37429-Paper.pdf",
        "paper_title": "Unsupervised Meta-Learning for Few-Shot Image Classification",
        "paper_author": "Siavash Khodadadeh &middot; Ladislau Boloni &middot; Mubarak Shah",
        "video_link": "https://github.com/siavash-khodadadeh/MetaLearning-TF2.0/raw/master/UMTRA_Paper/VideoPresentation.mp4",
        "abstract": "Few-shot or one-shot learning of classifiers requires a significant inductive bias towards the type of task to be learned. One way to acquire this is by meta-learning on tasks similar to the target task. In this paper, we propose UMTRA, an algorithm that performs unsupervised, model-agnostic meta-learning for classification tasks.\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2016",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/95192c98732387165bf8e396c0f2dad2-Paper.pdf",
        "paper_title": "MCP: Learning Composable Hierarchical Control with Multiplicative Compositional Policies",
        "paper_author": "Xue Bin Peng &middot; Michael Chang &middot; Grace Zhang &middot; Pieter Abbeel &middot; Sergey Levine",
        "video_link": "https://youtu.be/HLD6H2eJK1E",
        "abstract": "Humans are able to perform a myriad of sophisticated tasks by drawing upon skills acquired through prior experience. For autonomous agents to have this capability, they must be able to extract reusable skills from past experience that can be recombined in new ways for subsequent tasks. Furthermore, when controlling complex high-dimensional morphologies, such as humanoid bodies, tasks often require coordination of multiple skills simultaneously. Learning discrete primitives for every combination of skills quickly becomes prohibitive. Composable primitives that can be recombined to create a large variety of behaviors can be more suitable for modeling this combinatorial explosion. In this work, we propose multiplicative compositional policies (MCP), a method for learning reusable motor skills that can be composed to produce a range of complex behaviors. Our method factorizes an agent&#x27;s skills into a collection of primitives, where multiple primitives can be activated simultaneously via multiplicative composition. This flexibility allows the primitives to be transferred and recombined to elicit new behaviors as necessary for novel tasks. We demonstrate that MCP is able to extract composable skills for highly complex simulated characters from pre-training tasks, such as motion imitation, and then reuse these skills to solve challenging continuous control tasks, such as dribbling a soccer ball to a goal, and picking up an object and transporting it to a target location.",
        "transcript": "in this work we introduced multiplicative compositional policies a method for learning reusable motor primitives that can be composed to produce a flexible range of skills standard hierarchical policies compose primitive skills by using a gating function which specifies the probability of activating each primitive in a given scenario one of the limitations of this model is that only one primitive can be activated at each time step which can restrict the range of behaviors that can be produced by the composite policy we propose combining primitives using a multiplicative composition scheme which enables multiple primitives to be activated simultaneously and contribute to the composite policies action distribution the weights from the gating function specify each permit of influence on the composite distribution with the higher weight corresponding to a larger influence given a state each primitive proposes in action distribution in response to that state the gating function receives both the state and a task specific goal as input then outputs the weights for each primitive the distributions are then composed according to the weights to produce the composite action distribution each primitives action distribution is modeled by a Gaussian varying the weights produces different interpolations of the primitives distributions primitives are learned through pre-training tasks that encourage the primitives to specialize in different skills when transferring the primitives to new tasks a new gating function is trained to compose the primitives for the new task the primitives are trained by imitating reference motions such as mocap clips recorded from human actors once trained the primitives can be transferred to challenging new tasks such as picking up an object and carrying it to a target location we can also train characters to dribble a soccer ball to a goal more details are available in the paper thanks for watching",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2447",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/2c3ddf4bf13852db711dd1901fb517fa-Paper.pdf",
        "paper_title": "Uncertainty-based Continual Learning with Adaptive Regularization",
        "paper_author": "Hongjoon Ahn &middot; Sungmin Cha &middot; Donggyu Lee &middot; Taesup Moon",
        "video_link": "https://sites.google.com/view/project-page-of-ucl",
        "abstract": "We introduce a new neural network-based continual learning algorithm, dubbed as Uncertainty-regularized Continual Learning (UCL), which builds on traditional Bayesian online learning framework with variational inference. We focus on two significant drawbacks of the recently proposed regularization-based methods: a) considerable additional memory cost for determining the per-weight regularization strengths and b) the absence of gracefully forgetting scheme, which can prevent performance degradation in learning new tasks. In this paper, we show UCL can solve these two problems by introducing a fresh interpretation on the Kullback-Leibler (KL) divergence term of the variational lower bound for Gaussian mean-field approximation. Based on the interpretation, we propose the notion of node-wise uncertainty, which drastically reduces the number of additional parameters for implementing per-weight regularization. Moreover, we devise two additional regularization terms that enforce \\emph{stability} by freezing important parameters for past tasks and allow \\emph{plasticity} by controlling the actively learning parameters for a new task. Through extensive experiments, we show UCL convincingly outperforms most of recent state-of-the-art baselines not only on popular supervised learning benchmarks, but also on challenging lifelong reinforcement learning tasks. The source code of our algorithm is available at  https://github.com/csm9493/UCL.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4192",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/cd474f6341aeffd65f93084d0dae3453-Paper.pdf",
        "paper_title": "A Unifying Framework for Spectrum-Preserving Graph Sparsification and Coarsening",
        "paper_author": "Gecia Bravo-Hermsdorff &middot; Lee Gunderson",
        "video_link": "https://www.youtube.com/watch?v=xTAPZbQlq3A",
        "abstract": "How might one &quot;reduce&quot; a graph?\n",
        "transcript": "In this video, we describe an analytic unification of two actions frequently used in graph reduction: the deletion of edges, often used in graph sparsification algorithms, and the contraction of edges (that is, the merging of two adjacent nodes), which is often used in graph coarsening algorithms. Prior to this work, sparsification and coarsening were treated as separate algorithmic primitives, with different objective functions. What you are seeing now  is our graph reduction algorithm in action, which uses this analytic unification to simultaneously sparsify and coarsen a graph. The actions of edge deletion and edge contraction are, in fact, dual operations. One manifestation of this duality is seen by considering a planar graph, shown here in blue. The planar dual of this graph, shown here in red, is created by first placing its red vertices in the regions formed by the planar embedding of the original graph. Then, one adds a red edge between each of these red vertices that share a blue border. Notice that the planar dual always has the same number of edges as the original graph, such that each edge in one graph crosses exactly one edge in the other graph. Now, if one of the blue edges is deleted, its corresponding red edge is contracted, merging the two red nodes into one. Likewise, if a blue edge were to be contracted, it would amount to deleting its corresponding red edge. This duality generalizes to non planar graphs by considering its associated graphic matroid and its dual. Algebraically, this duality is reflected in the graph Laplacian, a matrix operator related to diffusion throughout a graph, and whose spectrum reveals information about the graph's global structure. Indeed, many sparsification and coarsening algorithms aim to preserve properties associated with the graph Laplacian. Consider the heat equation,  a prototypical diffusive process. With respect to the dynamics of this differential equation, edge deletion corresponds to the limit of zero edge weight, while edge contraction corresponds to  the limit of infinite edge weight. However, this edge contraction limit requires some entries in the graph Laplacian to become infinite, making analytic treatment difficult. Our primary insight came from the fact that the  inverse of the graph Laplacian remains finite in both of these limits. And in fact, many relevant problems on graphs involve solving the equation Lx = b for x, so the solution is given by applying the inverse to b. Moreover, while the lowest eigenvalues of the Laplacian are associated with the graph's global structure, by inverting the spectrum, these correspond to the highest eigenvalues of the inverse Laplacian. Motivated by these considerations,  we developed a probabilistic graph reduction algorithm that preserves the inverse Laplacian in expectation and aims to minimize the expected squared error for a given amount of reduction. Thus, by preserving the inverse Laplacian, our algorithm is able to perform both edge deletion and edge contraction while preferentially retaining the large-scale structure of a graph. If this video piqued your interest please stop by our poster Wednesday from 5 to 7 p.m. in East Exhibition Hall B+C. Thanks for watching!",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-8774",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/e9bf14a419d77534105016f5ec122d62-Paper.pdf",
        "paper_title": "DeepWave: A Recurrent Neural-Network for Real-Time Acoustic Imaging",
        "paper_author": "Matthieu SIMEONI &middot; Sepand Kashani &middot; Paul Hurley &middot; Martin Vetterli",
        "video_link": "https://www.youtube.com/watch?v=PwB3CS2rHdI",
        "abstract": "We propose a recurrent neural-network for real-time reconstruction of acoustic camera spherical maps. The network, dubbed DeepWave, is both physically and algorithmically motivated: its recurrent architecture mimics iterative solvers from convex optimisation, and its parsimonious parametrisation is based on the natural structure of acoustic imaging problems.\n",
        "transcript": "he had your dark suit and greasy washed water all year he had dark wash water all year he had your dark suit and greasy washed water all year he had your dark suit and greasy washed water all year all year he had your dark suit and greasy wash",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2765",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/370bfb31abd222b582245b977ea5f25a-Paper.pdf",
        "paper_title": "Few-shot Video-to-Video Synthesis",
        "paper_author": "Ting-Chun Wang &middot; Ming-Yu Liu &middot; Andrew Tao &middot; Guilin Liu &middot; Bryan Catanzaro &middot; Jan Kautz",
        "video_link": "https://www.youtube.com/watch?v=8AZBuyEuDqc",
        "abstract": "Video-to-video synthesis (vid2vid) aims at converting an input semantic video, such as videos of human poses or segmentation masks, to an output photorealistic video. While the state-of-the-art of vid2vid has advanced significantly, existing approaches share two major limitations. First, they are data-hungry. Numerous images of a target human subject or a scene are required for training. Second, a learned model has limited generalization capability. A pose-to-human vid2vid model can only synthesize poses of the single person in the training set. It does not generalize to other humans that are not in the training set. To address the limitations, we propose a few-shot vid2vid framework, which learns to synthesize videos of previously unseen subjects or scenes by leveraging few example images of the target at test time. Our model achieves this few-shot generalization capability via a novel network weight generation module utilizing an attention mechanism. We conduct extensive experimental validations with comparisons to strong baselines using several large-scale video datasets including human-dancing videos, talking-head videos, and street-scene videos. The experimental results verify the effectiveness of the proposed framework in addressing the two limitations of existing vid2vid approaches.",
        "transcript": "we present a few short framework for video to video synthesis our network can translate high-level representation videos to photorealistic videos based on example image when we change the example images the same model can generate different looking outputs for example given an image of a person we can transfer the motion of other persons to the person in the example image here are the synthesized sequences known as the results realistically capture the moving motions for all different subjects while still maintaining the appearance of the original person this shows that our model can be generalized to unseen subjects not present in the training set here we show more examples of different dancing sequences moreover we can also transfer motions to sculpture images making steel object stands like a real human as well in addition to pop sequences often work can also be applied to faces here is surely example images the driving sequences which we steal the motion from and the synthesized results again the results faithfully reflects the inked emotions while preserving the person's identity in example images we can also transfer motion to paintings thus making still pictures talk in a lively way finally our model can also be applied to stray things we use images from different cities as the example images and synthesized sequences of different styles thank you please find our website encode here",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-753",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/6f2268bd1d3d3ebaabb04d6b5d099425-Paper.pdf",
        "paper_title": "Image Synthesis with a Single (Robust) Classifier",
        "paper_author": "Shibani Santurkar &middot; Andrew Ilyas &middot; Dimitris Tsipras &middot; Logan Engstrom &middot; Brandon Tran &middot; Aleksander Madry",
        "video_link": "https://youtu.be/l3SoeIIjxTM",
        "abstract": "We show that the basic classification framework alone can be used to tackle some of the most challenging tasks in image synthesis. In contrast to other state-of-the-art approaches, the toolkit we develop is rather minimal: it uses a single, off-the-shelf classifier for all these tasks. The crux of our approach is that we train this classifier to be adversarially robust. It turns out that adversarial robustness is precisely what we need to directly manipulate salient features of the input. Overall, our findings demonstrate the utility of robustness in the broader machine learning context.",
        "transcript": "this is a video summary of our nukes 2019 paper image synthesis with a single robust classifier it is by now clear that deep neural networks have evolution s computer vision the world easily successfully as the most experts and have since been used to build a sophistic intuitive for higher vision tasks the keeper should explore theories are simply claspers enough to perform some of these more advanced tasks from an undisturbed we need to manipulate the input in a semantic way how do we do this using a classifier the most natural approach would be to maximize the score for chosen class as predicted by the classifier for example we can try to make this skype don't like by increasing the dog score let's try this out well it didn't really work the change the name put is very noticeable in fact this shouldn't come as a surprise we already know from the notorious and reserve exams that class effects are sensitive to small changes in the input in order to perform in manipulation we need to at least ensure that our classifiers are not too pretty in other words what seems to be missing here is robustness well if we instead cleaner models to also be invariant to small input changes using robust optimization this works glass maximization for busman's seems to actually add minifig dog features the diamond so starting from this primitive what kind of visual tasks can we do internal policy and also questioning thus create the center of the cache course with no priors or regular returns is enough for example we can do things like generation for large data sets like a madman super resolution in painting where the code is reconstruct a corrupted image image dimension station such as turning horses to zoom and vice versa or even turn crude steps into out taking this further McKellar to directly paying teachers on to Avengers beyond these applications the world has shown that robust class pairs can be used for imaginative and star transfer overall the broader message of our paper is that robustness can be useful beyond the security context in fact robust models can be versatile tools for domain specific applications you can read more her paper on purpose we also release her library robustness which can be used to replicate these experiments finally check out our other newspaper on understanding of material examples as a phenomenon",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2164",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/c3e4035af2a1cde9f21e1ae1951ac80b-Paper.pdf",
        "paper_title": "Domes to Drones: Self-Supervised Active Triangulation for 3D Human Pose Reconstruction",
        "paper_author": "Aleksis Pirinen &middot; Erik G\u00e4rtner &middot; Cristian Sminchisescu",
        "video_link": "https://lu.app.box.com/s/xd1nidkirdlg0htlkyomq33ipk01k6gk",
        "abstract": "Existing state-of-the-art estimation systems can detect 2d poses of multiple people in images quite reliably. In contrast, 3d pose estimation from a single image is ill-posed due to occlusion and depth ambiguities. Assuming access to multiple cameras, or given an active system able to position itself to observe the scene from multiple viewpoints, reconstructing 3d pose from 2d measurements becomes well-posed within the framework of standard multi-view geometry. Less clear is what is an informative set of viewpoints for accurate 3d reconstruction, particularly in complex scenes, where people are occluded by others or by scene objects. In order to address the view selection problem in a principled way, we here introduce ACTOR, an active triangulation agent for 3d human pose reconstruction. Our fully trainable agent consists of a 2d pose estimation network (any of which would work) and a deep reinforcement learning-based policy for camera viewpoint selection. The policy predicts observation viewpoints, the number of which varies adaptively depending on scene content, and the associated images are fed to an underlying pose estimator. Importantly, training the view selection policy requires no annotations -- given a pre-trained 2d pose estimator, ACTOR is trained in a self-supervised manner. In extensive evaluations on complex multi-people scenes filmed in a Panoptic dome, under multiple viewpoints, we compare our active triangulation agent to strong multi-view baselines, and show that ACTOR produces significantly more accurate 3d pose reconstructions. We also provide a proof-of-concept experiment indicating the potential of connecting our view selection policy to a physical drone observer.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-365",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/9be40cee5b0eee1462c82c6964087ff9-Paper.pdf",
        "paper_title": "Multiway clustering via tensor block models  ",
        "paper_author": "Miaoyan Wang &middot; Yuchen Zeng",
        "video_link": "https://youtu.be/b3sOTLwxHMY",
        "abstract": "We consider the problem of identifying multiway block structure from a large noisy tensor. Such problems arise frequently in applications such as genomics, recommendation system, topic modeling, and sensor network localization. We propose a tensor block model, develop a unified least-square estimation, and obtain the theoretical accuracy guarantees for multiway clustering. The statistical convergence of the estimator is established, and we show that the associated clustering procedure achieves partition consistency. A sparse regularization is further developed for identifying important blocks with elevated means. The proposal handles a broad range of data types, including binary, continuous, and hybrid observations. Through simulation and application to two real datasets, we demonstrate the outperformance of our approach over previous methods.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2764",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/98d8a23fd60826a2a474c5b4f5811707-Paper.pdf",
        "paper_title": "Visual Concept-Metaconcept Learning",
        "paper_author": "Chi Han &middot; Jiayuan Mao &middot; Chuang Gan &middot; Josh Tenenbaum &middot; Jiajun Wu",
        "video_link": "https://drive.google.com/open?id=1yP5gYyd8-Tx8SKvd1bWbO2H7prZO1Ndn",
        "abstract": "Humans reason with concepts and metaconcepts: we recognize red and blue from visual input; we also understand that they are colors, i.e., red is an instance of color. In this paper, we propose the visual concept-metaconcept learner (VCML) for joint learning of concepts and metaconcepts from images and associated question-answer pairs. The key is to exploit the bidirectional connection between visual concepts and metaconcepts. Visual representations provide grounding cues for predicting relations between unseen pairs of concepts. Knowing that red and blue are instances of color, we generalize to the fact that green is also an instance of color since they all categorize the hue of objects. Meanwhile, knowledge about metaconcepts empowers visual concept learning from limited, noisy, and even biased data. From just a few examples of purple cubes we can understand a new color purple, which resembles the hue of the cubes instead of the shape of them. Evaluation on both synthetic and real-world datasets validates our claims.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6955",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/4fdaa19b1f22a4d926fce9bfc7c61fa5-Paper.pdf",
        "paper_title": "Neuropathic Pain Diagnosis Simulator for Causal Discovery Algorithm Evaluation",
        "paper_author": "Ruibo Tu &middot; Kun Zhang &middot; Bo Bertilson &middot; Hedvig Kjellstrom &middot; Cheng Zhang",
        "video_link": "https://youtu.be/1UvVnIbjSX8",
        "abstract": "Discovery of causal relations from observational data is essential for many disciplines of science and real-world applications. However, unlike other machine learning algorithms, whose development has been greatly fostered by a large amount of available benchmark datasets, causal discovery algorithms are notoriously difficult to be systematically evaluated because few datasets with known ground-truth causal relations are available. In this work, we handle the problem of evaluating causal discovery algorithms by building a flexible simulator in the medical setting. We develop a neuropathic pain diagnosis simulator, inspired by the fact that the biological processes of neuropathic pathophysiology are well studied with well-understood causal influences. Our simulator exploits the causal graph of the neuropathic pain pathology and its parameters in the generator are estimated from real-life patient cases. We show that the data generated from our simulator have similar statistics as real-world data. As a clear advantage, the simulator can produce infinite samples without jeopardizing the privacy of real-world patients. Our simulator provides a natural tool for evaluating various types of causal discovery algorithms, including those to deal with practical issues in causal discovery, such as unknown confounders, selection bias, and missing data. Using our simulator, we have evaluated extensively causal discovery algorithms under various settings. ",
        "transcript": "hello everyone in this paper we propose a neuropathic pain diagnosis simulator for causal discovery evaluation a fundamental task in various disciplines of science is to find underlying causal relations and make use of them to understand and explain phenomena causal discovery aims for finding causal relationships by analyzing observational data assume that we have proposed a causal discovery method and we want to evaluate it we generally achieve this by testing our method on ground truth annotated real-world data a lemma there are very few real-world data sets available for constant discovery evaluation because it is difficult to get ground truth about causal relations moreover the challenges in real data analysis make the evaluation even harder to bypass real data related difficulties we use synthetic data for evaluations instead we know however that there is a performance gap between synthetic data and real data researchers today test their various methods using different synthetic datasets thus it is hard to compare ones method with others and improve upon them to solve such problems we can use simulators for evaluating causal discovery methods a simulator can mimic real-world scenarios and involve real data challenges our simulator is based on Europe attic pain diagnosis because the causal connections are known from exhaustive biomedical research for example due to lifting a heavy bag Alex hurt his disc alignment l5 to s1 this presses the nerve l5 and causes l5 radiculopathy consequently l5 radiculopathy causes the lower back and knee pain with the help of doctors we thoroughly summarized all the causal relations that we know of into a directed graph for simulating data from such a causal graph we need to know the conditional probability distribution for every node we use a real-world data set of 141 patients for learning the parameters we can then sample the synthetic data that we need from our simulator more details about our simulator can be found in this paper we show that our simulation data are indistinguishable from the real Diagnostics records even medical experts are unable to tell the difference we also evaluate causal discovery algorithms with our simulator in the presence of various practical challenges our simulator is fully open source online with data generation code that can be used with one single command line many examples for causal discovery evaluation are also valuable check them out use them for your research and cite us accordingly thank you",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-8401",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/c055dcc749c2632fd4dd806301f05ba6-Paper.pdf",
        "paper_title": "Icebreaker: Element-wise Efficient Information Acquisition with a Bayesian Deep Latent Gaussian Model",
        "paper_author": "Wenbo Gong &middot; Sebastian Tschiatschek &middot; Sebastian Nowozin &middot; Richard Turner &middot; Jos\u00e9 Miguel Hern\u00e1ndez-Lobato &middot; Cheng Zhang",
        "video_link": "https://www.youtube.com/watch?feature=%3Dyoutu.be",
        "abstract": "In this paper, we address the ice-start problem, i.e., the challenge of deploying machine learning models when only a little or no training data is initially available, and acquiring each feature element of data is associated with costs. This setting is representative of the real-world machine learning applications. For instance, in the health care domain, obtaining every single measurement comes with a cost. We propose Icebreaker, a principled framework for elementwise training data acquisition. Icebreaker introduces a full Bayesian Deep Latent Gaussian Model (BELGAM) with a novel inference method, which combines recent advances in amortized inference and stochastic gradient MCMC to enable fast and accurate posterior inference. By utilizing BELGAM\u2019s ability to fully quantify model uncertainty, we also propose two information acquisition functions for imputation and active prediction problems. We demonstrate that BELGAM performs significantly better than previous variational autoencoder (VAE) based models, when the data set size is small, using both machine learning benchmarks and real world recommender systems and health-care applications. Moreover, Icebreaker not only demonstrates improved performance compared to baselines, but it is also capable of achieving better test performance with less training data available.",
        "transcript": "hello everyone in this paper we propose a neuropathic pain diagnosis simulator for causal discovery evaluation a fundamental task in various disciplines of science is to find underlying causal relations and make use of them to understand and explain phenomena causal discovery aims for finding causal relationships by analyzing observational data assume that we have proposed a causal discovery method and we want to evaluate it we generally achieve this by testing our method on ground truth annotated real-world data a lemma there are very few real-world data sets available for constant discovery evaluation because it is difficult to get ground truth about causal relations moreover the challenges in real data analysis make the evaluation even harder to bypass real data related difficulties we use synthetic data for evaluations instead we know however that there is a performance gap between synthetic data and real data researchers today test their various methods using different synthetic datasets thus it is hard to compare ones method with others and improve upon them to solve such problems we can use simulators for evaluating causal discovery methods a simulator can mimic real-world scenarios and involve real data challenges our simulator is based on Europe attic pain diagnosis because the causal connections are known from exhaustive biomedical research for example due to lifting a heavy bag Alex hurt his disc alignment l5 to s1 this presses the nerve l5 and causes l5 radiculopathy consequently l5 radiculopathy causes the lower back and knee pain with the help of doctors we thoroughly summarized all the causal relations that we know of into a directed graph for simulating data from such a causal graph we need to know the conditional probability distribution for every node we use a real-world data set of 141 patients for learning the parameters we can then sample the synthetic data that we need from our simulator more details about our simulator can be found in this paper we show that our simulation data are indistinguishable from the real Diagnostics records even medical experts are unable to tell the difference we also evaluate causal discovery algorithms with our simulator in the presence of various practical challenges our simulator is fully open source online with data generation code that can be used with one single command line many examples for causal discovery evaluation are also valuable check them out use them for your research and cite us accordingly thank you",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-7407",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/99a401435dcb65c4008d3ad22c8cdad0-Paper.pdf",
        "paper_title": "ODE2VAE: Deep generative second order ODEs with Bayesian neural networks",
        "paper_author": "Cagatay Yildiz &middot; Markus Heinonen &middot; Harri Lahdesmaki",
        "video_link": "https://github.com/cagatayyildiz/ODE2VAE",
        "abstract": "We present Ordinary Differential Equation Variational Auto-Encoder (ODE2VAE), a latent second order ODE model for high-dimensional sequential data. Leveraging the advances in deep generative models, ODE2VAE can simultaneously learn the embedding of high dimensional trajectories and infer arbitrarily complex continuous-time latent dynamics. Our model explicitly decomposes the latent space into momentum and position components and solves a second order ODE system, which is in contrast to recurrent neural network (RNN) based time series models and recently proposed black-box ODE techniques. In order to account for uncertainty, we propose probabilistic latent ODE dynamics parameterized by deep Bayesian neural networks. We demonstrate our approach on motion capture, image rotation, and bouncing balls datasets. We achieve state-of-the-art performance in long term motion prediction and imputation tasks.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5181",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/3b7d09dac07c9ccd3aae2025cc195250-Paper.pdf",
        "paper_title": "Convergence-Rate-Matching Discretization of Accelerated Optimization Flows Through Opportunistic State-Triggered Control",
        "paper_author": "Miguel Vaquero &middot; Jorge Cortes",
        "video_link": "https://www.dropbox.com/sh/aildrjci7n55359/AAB1A2jEg66lgs2k8s2GWuWAa?dl=0",
        "abstract": "A recent body of exciting work seeks to shed light on the behavior of accelerated methods in optimization via high-resolution differential equations. These differential equations are continuous counterparts of the discrete-time optimization algorithms, and their convergence properties can be characterized using the powerful tools provided by classical Lyapunov stability analysis. An outstanding question of pivotal importance is how to discretize these continuous flows while maintaining their convergence rates. This paper provides a novel approach through the idea of opportunistic state-triggered control. We take advantage of the Lyapunov functions employed to characterize the rate of convergence of high-resolution differential equations to design variable-stepsize forward-Euler discretizations that preserve the Lyapunov decay of the original dynamics. The philosophy of our approach is not limited to forward-Euler discretizations and may be combined with other integration schemes.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5343",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/8dd291cbea8f231982db0fb1716dfc55-Paper.pdf",
        "paper_title": "Decentralized sketching of low rank matrices",
        "paper_author": "Rakshith Sharma Srinivasa &middot; Kiryung Lee &middot; Marius  Junge &middot; Justin Romberg",
        "video_link": "https://www.dropbox.com/sh/kpl064804i9ks1y/AADxPFiVivRDgPlku0lXX68na?dl=0",
        "abstract": "We address a low-rank matrix recovery problem where each column of a rank-r matrix X of size (d1,d2) is compressed beyond the point of recovery to size L with L &lt;&lt; d1. Leveraging the joint structure between the columns, we propose a method to recover the matrix to within an epsilon relative error in the Frobenius norm from a total of O(r(d_1 + d_2)\\log^6(d_1 + d_2)/\\epsilon^2) observations. This guarantee holds uniformly for all incoherent matrices of rank r. In our method, we propose to use a novel matrix norm called the mixed-norm along with the maximum l2 norm of the columns to design a novel convex relaxation for low-rank recovery that is tailored to our observation model. We also show that our proposed mixed-norm, the standard nuclear norm, and the max-norm are particular instances of convex regularization of low-rankness via tensor norms. Finally, we provide a scalable ADMM algorithm for the mixed-norm based method and demonstrate its empirical performance via large-scale simulations. ",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6671",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/a1e865a9b1065392ed6035d8ccd072d9-Paper.pdf",
        "paper_title": "Fast and Accurate Stochastic Gradient Estimation",
        "paper_author": "Beidi Chen &middot; Yingchen Xu &middot; Anshumali Shrivastava",
        "video_link": "https://drive.google.com/open?id=1GJAErrv_7iAvzqhJEcfZd2vGVnQdaA_A",
        "abstract": "Stochastic Gradient Descent or SGD is the most popular optimization algorithm for large-scale problems. SGD estimates the gradient by uniform sampling with sample size one. There have been several other works that suggest faster epoch-wise convergence by using weighted non-uniform sampling for better gradient estimates. Unfortunately, the per-iteration cost of maintaining this adaptive distribution for gradient estimation is more than calculating the full gradient itself, which we call the chicken-and-the-egg loop. As a result, the false impression of faster convergence in iterations, in reality, leads to slower convergence in time. In this paper, we break this barrier by providing the first demonstration of a scheme, Locality sensitive hashing (LSH) sampled Stochastic Gradient Descent (LGD), which leads to superior gradient estimation while keeping the sampling cost per iteration similar to that of the uniform sampling. Such an algorithm is possible due to the sampling view of LSH, which came to light recently. As a consequence of superior and fast estimation, we reduce the running time of all existing gradient descent algorithms, that relies on gradient estimates including Adam, Ada-grad, etc. We demonstrate the effectiveness of our proposal with experiments on linear models as well as the non-linear BERT, which is a recent popular deep learning based language representation model.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-7941",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/46c7cb50b373877fb2f8d5c4517bb969-Paper.pdf",
        "paper_title": "Fast, Provably convergent IRLS Algorithm for p-norm Linear Regression",
        "paper_author": "Deeksha Adil &middot; Richard Peng &middot; Sushant Sachdeva",
        "video_link": "https://www.youtube.com/watch?v=lG3ycfrK88g",
        "abstract": "Linear regression in L_p-norm is a canonical optimization problem that arises in several applications, including sparse recovery, semi-supervised learning, and signal processing. Generic convex optimization algorithms for solving L_p-regression are slow in practice. Iteratively Reweighted Least Squares (IRLS) is an easy to implement family of algorithms for solving these problems that has been studied for over 50 years. However, these algorithms often diverge for p &gt; 3, and since the work of Osborne (1985), it has been an open problem whether there is an IRLS algorithm that converges for p &gt; 3. We propose p-IRLS, the first IRLS algorithm that provably converges geometrically for any p \\in [2,\\infty). Our algorithm is simple to implement and is guaranteed to find a high accuracy solution in a sub-linear number of iterations. Our experiments demonstrate that it performs even better than our theoretical bounds, beats the standard Matlab/CVX implementation for solving these problems by 10\u201350x, and is the fastest among available implementations in the high-accuracy regime.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5233",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/26b58a41da329e0cbde0cbf956640a58-Paper.pdf",
        "paper_title": "Stochastic Variance Reduced Primal Dual Algorithms for Empirical Composition Optimization",
        "paper_author": "Adithya M Devraj &middot; Jianshu Chen",
        "video_link": "https://github.com/adidevraj/SVRPDA/wiki/Video",
        "abstract": "We consider a generic empirical composition optimization problem, where there are empirical averages present both outside and inside nonlinear loss functions. Such a problem is of interest in various machine learning applications, and cannot be directly solved by standard methods such as stochastic gradient descent (SGD). We take a novel approach to solving this problem by reformulating the original minimization objective into an equivalent min-max objective, which brings out all the empirical averages that are originally inside the nonlinear loss functions. We exploit the rich structures of the reformulated problem and develop a stochastic primal-dual algorithms, SVRPDA-I, to solve the problem efficiently. We carry out extensive theoretical analysis of the proposed algorithm, obtaining the convergence rate, the total computation complexity and the storage complexity. In particular, the algorithm is shown to converge at a linear rate when the problem is strongly convex. Moreover, we also develop an approximate version of the algorithm, named SVRPDA-II, which further reduces the memory requirement. Finally, we evaluate the performance of our algorithms on several real-world benchmarks and experimental results show that they significantly outperform existing techniques.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-8540",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/39d929972619274cc9066307f707d002-Paper.pdf",
        "paper_title": "Function-Space Distributions over Kernels",
        "paper_author": "Gregory Benton &middot; Wesley Maddox &middot; Jayson Salkey &middot; Julio Albinati &middot; Andrew Gordon Wilson",
        "video_link": " class=",
        "abstract": "\tGaussian processes are flexible function approximators, with inductive biases controlled by a covariance kernel. Learning the kernel is the key to representation learning and strong predictive performance. In this paper, we develop functional kernel learning (FKL) to directly infer functional posteriors over kernels. In particular, we place a transformed Gaussian process over a spectral density, to induce a non-parametric distribution over kernel functions. The resulting approach enables learning of rich representations, with support for any stationary kernel, uncertainty over the values of the kernel, and an interpretable specification of a prior directly over kernels, without requiring sophisticated initialization or manual intervention. We perform inference through elliptical slice sampling, which is especially well suited to marginalizing posteriors with the strongly correlated priors typical to function space modeling. We develop our approach for non-uniform, large-scale, multi-task, and multidimensional data, and show promising performance in a wide range of settings, including interpolation, extrapolation, and kernel recovery experiments.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5517",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/6c7cd904122e623ce625613d6af337c4-Paper.pdf",
        "paper_title": "Poincar\u00e9 Recurrence, Cycles and Spurious Equilibria in Gradient-Descent-Ascent for Non-Convex Non-Concave Zero-Sum Games",
        "paper_author": "Emmanouil-Vasileios Vlatakis-Gkaragkounis &middot; Lampros Flokas &middot; Georgios Piliouras",
        "video_link": "http://www.cs.columbia.edu/~emvlatakis/Videos/Poincare_Recurrence_Cycles_and_Spurious_Equilibria_in_Gradient-Descent-Ascent_for_Non-Convex_Non-Concave_Zero-Sum_Games.html",
        "abstract": "We study a wide class of non-convex non-concave min-max games that generalizes over standard bilinear zero-sum games. In this class, players control the inputs of a smooth function whose output is being applied to a bilinear zero-sum game. This class of games is motivated by the  indirect nature of the competition in\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5823",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/658bbbdef9415ba5e2ff857f1146ba6e-Paper.pdf",
        "paper_title": "McDiarmid-Type Inequalities for Graph-Dependent Variables and Stability Bounds",
        "paper_author": "Rui (Ray) Zhang &middot; Xingwu Liu &middot; Yuyi Wang &middot; Liwei Wang",
        "video_link": "https://rui-ray-zhang.github.io/NIPS/NIPS.mp4",
        "abstract": "A crucial assumption in most statistical learning theory is that samples are independently and identically distributed (i.i.d.). However, for many real applications, the i.i.d. assumption does not hold. We consider learning problems in which examples are dependent and their dependency relation is characterized by a graph. To establish algorithm-dependent generalization theory for learning with non-i.i.d. data, we first prove novel McDiarmid-type concentration inequalities for Lipschitz functions of graph-dependent random variables. We show that concentration relies on the forest complexity of the graph, which characterizes the strength of the dependency. We demonstrate that for many types of dependent data, the forest complexity is small and thus implies good concentration. Based on our new inequalities we are able to build stability bounds for learning from graph-dependent data.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6969",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/7813d1590d28a7dd372ad54b5d29d033-Paper.pdf",
        "paper_title": "Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs",
        "paper_author": "Jonas Kubilius &middot; Martin Schrimpf &middot; Ha Hong &middot; Najib Majaj &middot; Rishi Rajalingham &middot; Elias Issa &middot; Kohitij Kar &middot; Pouya Bashivan &middot; Jonathan Prescott-Roy &middot; Kailyn Schmidt &middot; Aran Nayebi &middot; Daniel Bear &middot; Daniel Yamins &middot; James J DiCarlo",
        "video_link": "https://cbmm.mit.edu/video/brain-object-recognition-high-performing-shallow-recurrent-anns",
        "abstract": "Deep convolutional artificial neural networks (ANNs) are the leading class of candidate models of the mechanisms of visual processing in the primate ventral stream. While initially inspired by brain anatomy, over the past years, these ANNs have evolved from a simple eight-layer architecture in AlexNet to extremely deep and branching architectures, demonstrating increasingly better object categorization performance, yet bringing into question how brain-like they still are. In particular, typical deep models from the machine learning community are often hard to map onto the brain&#x27;s anatomy due to their vast number of layers and missing biologically-important connections, such as recurrence. Here we demonstrate that better anatomical alignment to the brain and high performance on machine learning as well as neuroscience measures do not have to be in contradiction. We developed CORnet-S, a shallow ANN with four anatomically mapped areas and recurrent connectivity, guided by Brain-Score, a new large-scale composite of neural and behavioral benchmarks for quantifying the functional fidelity of models of the primate ventral visual stream. Despite being significantly shallower than most models, CORnet-S is the top model on Brain-Score and outperforms similarly compact models on ImageNet. Moreover, our extensive analyses of CORnet-S circuitry variants reveal that recurrence is the main predictive factor of both Brain-Score and ImageNet top-1 performance. Finally, we report that the temporal evolution of the CORnet-S &quot;IT&quot; neural population resembles the actual monkey IT population dynamics. Taken together, these results establish CORnet-S, a compact, recurrent ANN, as the current best model of the primate ventral visual stream.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4795",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/adf7ee2dcf142b0e11888e72b43fcb75-Paper.pdf",
        "paper_title": "This Looks Like That: Deep Learning for Interpretable Image Recognition",
        "paper_author": "Chaofan Chen &middot; Oscar Li &middot; Daniel Tao &middot; Alina Barnett &middot; Cynthia Rudin &middot; Jonathan K Su",
        "video_link": "https://youtu.be/k3IQnRsl9U4",
        "abstract": "When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture -- prototypical part network (ProtoPNet), that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The model thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training without any annotations for parts of images. We demonstrate our method on the CUB-200-2011 dataset and the Stanford Cars dataset. Our experiments show that ProtoPNet can achieve comparable accuracy with its analogous non-interpretable counterpart, and when several ProtoPNets are combined into a larger network, it can achieve an accuracy that is on par with some of the best-performing deep models. Moreover, ProtoPNet provides a level of interpretability that is absent in other interpretable deep models.",
        "transcript": "in this video we will present our paper this looks like that deep learning for interpret about image recognition suppose you are looking at a spurt and wondering what kind of burn it is you guess that the bird is a sparrow but how would you describe your thought process perhaps the birds had looks like that of a prototypical sparrow or the wing bars look like a sparrow swing bars when we classify images we might focus some parts of the image and compared them with prototypical aspects of a given class by saying this looks like that in this work we introduce a network architecture prototypical parts network or proto P net that defines a new form of interpretability in image recognition by explaining its classification decisions just like how we humans would do it in this way our model is interpret well in the sense that it has a transparent reasoning process while making predictions previous integratable models often explain classification decisions using attentions they point to either the entire object or the important parts of an object however it is often unclear for these models why the highlighter regions are recognized as important in contrast our model provides a retry explanation by not only highlighting the important parts but also justifying the highlighting by drawing comparison to prototypical aspects of each class more concretely our proto pianet introduced as a special prototype layer that can follow any feature extraction convolutional layers the product idea contains prototypes that can be understood as representations of typical parts in each class such as red wings for the class of red-winged blackbirds in the prototype layer the patches of convolutional features are compared to each other learned prototypes using l2 distances this generates a prototype activation map which tells us both the location of the most singular patch as well as the degree of such celerity as indicated by a similarity score for example the top would have here corresponds to the head of a clay color sparrow given the new input image on the left our model recognizes the upper right column edge of the input image which is the head of the bird to be very similar to this arrow head prototype which has the similarity score of 3.95 every blue have union in the prototype layer produces such as memory score and those linearity scores are weighted by a fully connected layer to produce the auto logits i the final source for all the classes our special prototype layer can be used on top of any deep convolutional feature extractors to enhance the models interpretability in our experiments we integrated the prototype layer with vgg resonant and dense net architectures the experimental results show that proto peanut can achieve comparable accuracy with its analogous non interpreting counterpart we can view decision-making of our model as evaluating a scoring sheet for each class here the final score for every class can be understood as a weighted sum of similarity scores with visualizable prototypes of that class the explanations generated by our network are actually used during classification and are not created post hoc to learn more about our work please check out our paper for more detail",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-3146",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/5d4ae76f053f8f2516ad12961ef7fe97-Paper.pdf",
        "paper_title": "Adversarial Training and Robustness for Multiple Perturbations",
        "paper_author": "Florian Tramer &middot; Dan Boneh",
        "video_link": "https://www.youtube.com/watch?v=aUDkfVd3t_8",
        "abstract": "Defenses against adversarial examples, such as adversarial training, are typically tailored to a single perturbation type (e.g., small $\\ell_\\infty$-noise). For other perturbations, these defenses offer no guarantees and, at times, even increase the model&#x27;s vulnerability.\n",
        "transcript": "this video presents our paper on address hull training and robustness for multiple perturbations which appears at nurbs 2019 we tackle the problem of defending machine learning models against multiple types of address all examples we show both formally and experimentally the existence of our business trade-off were defending against multiple perturbation types lowers the model's robustness to each individual type we also introduce a fine attacks that further reduce the accuracy of robust models by interpolating between perturbations so what are addressed all examples they are minimally perturbed inputs that reliably cause classifiers to make mistakes these fail show that machine learning models learn very different features than our own visual system and our concern for safety or security critical deployments a natural defense against address all examples is adverse el training for some chosen sets of perturbations that we want to be robust to we continuously generate worst-case address L perturbations for our model and add these to the training set address all training does improve robustness for the type of perturbations that the model is trained against infinity noise in this case but the model remains vulnerable to other types of perceptually small perturbations such as sparse noise or small rotations we just ask whether we can extend the address on training so as to learn a model that is simultaneously robust to multiple types of perturbations that an adversary might choose we generalize address all training to this setting by training a model on worst-case address on examples that come from the union of all the chosen sets so does this work yes though some interesting caveats on safe are 10 for instance we show that the model trained to be robust to just two types of perturbations loses about five percent of robust accuracy compared to models that were individually trained against each perturbation type we actually prove that this type of robustness trade-off is inherent in some natural classification tasks surprisingly on mes the situation is even worse a model trained on multiple types of LP noise achieves only about 50% robust accuracy a drop of 20% compared to models individually trained on each type of noise what's happening here is that to achieve an and finicky robustness the model learns to threshold the input pixels and is partially zeroes out to models gradients as a side effect is breaks l1 and l2 attacks and the model fails to learn the robust representation our work shows that this issue commonly known as gradient asking also effects advice on training finally we consider a more general adversary' that combines perturbation types as an example we show that instead of Eva rotating an image or adding small noise to it an adversity that there's a little bit of both confer producer models robust accuracy by 10 percent to conclude while we can train models against different types of adverse health examples this comes at a cost in robustness to each individual type our work raises some open questions such as how to prevent gradient masking on a list or how to more efficiently scale multi perturbation adverse health training finally there remains a fundamental question of how to list all the types of perturbations that we want our models to be robust to in order to emulate our own visual system if you'd like to learn more we invite you to read our paper or to attend our spotlight talk and poster at Europe's",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-8678",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/2201611d7a08ffda97e3e8c6b667a1bc-Paper.pdf",
        "paper_title": "Multi-Criteria Dimensionality Reduction with Applications to Fairness",
        "paper_author": "Uthaipon Tantipongpipat &middot; Samira Samadi &middot; Mohit Singh &middot; Jamie Morgenstern &middot; Santosh Vempala",
        "video_link": "https://youtu.be/aR64H5Jn0gY",
        "abstract": "Dimensionality reduction is a classical technique widely used for data analysis. One foundational instantiation is Principal Component Analysis (PCA),\n",
        "transcript": "hello my name is Tao I want to present a three-minute video for a multi criteria dimensionality reduction with applications to famous paper except at two nerves 2019 let's start first with the motivation we perform the standard PCA on the real data of face image consisting of male and female group what we observe is that the reconstruction area for male group is consistently better than female group for many target dimensions here we see that the reconstruction error is about 10% better for male than female so the question is how can we make it more fair to both groups our first contribution is to formulate a problem as multi-criteria dimensionality reduction or MC dr as you can see here you can think of fi as the generalization of variance I give you protection P the group may define the own utility something more general than just to variance and social welfare here doesn't have to be the sum like total variance as in standard PCA but it can be other function so for example in a Social Welfare the FI utility is the same is just o variance the social welfare is taken to be the product instead of some another example is marginal loss this case the FI is not the variance but the change of variance between the best projection the group could have gotten compared to the given protection which may be different because of the group in the same dataset and G is taken to be the group that has the worst performance algorithmically we give a polynomial time algorithm for this problem the guarantee is that it has the optimal utility and small rank correlation s which is roughly square root of 2 times the number of groups by scaling we can also achieve no Rev violation but with approximation ratio 1 - s over D on utility in practice we develop another method called multiplicative by update which scales better we perform an experiment and here's an example we look at the marginal last objective compare between our algorithm STP round and normal PCA STP round is specified to maximize national sugar Farah and SF and minimize marginal loss and interestingly even though it's specified to maximize now social welfare in marginal our objective is to perform significantly better than no more PCA our one theoretical contribution is to prove that every extreme point of the STP relaxation has low rank and this is a connection we made between up enough optimization community and machine learning community we give a complexity result of this problem showing the NP hardness of general for general K and polynomial-time solvability for fixed K the code is available online on github we also have a web page that give more explanation and motivation for free PCA thank you for listening",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1349",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/bcc0d400288793e8bdcd7c19a8ac0c2b-Paper.pdf",
        "paper_title": "Integrating Bayesian and Discriminative Sparse Kernel Machines for  Multi-class Active Learning",
        "paper_author": "Weishi Shi &middot; Qi Yu",
        "video_link": "https://drive.google.com/open?id=1awBUI9liuh28vfJWHlc2beoYm8Zfybm9",
        "abstract": "We propose a novel active learning (AL) model that integrates Bayesian and discriminative kernel machines for fast and accurate multi-class data sampling. By joining a sparse Bayesian model and a maximum margin machine under a unified kernel machine committee (KMC), the proposed model is able to identify a small number of data samples that best represent the overall data space while accurately capturing the decision boundaries. The integration is conducted using the  maximum entropy discrimination framework, resulting in a joint objective function that contains generalized entropy as a regularizer. Such a property allows the proposed AL model to choose data samples that more effectively handle non-separable classification problems. Parameter learning is achieved through a principled optimization framework that leverages  convex duality and sparse structure of KMC to efficiently optimize the joint objective function. Key model parameters are used to design a novel sampling function  to choose data samples that can simultaneously improve multiple decision boundaries, making it an effective sampler for problems with a large number of classes. Experiments conducted over both synthetic and real data and comparison with competitive AL methods demonstrate the effectiveness of the proposed model.\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5204",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/2e6d9c6052e99fcdfa61d9b9da273ca2-Paper.pdf",
        "paper_title": "Practical Two-Step Lookahead Bayesian Optimization",
        "paper_author": "Jian Wu &middot; Peter Frazier",
        "video_link": "https://github.com/wujian16/TwoStep-BayesOpt/tree/master/Presentation",
        "abstract": "Expected improvement and other acquisition functions widely used in Bayesian optimization use a &quot;one-step&quot; assumption: they value objective function evaluations assuming no future evaluations will be performed. Because we usually evaluate over multiple steps, this assumption may leave substantial room for improvement. Existing theory gives acquisition functions looking multiple steps in the future but calculating them requires solving a high-dimensional continuous-state continuous-action Markov decision process (MDP). Fast exact solutions of this MDP remain out of reach of today&#x27;s methods. As a result, previous two- and multi-step lookahead Bayesian optimization algorithms are either too expensive to implement in most practical settings or resort to heuristics that may fail to fully realize the promise of two-step lookahead. This paper proposes a computationally efficient algorithm that provides an accurate solution to the two-step lookahead Bayesian optimization problem in seconds to at most several minutes of computation per batch of evaluations. The resulting acquisition function provides increased query efficiency and robustness compared with previous two- and multi-step lookahead methods in both single-threaded and batch experiments. This unlocks the value of two-step lookahead in practice. We demonstrate the value of our algorithm with extensive experiments on synthetic test functions and real-world problems.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1775",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/36d7534290610d9b7e9abed244dd2f28-Paper.pdf",
        "paper_title": "Thompson Sampling for Multinomial Logit Contextual Bandits",
        "paper_author": "Min-hwan Oh &middot; Garud Iyengar",
        "video_link": "http://www.columbia.edu/~mo2499/ts-mnl.html",
        "abstract": "We consider a dynamic assortment selection problem where the goal is to offer a sequence of assortments that maximizes the expected cumulative revenue, or alternatively, minimize the expected regret. The feedback here is the item that the user picks from the assortment. The distinguishing feature in this work is that this feedback has a multinomial logistic distribution. The utility of each item is a dynamic function of contextual information of both the item and the user.\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6371",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/15825aee15eb335cc13f9b559f166ee8-Paper.pdf",
        "paper_title": "Online Continual Learning with Maximal Interfered Retrieval",
        "paper_author": "Rahaf Aljundi &middot; Eugene Belilovsky &middot; Tinne Tuytelaars &middot; Laurent Charlin &middot; Massimo Caccia &middot; Min Lin &middot; Lucas Page-Caccia",
        "video_link": "https://www.youtube.com/watch?v=wfb9UV_n8jg",
        "abstract": "Continual learning, the setting where a learning agent is faced with a never-ending stream of data, continues to be a great challenge for modern machine learning systems. In particular the online or &quot;single-pass through the data&quot; setting has gained attention recently as a natural setting that is difficult to tackle. Methods based on replay, either generative or from a stored memory, have been shown to be effective approaches for continual learning, matching or exceeding the state of the art in a number of standard benchmarks. These approaches typically rely on randomly selecting samples from the replay memory or from a generative model, which is suboptimal. In this work, we consider a controlled sampling of memories for replay. We retrieve the samples which are most interfered, i.e. whose prediction will be most negatively impacted by the foreseen parameters update. We show a formulation for this sampling criterion in both the generative replay and the experience replay setting, producing consistent gains in performance and greatly reduced forgetting. We release an implementation of our method at https://github.com/optimass/Maximally_Interfered_Retrieval",
        "transcript": "hi everyone today I will present our inner EPS paper on online continual learning and this is some work I did with a half Lukas Eugene myself Minh lava and Tina so in continued learning we're currently focused on solving the catastrophic forgetting problem which is that when a model learns a new task it completely forgets how to perform the previous task it learned so there's a couple of way to alleviate the catastrophic forgetting problem but one popular family of methods is rear salt so simply put when you train on a new task you're going to reuse the previous ones there's two Popular's way to achieve this the simplest one is when you sequentially train on task you're going to save some data from the previous task and you're going to retrain on those data points later on we're gonna call this experience replay or a memory replay another way to achieve rehearsal is instead of storing old data as is we're gonna compress it with a generative model so you're gonna train a generative model culturally and when you want to rehearse on past tasks you're just gonna generate some data and train on those generated data points now one important point I emitted is that you're going to randomly rears on the previous task this sort of assumes that when you're learning a new task it's causing a equal amount of interference on the previous task you've learned but this might be a bad assumption for example if I'm learning a new language maybe this will cause more interference on my language skills than on my ability to ride my bike so in this paper we ask can we do better than random rehearsal so I will explain the method with a little cartoon and then we're gonna dive deeper to it so let's say you've trained a classifier to recognize the digit from 0 to 4 and now you would like it to recognize the digit 5 as well so on the left you have the current loss landscape for this new task in parameter space and on the right you have the last landscape but in input space or in task space this might not be super clear right now but it's gonna get clearer in a second so the first thing we're gonna do is when we're going to take a data point for the from the current task and we're going to take a virtual update step this will most likely decrease the loss for the current task but will also most likely increase the loss on the previous task next we're gonna find where that loss would increase the most in this case it's on the digit number three because the tree looks a little bit like a five and next we're gonna up meant our mini-batch with the digit number three here and this will and now we're gonna take a real gradient update step and hopefully this will not increase as much the loss on the digit number three okay so we can apply our method to experience replay or generative replay it's a little bit easier to explain with experience replay so I will start with this one so you're training a classifier continually you have a standard objective function you're going to store memories in a buffer and when a new data point comes in you're going to take a virtual update step and then you're going to look inside the buffer for the top values where the in fearing interference is maximized and here the interference is the loss is the difference between the loss of the virtual model and the current model so to summarize you look inside your buffer for samples that you're forgetting the most basically and then you augment the mini-batch with those samples and hopefully you don't forget as much okay so now I will explain our method applied to generative replay so now instead of storing old data in a buffer we're storing it in a generative model which is composed of an encoder and a decoder again and you did a point comes in we're going to take our virtual update step and now instead of looking inside the buffer for those samples where interference is maximized we're going to look inside the latent space of the generator and we're gonna do this by gradient descent on the latent codes to maximize interference on a generated samples so long story short we were looking inside the latent space of the generator for a sample that we're forgetting the most given that virtual update and we also have a real constraint to encourage diversity in the retrieve samples okay so we're now going to look into qualitative results for the split M&S data set and this data set it's we split and this into five tasks first we have some offline experiment results so more than one epic pre-task so now you can see that when the model is learning the last task which consists of binary classification between eights and nines when the model is learning the digit 8 it's fetching sometimes the digit 3 which is similar to a 8 and when it's running about nines its fetching the digit number 4 so everything seems to be working as we anticipated in the online setting the it's much harder so as you can see that vai baseline is generating fading in digits or that are not always recognizable but in our case again when we're learning about the digit 8 & 9 we're fetching again the number 4 and the number 3 which seems to be recognizable so qualitatively speaking it seems that our method can outperform the baseline I'm now going to quickly talk about the quantitative results so first under splittin is data set and the permitted and this data set both our methods can outperform their respective baseline both in terms of accuracy and in terms of forgetting and we can also achieve the best performance over all the baselines and for the split safe art and data set we only applied our experience replay method because generative replay doesn't work yet on harder data sets like so far and again here we cannot perform the baselines so other stuffs you can find in the paper is another approach with which is an ibrid between the experience replay and the genetic replay approach we have results on mini imagenet which is a really hard data set for consider learning we have an ablation study we have results on online control generative modeling and we also have a nice code base that can reproduce reproduce all of the results so thanks for listening",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-3880",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/0dd1bc593a91620daecf7723d2235624-Paper.pdf",
        "paper_title": "Unsupervised Emergence of Egocentric Spatial Structure from Sensorimotor Prediction",
        "paper_author": "Alban Laflaqui\u00e8re &middot; Michael Garcia Ortiz",
        "video_link": "https://www.dropbox.com/sh/6jcy6mq1tp2u8th/AAD8aQiSvCybLKSL4kA-wdhia?dl=0",
        "abstract": "Despite its omnipresence in robotics application, the nature of spatial knowledge and the mechanisms that underlie its emergence in autonomous agents are still poorly understood. Recent theoretical works suggest that the Euclidean structure of space induces invariants in an agent\u2019s raw sensorimotor experience. We hypothesize that capturing these invariants is beneficial for sensorimotor prediction and that, under certain exploratory conditions, a motor representation capturing the structure of the external space should emerge as a byproduct of learning to predict future sensory experiences. We propose a simple sensorimotor predictive scheme, apply it to different agents and types of exploration, and evaluate the pertinence of these hypotheses. We show that a naive agent can capture the topology and metric regularity of its sensor\u2019s position in an egocentric spatial frame without any a priori knowledge, nor extraneous supervision.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-8678",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/2201611d7a08ffda97e3e8c6b667a1bc-Paper.pdf",
        "paper_title": "Multi-Criteria Dimensionality Reduction with Applications to Fairness",
        "paper_author": "Uthaipon Tantipongpipat &middot; Samira Samadi &middot; Mohit Singh &middot; Jamie Morgenstern &middot; Santosh Vempala",
        "video_link": "https://youtu.be/aR64H5Jn0gY",
        "abstract": "Dimensionality reduction is a classical technique widely used for data analysis. One foundational instantiation is Principal Component Analysis (PCA),\n",
        "transcript": "hello my name is Tao I want to present a three-minute video for a multi criteria dimensionality reduction with applications to famous paper except at two nerves 2019 let's start first with the motivation we perform the standard PCA on the real data of face image consisting of male and female group what we observe is that the reconstruction area for male group is consistently better than female group for many target dimensions here we see that the reconstruction error is about 10% better for male than female so the question is how can we make it more fair to both groups our first contribution is to formulate a problem as multi-criteria dimensionality reduction or MC dr as you can see here you can think of fi as the generalization of variance I give you protection P the group may define the own utility something more general than just to variance and social welfare here doesn't have to be the sum like total variance as in standard PCA but it can be other function so for example in a Social Welfare the FI utility is the same is just o variance the social welfare is taken to be the product instead of some another example is marginal loss this case the FI is not the variance but the change of variance between the best projection the group could have gotten compared to the given protection which may be different because of the group in the same dataset and G is taken to be the group that has the worst performance algorithmically we give a polynomial time algorithm for this problem the guarantee is that it has the optimal utility and small rank correlation s which is roughly square root of 2 times the number of groups by scaling we can also achieve no Rev violation but with approximation ratio 1 - s over D on utility in practice we develop another method called multiplicative by update which scales better we perform an experiment and here's an example we look at the marginal last objective compare between our algorithm STP round and normal PCA STP round is specified to maximize national sugar Farah and SF and minimize marginal loss and interestingly even though it's specified to maximize now social welfare in marginal our objective is to perform significantly better than no more PCA our one theoretical contribution is to prove that every extreme point of the STP relaxation has low rank and this is a connection we made between up enough optimization community and machine learning community we give a complexity result of this problem showing the NP hardness of general for general K and polynomial-time solvability for fixed K the code is available online on github we also have a web page that give more explanation and motivation for free PCA thank you for listening",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4795",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/adf7ee2dcf142b0e11888e72b43fcb75-Paper.pdf",
        "paper_title": "This Looks Like That: Deep Learning for Interpretable Image Recognition",
        "paper_author": "Chaofan Chen &middot; Oscar Li &middot; Daniel Tao &middot; Alina Barnett &middot; Cynthia Rudin &middot; Jonathan K Su",
        "video_link": "https://youtu.be/k3IQnRsl9U4",
        "abstract": "When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture -- prototypical part network (ProtoPNet), that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The model thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training without any annotations for parts of images. We demonstrate our method on the CUB-200-2011 dataset and the Stanford Cars dataset. Our experiments show that ProtoPNet can achieve comparable accuracy with its analogous non-interpretable counterpart, and when several ProtoPNets are combined into a larger network, it can achieve an accuracy that is on par with some of the best-performing deep models. Moreover, ProtoPNet provides a level of interpretability that is absent in other interpretable deep models.",
        "transcript": "in this video we will present our paper this looks like that deep learning for interpret about image recognition suppose you are looking at a spurt and wondering what kind of burn it is you guess that the bird is a sparrow but how would you describe your thought process perhaps the birds had looks like that of a prototypical sparrow or the wing bars look like a sparrow swing bars when we classify images we might focus some parts of the image and compared them with prototypical aspects of a given class by saying this looks like that in this work we introduce a network architecture prototypical parts network or proto P net that defines a new form of interpretability in image recognition by explaining its classification decisions just like how we humans would do it in this way our model is interpret well in the sense that it has a transparent reasoning process while making predictions previous integratable models often explain classification decisions using attentions they point to either the entire object or the important parts of an object however it is often unclear for these models why the highlighter regions are recognized as important in contrast our model provides a retry explanation by not only highlighting the important parts but also justifying the highlighting by drawing comparison to prototypical aspects of each class more concretely our proto pianet introduced as a special prototype layer that can follow any feature extraction convolutional layers the product idea contains prototypes that can be understood as representations of typical parts in each class such as red wings for the class of red-winged blackbirds in the prototype layer the patches of convolutional features are compared to each other learned prototypes using l2 distances this generates a prototype activation map which tells us both the location of the most singular patch as well as the degree of such celerity as indicated by a similarity score for example the top would have here corresponds to the head of a clay color sparrow given the new input image on the left our model recognizes the upper right column edge of the input image which is the head of the bird to be very similar to this arrow head prototype which has the similarity score of 3.95 every blue have union in the prototype layer produces such as memory score and those linearity scores are weighted by a fully connected layer to produce the auto logits i the final source for all the classes our special prototype layer can be used on top of any deep convolutional feature extractors to enhance the models interpretability in our experiments we integrated the prototype layer with vgg resonant and dense net architectures the experimental results show that proto peanut can achieve comparable accuracy with its analogous non interpreting counterpart we can view decision-making of our model as evaluating a scoring sheet for each class here the final score for every class can be understood as a weighted sum of similarity scores with visualizable prototypes of that class the explanations generated by our network are actually used during classification and are not created post hoc to learn more about our work please check out our paper for more detail",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-3146",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/5d4ae76f053f8f2516ad12961ef7fe97-Paper.pdf",
        "paper_title": "Adversarial Training and Robustness for Multiple Perturbations",
        "paper_author": "Florian Tramer &middot; Dan Boneh",
        "video_link": "https://www.youtube.com/watch?v=aUDkfVd3t_8",
        "abstract": "Defenses against adversarial examples, such as adversarial training, are typically tailored to a single perturbation type (e.g., small $\\ell_\\infty$-noise). For other perturbations, these defenses offer no guarantees and, at times, even increase the model&#x27;s vulnerability.\n",
        "transcript": "this video presents our paper on address hull training and robustness for multiple perturbations which appears at nurbs 2019 we tackle the problem of defending machine learning models against multiple types of address all examples we show both formally and experimentally the existence of our business trade-off were defending against multiple perturbation types lowers the model's robustness to each individual type we also introduce a fine attacks that further reduce the accuracy of robust models by interpolating between perturbations so what are addressed all examples they are minimally perturbed inputs that reliably cause classifiers to make mistakes these fail show that machine learning models learn very different features than our own visual system and our concern for safety or security critical deployments a natural defense against address all examples is adverse el training for some chosen sets of perturbations that we want to be robust to we continuously generate worst-case address L perturbations for our model and add these to the training set address all training does improve robustness for the type of perturbations that the model is trained against infinity noise in this case but the model remains vulnerable to other types of perceptually small perturbations such as sparse noise or small rotations we just ask whether we can extend the address on training so as to learn a model that is simultaneously robust to multiple types of perturbations that an adversary might choose we generalize address all training to this setting by training a model on worst-case address on examples that come from the union of all the chosen sets so does this work yes though some interesting caveats on safe are 10 for instance we show that the model trained to be robust to just two types of perturbations loses about five percent of robust accuracy compared to models that were individually trained against each perturbation type we actually prove that this type of robustness trade-off is inherent in some natural classification tasks surprisingly on mes the situation is even worse a model trained on multiple types of LP noise achieves only about 50% robust accuracy a drop of 20% compared to models individually trained on each type of noise what's happening here is that to achieve an and finicky robustness the model learns to threshold the input pixels and is partially zeroes out to models gradients as a side effect is breaks l1 and l2 attacks and the model fails to learn the robust representation our work shows that this issue commonly known as gradient asking also effects advice on training finally we consider a more general adversary' that combines perturbation types as an example we show that instead of Eva rotating an image or adding small noise to it an adversity that there's a little bit of both confer producer models robust accuracy by 10 percent to conclude while we can train models against different types of adverse health examples this comes at a cost in robustness to each individual type our work raises some open questions such as how to prevent gradient masking on a list or how to more efficiently scale multi perturbation adverse health training finally there remains a fundamental question of how to list all the types of perturbations that we want our models to be robust to in order to emulate our own visual system if you'd like to learn more we invite you to read our paper or to attend our spotlight talk and poster at Europe's",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-86",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/93db85ed909c13838ff95ccfa94cebd9-Paper.pdf",
        "paper_title": "Multi-Resolution Weak Supervision for Sequential Data",
        "paper_author": "Paroma Varma &middot; Frederic Sala &middot; Shiori Sagawa &middot; Jason A Fries &middot; Daniel Fu &middot; Saelig Khattar &middot; Ashwini Ramamoorthy &middot; Ke Xiao &middot; Kayvon  Fatahalian &middot; James Priest &middot; Christopher R\u00e9",
        "video_link": "http://fredsala.github.io/MultiResWS.mov",
        "abstract": "Since manually labeling training data is slow and expensive, recent industrial and scientific research efforts have turned to weaker or noisier forms of supervision sources. However, existing weak supervision approaches fail to model multi-resolution sources for sequential data, like video, that can assign labels to individual elements or collections of elements in a sequence. A key challenge in weak supervision is estimating the unknown accuracies and correlations of these sources without using labeled data. Multi-resolution sources exacerbate this challenge due to complex correlations and sample complexity that scales in the length of the sequence. We propose Dugong, the first framework to model multi-resolution weak supervision sources with complex correlations to assign probabilistic labels to training data. Theoretically, we prove that Dugong, under mild conditions, can uniquely recover the unobserved accuracy and correlation parameters and use parameter sharing to improve sample complexity. Our method assigns clinician-validated labels to population-scale biomedical video repositories, helping outperform traditional supervision by 36.8 F1 points and addressing a key use case where machine learning has been severely limited by the lack of expert labeled data. On average, Dugong improves over traditional supervision by 16.0 F1 points and existing weak supervision approaches by 24.2 F1 points across several video and sensor classification tasks. ",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-192",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/58a2fc6ed39fd083f55d4182bf88826d-Paper.pdf",
        "paper_title": "Reducing Noise in GAN Training with Variance Reduced Extragradient",
        "paper_author": "Tatjana Chavdarova &middot; Gauthier Gidel &middot; Fran\u00e7ois Fleuret &middot; Simon Lacoste-Julien",
        "video_link": "https://github.com/Chavdarova/SVRE/tree/master/video",
        "abstract": "We study the effect of the stochastic gradient noise on the training of generative adversarial networks (GANs) and show that it can prevent the convergence of standard game optimization methods, while the batch version converges. We address this issue with a novel stochastic variance-reduced extragradient (SVRE) optimization algorithm, which for a large class of games improves upon the previous convergence rates proposed in the literature. We observe empirically that SVRE performs similarly to a batch method on MNIST while being computationally cheaper, and that SVRE yields more stable GAN training on standard datasets.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-93",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/98dce83da57b0395e163467c9dae521b-Paper.pdf",
        "paper_title": "The Point Where Reality Meets Fantasy: Mixed Adversarial Generators for Image Splice Detection",
        "paper_author": "Vladimir V. Kniaz &middot; Vladimir Knyaz &middot; Fabio Remondino",
        "video_link": "https://www.dropbox.com/s/xfxszql3dh6a7uk/MAG_Presentation.mp4?dl=0",
        "abstract": "Modern photo editing tools allow creating realistic manipulated images easily. While fake images can be quickly generated, learning models for their detection is challenging due to the high variety of tampering artifacts and the lack of large labeled datasets of manipulated images. In this paper, we propose a new framework for training of discriminative segmentation model via an adversarial process. We simultaneously train four models: a generative retouching model G_R that translates manipulated image to the real image domain, a generative annotation model G_A that estimates the pixel-wise probability of image patch being either real or fake, and two discriminators D_R and D_A that qualify the output of G_R and G_A. The aim of model G_R is to maximize the probability of model G_A making a mistake. Our method extends the generative adversarial networks framework with two main contributions: (1) training of a generative model G_R against a deep semantic segmentation network G_A that learns rich scene semantics for manipulated region detection, (2) proposing per class semantic loss that facilitates semantically consistent image retouching by the G_R. We collected large-scale manipulated image dataset to train our model. The dataset includes 16k real and fake images with pixel-level annotations of manipulated areas. The dataset also provides ground truth pixel-level object annotations. We validate our approach on several modern manipulated image datasets, where quantitative results and ablations demonstrate that our method achieves and surpasses the state-of-the-art in manipulated image detection. We made our code and dataset publicly available.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2770",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/a7a3d70c6d17a73140918996d03c014f-Paper.pdf",
        "paper_title": "Neural Similarity Learning",
        "paper_author": "Weiyang Liu &middot; Zhen Liu &middot; James Rehg &middot; Le Song",
        "video_link": "http://wyliu.com/",
        "abstract": "Inner product-based convolution has been the founding stone of convolutional neural networks (CNNs), enabling end-to-end learning of visual representation. By generalizing inner product with a bilinear matrix, we propose the neural similarity which serves as a learnable parametric similarity measure for CNNs. Neural similarity naturally generalizes the convolution and enhances flexibility. Further, we consider the neural similarity learning (NSL) in order to learn the neural similarity adaptively from training data. Specifically, we propose two different ways of learning the neural similarity: static NSL and dynamic NSL. Interestingly, dynamic neural similarity makes the CNN  become a dynamic inference network. By regularizing the bilinear matrix, NSL can be viewed as learning the shape of kernel and the similarity measure simultaneously. We further justify the effectiveness of NSL with a theoretical viewpoint. Most importantly, NSL shows promising performance in visual recognition and few-shot learning, validating the superiority of NSL over the inner product-based convolution counterparts.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4818",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/e88f243bf341ded9b4ced444795c3f17-Paper.pdf",
        "paper_title": "Modeling Expectation Violation in Intuitive Physics with Coarse Probabilistic Object Representations",
        "paper_author": "Kevin Smith &middot; Lingjie Mei &middot; Shunyu Yao &middot; Jiajun Wu &middot; Elizabeth Spelke &middot; Josh Tenenbaum &middot; Tomer Ullman",
        "video_link": "https://www.youtube.com/watch?v=95HlF9nCca4",
        "abstract": "From infancy, humans have expectations about how objects will move and interact. Even young children expect objects not to move through one another, teleport, or disappear. They are surprised by mismatches between physical expectations and perceptual observations, even in unfamiliar scenes with completely novel objects. A model that exhibits human-like understanding of physics should be similarly surprised, and adjust its beliefs accordingly.  We propose ADEPT, a model that uses a coarse (approximate geometry) object-centric representation for dynamic 3D scene understanding. Inference integrates deep recognition networks, extended probabilistic physical simulation, and particle filtering for forming predictions and expectations across occlusion. We also present a new test set for measuring violations of physical expectations, using a range of scenarios derived from developmental psychology.  We systematically compare ADEPT, baseline models, and human expectations on this test set.  ADEPT outperforms standard network architectures in discriminating physically implausible scenes, and often performs this discrimination at the same level as people.",
        "transcript": "people have an early possibly innate understanding of the world termed core knowledge developmental research suggests that even babies already expect objects to behave in certain ways for example objects shouldn't just disappear or move through one another consider this video of a solid screen rotating over a teddy bear hiding it from view then rotating right through it Wow infants look longer at such events compared to similar looking events that do not violate physics such surprise signals can in turn direct learning the goal of this project is to model the early understanding of physics to capture expectation violation models should take in events and output scalars indicating the level of surprise the surprise for a physical violation event should be higher than a matched norm violation event we created eight different types of violations based on developmental research probing the principles of permanence solidity and continuity previous models based on video prediction performed poorly due to a lack of physical understanding we propose a model based on approximate D rendering extended physics and tracking or adept adept has two parts a perception module and a reasoning module the perception module D renders objects by segmenting them in extracting course attributes from each segment the coarser presentation helps generalize to unseen objects the reasoning module uses a probabilistic physics engine to unfold the belief state over time when a new frame comes in a depth compares the observation from the perception module with its prediction compute surprise and updates the belief putting it all together considering the following violation of permanence video in which two objects enter but only one object leaves the object tracking window shows the physics modules particle filter estimation for where the objects are the yellow object is assumed to have stopped behind the screen but then when the screen comes down this event is registered as surprising we compared them to this models based on video prediction including encoder/decoder Gann analyst TM we use relative accuracy to measure how well the models discriminate violations from control ad that performs best or ties in seven of the eight scenarios in our stimuli set it is the only model to perform above chance in all scenarios adept also generalizes best novel shapes not in the training we asked people to judge how surprising they found our scenarios we then compared the relative accuracies of each model to those of humans well not a perfect match and that predictions are the closest to humans with other models deviating by at least twice the rude mean square error in summary we introduced a new benchmark based on developmental research to test core physics the adapt model that recognizes implausible events using approximate perception and probabilistic dynamics and we also carried out a quantitative model comparison to human judgments this approach highlights the importance of object centric representations for generalizable physical scene understanding",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4107",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/2297607a5db8576d5ad6bbd83696ff60-Paper.pdf",
        "paper_title": "Nonlinear scaling of resource allocation in sensory bottlenecks",
        "paper_author": "Laura R Edmondson &middot; Alejandro Jimenez Rodriguez &middot; Hannes P. Saal",
        "video_link": "https://www.youtube.com/watch?v=M6ohnt_6J9Q",
        "abstract": "In many sensory systems, information transmission is constrained by a bottleneck,\n",
        "transcript": "hello my name is Laura Edmondson and I will give a short overview of our work non-linear scaling of resource allocation in sensory bottlenecks in biological sensory systems information transmission is often constrained by a neuro bottleneck where the number of output neurons is vastly smaller than the number of input neurons this implies that some information will be lost in the bottleneck furthermore receptors are often not distributed uniformly across the sensory sheet for varying their density for example envision the density of cones in the retina is much greater at the favia than the periphery in touch the mechanoreceptors are more densely packed in the fingertips and they are in the palm so given these constraints how should the output neurons represent the input spaces in this example we have a higher density region with three times as many input receptors packed into the same space as the corresponding low density region if there was no bottleneck then we might expect a one-to-one mapping of each receptor to an output neuron leading to a proportional representation of the input region receptors what happens when we have fewer outputs and inputs that is in the case of a bottleneck and how does the representation change depending on the width of the bottleneck we investigated these questions using an efficient coding model that maximizes overall information transmission information maximization is achieved by removing correlations from the input signal nearby receptors on the sensory sheet tend to be correlated with the correlations dropping off as a function of the receptor distance crucially neighboring receptors in a high-density input space will be more correlated than those in a low density input space in this paper we show that this problem can be solved by calculating the assault in the eigenvalues of the input covariances for the two regions shown here in blue and orange respectively furthermore for certain forms of the covariance function this can be done analytically so what did we find when the bottleneck is narrow the vast majority of the neurons are allocated to the high-density input region shown in blue leading to an expansion in the bottleneck for intermediate-sized bottlenecks the allocation converges to a constant value leaving to the plateau you see here now the lower density region shown in orange tends to be over-represented finally for wide bottlenecks the allocation converges to a representation proportional to the input ratio when the density ratio is larger the representation of the low-density region can be seen at smaller bottle net widths the width at which the low-density region over-representation plateaus is also smaller what happens when we change how fast the covariance function decays for the low-density region and narrow a covariance leads to the high density region being over-represented for increasingly large bottlenecks in conclusion limiting the number of output neurons does not lead to proportional representation and sensory receptors in the two input regions the input region representation can contract and expand depending on the width of the bottleneck and finally the extent of the spatial correlations and different ratios of receptor densities also influence the allocation in the bottleneck thank you for listening and please check out our paper for more details",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6969",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/7813d1590d28a7dd372ad54b5d29d033-Paper.pdf",
        "paper_title": "Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs",
        "paper_author": "Jonas Kubilius &middot; Martin Schrimpf &middot; Kohitij Kar &middot; Rishi Rajalingham &middot; Ha Hong &middot; Najib Majaj &middot; Elias Issa &middot; Pouya Bashivan &middot; Jonathan Prescott-Roy &middot; Kailyn Schmidt &middot; Aran Nayebi &middot; Daniel Bear &middot; Daniel Yamins &middot; James J DiCarlo",
        "video_link": "https://cbmm.mit.edu/video/brain-object-recognition-high-performing-shallow-recurrent-anns",
        "abstract": "Deep convolutional artificial neural networks (ANNs) are the leading class of candidate models of the mechanisms of visual processing in the primate ventral stream. While initially inspired by brain anatomy, over the past years, these ANNs have evolved from a simple eight-layer architecture in AlexNet to extremely deep and branching architectures, demonstrating increasingly better object categorization performance, yet bringing into question how brain-like they still are. In particular, typical deep models from the machine learning community are often hard to map onto the brain&#x27;s anatomy due to their vast number of layers and missing biologically-important connections, such as recurrence. Here we demonstrate that better anatomical alignment to the brain and high performance on machine learning as well as neuroscience measures do not have to be in contradiction. We developed CORnet-S, a shallow ANN with four anatomically mapped areas and recurrent connectivity, guided by Brain-Score, a new large-scale composite of neural and behavioral benchmarks for quantifying the functional fidelity of models of the primate ventral visual stream. Despite being significantly shallower than most models, CORnet-S is the top model on Brain-Score and outperforms similarly compact models on ImageNet. Moreover, our extensive analyses of CORnet-S circuitry variants reveal that recurrence is the main predictive factor of both Brain-Score and ImageNet top-1 performance. Finally, we report that the temporal evolution of the CORnet-S &quot;IT&quot; neural population resembles the actual monkey IT population dynamics. Taken together, these results establish CORnet-S, a compact, recurrent ANN, as the current best model of the primate ventral visual stream.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5317",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/125b93c9b50703fe9dac43ec231f5f83-Paper.pdf",
        "paper_title": "Efficiently avoiding saddle points with zero order methods: No gradients required ",
        "paper_author": "Emmanouil-Vasileios Vlatakis-Gkaragkounis &middot; Lampros Flokas &middot; Georgios Piliouras",
        "video_link": "http://www.cs.columbia.edu/~emvlatakis/Videos/Poincare_Recurrence_Cycles_and_Spurious_Equilibria_in_Gradient-Descent-Ascent_for_Non-Convex_Non-Concave_Zero-Sum_Games.html",
        "abstract": "We consider the case of derivative-free algorithms for non-convex optimization, also known as zero order algorithms, that use only function evaluations rather than gradients. For a wide variety of gradient approximators based on finite differences, we establish asymptotic convergence to second order stationary points using a carefully tailored application of the Stable Manifold Theorem.  Regarding efficiency, we introduce a noisy zero-order method that converges to second order stationary points, i.e avoids saddle points. Our algorithm uses only $\\tilde{\\mathcal{O}}(1 / \\epsilon^2)$ approximate gradient calculations and, thus, it matches the converge rate guarantees of their exact gradient counterparts up to constants. In contrast to previous work, our convergence rate analysis avoids imposing additional dimension dependent slowdowns in the number of iterations required for non-convex zero order optimization.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6819",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/b6f97e6f0fd175613910d613d574d0cb-Paper.pdf",
        "paper_title": "Control What You Can: Intrinsically Motivated Task-Planning Agent",
        "paper_author": "Sebastian Blaes &middot; Marin Vlastelica Pogan\u010di\u0107 &middot; Jiajie Zhu &middot; Georg Martius",
        "video_link": "https://owncloud.tuebingen.mpg.de/index.php/s/M3Ze4GStAn4aZdD",
        "abstract": "We present a novel intrinsically motivated agent that learns how to control the\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-7793",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/e2ccf95a7f2e1878fcafc8376649b6e8-Paper.pdf",
        "paper_title": "Generalization in Reinforcement Learning with Selective Noise Injection and Information Bottleneck",
        "paper_author": "Maximilian Igl &middot; Kamil Ciosek &middot; Yingzhen Li &middot; Sebastian Tschiatschek &middot; Cheng Zhang &middot; Sam Devlin &middot; Katja Hofmann",
        "video_link": "https://1drv.ms/v/s!Aj45y31uNubdlVXufoKxmwAqr0fP?e=TtGFfX",
        "abstract": "The ability for policies to generalize to new environments is key to the broad application of RL agents. A promising approach to prevent an agent\u2019s policy from overfitting to a limited set of training environments is to apply regularization techniques originally developed for supervised learning. However, there are stark differences between supervised learning and RL. We discuss those differences and propose modifications to existing regularization techniques in order to better adapt them to RL. In particular, we focus on regularization techniques relying on the injection of noise into the learned function, a family that includes some of the most widely used approaches such as Dropout and Batch Normalization. To adapt them to RL, we propose Selective Noise Injection (SNI), which maintains the regularizing effect the injected noise has, while mitigating the adverse effects it has on the gradient quality. Furthermore, we demonstrate that the Information Bottleneck (IB) is a particularly well suited regularization technique for RL as it is effective in the low-data regime encountered early on in training RL agents. Combining the IB with SNI, we significantly outperform current state of the art results, including on the recently proposed generalization benchmark Coinrun.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-7307",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/a1a527267c0d33a86382a03c4c721cd2-Paper.pdf",
        "paper_title": "Gossip-based Actor-Learner Architectures for Deep Reinforcement Learning",
        "paper_author": "Mahmoud Assran &middot; Joshua Romoff &middot; Nicolas Ballas &middot; Joelle Pineau &middot; Mike Rabbat",
        "video_link": "https://www.dropbox.com/sh/1ommra478q2j0mx/AAD8DpJMrnX_jYcfPKrht4nWa?dl=0",
        "abstract": "Multi-simulator training has contributed to the recent success of Deep Reinforcement Learning (Deep RL) by stabilizing learning and allowing for higher training throughputs. In this work, we propose Gossip-based Actor-Learner Architectures (GALA) where several actor-learners (such as A2C agents) are organized in a peer-to-peer communication topology, and exchange information through asynchronous gossip in order to take advantage of a large number of distributed simulators. We prove that GALA agents remain within an epsilon-ball of one-another during training when using loosely coupled asynchronous communication. By reducing the amount of synchronization between agents, GALA is more computationally efficient and scalable compared to A2C, its fully-synchronous counterpart. GALA also outperforms A2C, being more robust and sample efficient. We show that we can run several loosely coupled GALA agents in parallel on a single GPU and achieve significantly higher hardware utilization and frame-rates than vanilla A2C at comparable power draws.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-9215",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/5a44a53b7d26bb1e54c05222f186dcfb-Paper.pdf",
        "paper_title": "Imitation-Projected Programmatic Reinforcement Learning",
        "paper_author": "Abhinav Verma &middot; Hoang Le &middot; Yisong Yue &middot; Swarat Chaudhuri",
        "video_link": "https://sites.google.com/view/programmatic-rl",
        "abstract": "We study the problem of programmatic reinforcement learning, in which policies are represented as short programs in a symbolic language. Programmatic policies can be more interpretable, generalizable, and amenable to formal verification than neural policies; however, designing rigorous learning approaches for such policies remains a challenge. Our approach to this challenge - a meta-algorithm called PROPEL - is based on three insights. First, we view our learning task as optimization in policy space, modulo the constraint that the desired policy has a programmatic representation, and solve this optimization problem using a form of mirror descent that takes a gradient step into the unconstrained policy space and then projects back onto the constrained space.  Second, we view the unconstrained policy space as mixing neural and programmatic representations, which enables employing state-of-the-art deep policy gradient approaches.  Third, we cast the projection step as program synthesis via imitation learning, and exploit contemporary combinatorial methods for this task. We present theoretical convergence results for PROPEL and empirically evaluate the approach in three continuous control domains. The experiments show that PROPEL can significantly outperform state-of-the-art approaches for learning programmatic policies.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4541",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/2f3c6a4cd8af177f6456e7e51a916ff3-Paper.pdf",
        "paper_title": "The spiked matrix model with generative priors",
        "paper_author": "Benjamin Aubin &middot; Bruno Loureiro &middot; Antoine Maillard &middot; Florent Krzakala &middot; Lenka Zdeborov\u00e1",
        "video_link": "https://youtu.be/0XEVjCL_9Dk",
        "abstract": "Using a low-dimensional parametrization of signals is a generic and powerful way to enhance performance in signal processing and statistical inference. A very popular and widely explored type of dimensionality reduction is sparsity; another type is generative modelling of signal distributions. Generative models based on neural networks, such as GANs or variational auto-encoders, are particularly performant and are gaining on applicability. In this paper we study spiked matrix models, where a low-rank matrix is observed through a noisy channel. This problem with sparse structure of the spikes has attracted broad attention in the past literature. Here, we replace the sparsity assumption by generative modelling, and investigate the consequences on statistical and algorithmic properties. We analyze the Bayes-optimal performance under specific generative models for the spike. In contrast with the sparsity assumption, we do not observe regions of parameters where statistical performance is superior to the best known algorithmic performance. We show that in the analyzed cases the approximate message passing algorithm is able to reach optimal performance. We also design enhanced spectral algorithms and analyze their performance and thresholds using random matrix theory, showing their superiority to the classical principal component analysis. We complement our theoretical results by illustrating the performance of the spectral algorithms when the spikes come from real datasets.",
        "transcript": "hi my name is Bruno I need this video introduces the main ideas and results of our recent work on the spiked matrix model of genetic priors we all know that the structure of data plays a very important role in machine learning tasks and knowing how to capitalize it can make a major difference in training a model in recent years generative models for data such as variational autoencoders and generative diversity networks gaining popularity this generative models exploit expressivity of neural networks to create low dimensional latent representations of data sets on general grounds would like to understand how can we use these generative networks to improve signal reconstruction for example say that we want to denoise a corrupted image of a face if I train again on a given data set of photos can I use it again as a prior to include reconstruction in our work we study these questions on an analytically tractable setting our playground to explore this question will be Rank 1 matrix factorization in this problem we are given a matrix Y generated from adding noise to a rank one matrix and the aim is to reconstruct the exact realization of this star knowing this context at the spike this model is what is a widely study as a proxy for principal component analysis and indeed PCA is an optimal algorithm when the spike is unstructured but what happens when V has a lower dimensional structure a popular way to model this is to take the spike to be sparse in this case it is not surprising the PCA is no longer optimal since it doesn't use any information about the sparsity many algorithms know under the umbrella of sparse PCA are able to improve over vanilla piecing however quite striking no non algorithm is able to reach the statistically optimal noise threshold in this case instead what if we take the low dimensional structure to be encoded by a deep generative Network can we do better spoiler our work show that yes we did Ivan rigorously proved a form of describing the performance of the Bayes optimal estimator for any distribution for the spike in particular when this price taking from the example of our unknown generative networks with iid weights our formulas values for any distribution of the latent variable and for any choice of activation functions we also derive an approximate message passing algorithm to estimate the spike from Y we show that the performance of our EMP algorithm can be tracked down exactly in the high dimensional limit in particular for the more kamaal textures with activation functions to be linear real or sign the MP performance coincide with the optimal performance of the bayesian estimator previously discussed in other words different from sparse PC there is no algorithmic to statistical gap for studied architectures we also proposed a simple and easy to implement spectral method derived from our MD algorithm ensure that it starts to correlate with the spike at a statistically optimal fresh wound in particular it always beat PCA in performance curiously our spectral method depends on the structure of the spike only through its covariance this suggests we can apply to arbitrary structured data by using the empirical variance instead we probe this experimentally by choosing spike from real data set fashion immunised surprisingly our spectral method beats PC even though the spike is not drawn from a generative model unfortunately time is short and this video is just a taster of the main ideas and results of our work if you got here is and wants to know more please do pop by our poster on Friday or send us an email to arrange a discussion see you in your ribs",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6476",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/ab49ef78e2877bfd2c2bfa738e459bf0-Paper.pdf",
        "paper_title": "The Impact of Regularization on High-dimensional Logistic Regression",
        "paper_author": "Fariborz Salehi &middot; Ehsan Abbasi &middot; Babak Hassibi",
        "video_link": "https://caltech.box.com/s/e8gcoyxd2bwasd6kvkrgxvc9i9osmmmv",
        "abstract": "Logistic regression is commonly used for modeling dichotomous outcomes. In the classical setting, where the number of observations is much larger than the number of parameters, properties of the maximum likelihood estimator in logistic regression are well understood. Recently, Sur and Candes~\\cite{sur2018modern} have studied logistic regression in the high-dimensional regime, where the number of observations and parameters are comparable, and show, among other things, that the maximum likelihood estimator is biased. In the high-dimensional regime the underlying parameter vector is often structured (sparse, block-sparse, finite-alphabet, etc.) and so in this paper we study regularized logistic regression (RLR), where a convex regularizer that encourages the desired structure is added to the negative of the log-likelihood function. An advantage of RLR is that it allows parameter recovery even for instances where the (unconstrained) maximum likelihood estimate does not exist. We provide a precise analysis of the performance of RLR via the solution of a system of six nonlinear equations, through which any performance metric of interest (mean, mean-squared error, probability of support recovery, etc.) can be explicitly computed. Our results generalize those of Sur and Candes and we provide a detailed study for the cases of $\\ell_2^2$-RLR and sparse ($\\ell_1$-regularized) logistic regression. In both cases, we obtain explicit expressions for various performance metrics and can find the values of the regularizer parameter that optimizes the desired performance. The theory is validated by extensive numerical simulations across a range of parameter values and problem instances.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6320",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/faf02b2358de8933f480a146f4d2d98e-Paper.pdf",
        "paper_title": "On the Downstream Performance of Compressed Word Embeddings",
        "paper_author": "Avner May &middot; Jian Zhang &middot; Tri Dao &middot; Christopher R\u00e9",
        "video_link": "https://avnermay.github.io/compressed_embeddings_neurips_2019_video.mp4",
        "abstract": "Compressing word embeddings is important for deploying NLP models in memory-constrained settings. However, understanding what makes compressed embeddings perform well on downstream tasks is challenging---existing measures of compression quality often fail to distinguish between embeddings that perform well and those that do not. We thus propose the eigenspace overlap score as a new measure. We relate the eigenspace overlap score to downstream performance by developing generalization bounds for the compressed embeddings in terms of this score, in the context of linear and logistic regression. We then show that we can lower bound the eigenspace overlap score for a simple uniform quantization compression method, helping to explain the strong empirical performance of this method. Finally, we show that by using the eigenspace overlap score as a selection criterion between embeddings drawn from a representative set we compressed, we can efficiently identify the better performing embedding with up to 2x lower selection error rates than the next best measure of compression quality, and avoid the cost of training a separate model for each task of interest.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-39",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/d67d8ab4f4c10bf22aa353e27879133c-Paper.pdf",
        "paper_title": "Ask not what AI can do, but what AI should do: Towards a framework of task delegability",
        "paper_author": "Brian Lubars &middot; Chenhao Tan",
        "video_link": "http://tiny.cc/delegationvideo",
        "abstract": "While artificial intelligence (AI) holds promise for addressing societal challenges, issues of exactly which tasks to automate and to what extent to do so remain understudied. We approach this problem of task delegability from a human-centered perspective by developing a framework on human perception of task delegation to AI. We consider four high-level factors that can contribute to a delegation decision: motivation, difficulty, risk, and trust. To obtain an empirical understanding of human preferences in different tasks, we build a dataset of 100 tasks from academic papers, popular media portrayal of AI, and everyday life, and administer a survey based on our proposed framework. We find little preference for full AI control and a strong preference for machine-in-the-loop designs, in which humans play the leading role. Among the four factors, trust is the most correlated with human preferences of optimal human-machine delegation. This framework represents a first step towards characterizing human preferences of AI automation across tasks. We hope this work encourages future efforts towards understanding such individual attitudes; our goal is to inform the public and the AI research community rather than dictating any direction in technology development.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5938",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/62e0973455fd26eb03e91d5741a4a3bb-Paper.pdf",
        "paper_title": "Online Forecasting of Total-Variation-bounded Sequences",
        "paper_author": "Dheeraj Baby &middot; Yu-Xiang Wang",
        "video_link": "https://slideslive.com/38917673/online-forecasting-of-totalvariationbounded-sequences",
        "abstract": "We consider the problem of online forecasting of sequences of length $n$ with total-variation at most $C_n$ using observations contaminated by independent $\\sigma$-subgaussian noise. We design an $O(n\\log n)$-time algorithm that achieves a cumulative square error of $\\tilde{O}(n^{1/3}C_n^{2/3}\\sigma^{4/3} + C_n^2)$ with high probability. We also prove a lower bound that matches the upper bound in all parameters (up to a $\\log(n)$ factor). To the best of our knowledge, this is the first **polynomial-time** algorithm that achieves the optimal $O(n^{1/3})$ rate in forecasting total variation bounded sequences and the first algorithm that **adapts to unknown** $C_n$.Our proof techniques leverage the special localized structure of Haar wavelet basis and the adaptivity to unknown smoothness parameters in the classical wavelet smoothing [Donoho et al., 1998]. We also compare our model to the rich literature of dynamic regret minimization and nonstationary stochastic optimization, where our problem can be treated as a special case. We show that the workhorse in those settings --- online gradient descent and its variants with a fixed restarting schedule --- are instances of a class of **linear forecasters** that require a suboptimal regret of $\\tilde{\\Omega}(\\sqrt{n})$. This implies that the use of more adaptive algorithms is necessary to obtain the optimal rate. ",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-8876",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/73bf6c41e241e28b89d0fb9e0c82f9ce-Paper.pdf",
        "paper_title": "Understanding the Representation Power of Graph Neural Networks in Learning Graph Topology",
        "paper_author": "Nima Dehmamy &middot; Albert-Laszlo Barabasi &middot; Rose Yu",
        "video_link": "https://github.com/nimadehmamy/Understanding-GCN",
        "abstract": "To deepen our understanding of graph neural networks, we investigate the representation power of Graph Convolutional Networks (GCN) through the looking glass of graph moments, a key property of  graph topology encoding path of various lengths.\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6710",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/dffbb6efd376d8dbb22cdf491e481edc-Paper.pdf",
        "paper_title": "Universality in Learning from Linear Measurements",
        "paper_author": "Ehsan Abbasi &middot; Fariborz Salehi &middot; Babak Hassibi",
        "video_link": "https://caltech.box.com/s/vwr8lrxy9edr5m2vbwqheeryoi7y3wq6",
        "abstract": "We study the problem of recovering a structured signal from independently and identically drawn linear measurements. A convex penalty function $f(\\cdot)$ is considered which penalizes deviations from the desired structure, and signal recovery is performed by minimizing $f(\\cdot)$ subject to the linear measurement constraints. The main question of interest is to determine the minimum number of measurements that is necessary and sufficient for the perfect recovery of the unknown signal with high probability. Our main result states that, under some mild conditions on $f(\\cdot)$ and on the distribution from which the linear measurements are drawn, the minimum number of measurements required for perfect recovery depends only on the first and second order statistics of the measurement vectors. As a result, the required of number of measurements can be determining by studying measurement vectors that are Gaussian (and have the same mean vector and covariance matrix) for which a rich literature and comprehensive theory exists. As an application, we show that the minimum number of random quadratic measurements (also known as rank-one projections) required to recover a low rank positive semi-definite matrix is $3nr$, where $n$ is the dimension of the matrix and $r$ is its rank. As a consequence, we settle the long standing open question of determining the minimum number of measurements required for perfect signal recovery in phase retrieval using the celebrated PhaseLift algorithm, and show it to be $3n$.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-7492",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/c82b013313066e0702d58dc70db033ca-Paper.pdf",
        "paper_title": "Search-Guided, Lightly-Supervised Training of Structured Prediction Energy Networks",
        "paper_author": "Amirmohammad Rooshenas &middot; Dongxu Zhang &middot; Gopal Sharma &middot; Andrew McCallum",
        "video_link": "https://rooshenas.github.io/files/sg-spen.mp4",
        "abstract": " In structured output prediction tasks, labeling ground-truth training output is often expensive. However, for many tasks, even when the true output is unknown, we can evaluate predictions using a scalar reward function, which may be easily assembled from human knowledge or non-differentiable pipelines.  But searching through the entire output space to find the best output with respect to this reward function is typically intractable.  In this paper, we instead use efficient truncated randomized search in this reward function to train structured prediction energy networks (SPENs), which provide efficient test-time inference using gradient-based search on a smooth, learned representation of the score landscape, and have previously yielded state-of-the-art results in structured prediction.  In particular, this truncated randomized search in the reward function yields previously unknown local improvements, providing effective supervision to SPENs, avoiding their traditional need for labeled training data.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-8097",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/5a2afca61e35f45a7dd44ca46e0225f4-Paper.pdf",
        "paper_title": "Computational Mirrors: Blind Inverse Light Transport by Deep Matrix Factorization",
        "paper_author": "Miika Aittala &middot; Prafull Sharma &middot; Lukas Murmann &middot; Adam Yedidia &middot; Gregory Wornell &middot; Bill Freeman &middot; Fredo Durand",
        "video_link": "http://compmirrors.csail.mit.edu/videos/compmirrors_3minute.mp4",
        "abstract": "We recover a video of the motion taking place in a hidden scene by observing changes in indirect illumination in a nearby uncalibrated visible region. We solve this problem by factoring the observed video into a matrix product between the unknown hidden scene video and an unknown light transport matrix. This task is extremely ill-posed, as any non-negative factorization will satisfy the data. Inspired by recent work on the Deep Image Prior, we parameterize the factor matrices using randomly initialized convolutional neural networks trained in a one-off manner, and show that this results in decompositions that reflect the true motion in the hidden scene.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5098",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/f5ac21cd0ef1b88e9848571aeb53551a-Paper.pdf",
        "paper_title": "Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer",
        "paper_author": "Wenzheng Chen &middot; Huan Ling &middot; Jun Gao &middot; Edward Smith &middot; Jaakko Lehtinen &middot; Alec Jacobson &middot; Sanja Fidler",
        "video_link": "https://nv-tlabs.github.io/DIB-R/",
        "abstract": "Many machine learning models operate on images, but ignore the fact that images are 2D projections formed by 3D geometry interacting with light, in a process called rendering. Enabling ML models to understand image formation might be key for generalization. However, due to an essential rasterization step involving discrete assignment operations, rendering pipelines are non-differentiable and thus largely inaccessible to gradient-based ML techniques. In this paper, we present DIB-Render, a novel rendering framework through which gradients can be analytically computed. Key to our approach is to view rasterization as a weighted interpolation, allowing image gradients to back-propagate through various standard vertex shaders within a single framework. Our approach supports optimizing over vertex positions, colors, normals, light directions and texture coordinates, and allows us to incorporate various well-known lighting models from graphics. We showcase our approach in two ML applications: single-image 3D object prediction, and 3D textured object generation, both trained using exclusively 2D supervision. ",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4875",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/cf040fc71060367913e81ac1eb050aea-Paper.pdf",
        "paper_title": "STAR-Caps: Capsule Networks with Straight-Through Attentive Routing",
        "paper_author": "Karim Ahmed &middot; Lorenzo Torresani",
        "video_link": "http://bit.ly/2PA6JlV",
        "abstract": " Capsule networks have been shown to be powerful models for image classification, thanks to their ability to represent and capture viewpoint variations of an object. However, the high computational complexity of capsule networks that stems from the recurrent dynamic routing poses a major drawback making their use for large-scale image classification challenging. In this work, we propose Star-Caps a capsule-based network that exploits a straight-through attentive routing to address the drawbacks of capsule networks. By utilizing attention modules augmented by differentiable binary routers, the proposed mechanism estimates the routing coefficients between capsules without recurrence, as opposed to prior related work. Subsequently, the routers utilize straight-through estimators to make binary decisions to either connect or disconnect the route between capsules, allowing stable and faster performance. The experiments conducted on several image classification datasets, including MNIST, SmallNorb, CIFAR-10, CIFAR-100, and ImageNet show that STAR-Caps outperforms the baseline capsule networks.\n",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-39",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/d67d8ab4f4c10bf22aa353e27879133c-Paper.pdf",
        "paper_title": "Ask not what AI can do, but what AI should do: Towards a framework of task delegability",
        "paper_author": "Brian Lubars &middot; Chenhao Tan",
        "video_link": "http://tiny.cc/delegationvideo",
        "abstract": "While artificial intelligence (AI) holds promise for addressing societal challenges, issues of exactly which tasks to automate and to what extent to do so remain understudied. We approach this problem of task delegability from a human-centered perspective by developing a framework on human perception of task delegation to AI. We consider four high-level factors that can contribute to a delegation decision: motivation, difficulty, risk, and trust. To obtain an empirical understanding of human preferences in different tasks, we build a dataset of 100 tasks from academic papers, popular media portrayal of AI, and everyday life, and administer a survey based on our proposed framework. We find little preference for full AI control and a strong preference for machine-in-the-loop designs, in which humans play the leading role. Among the four factors, trust is the most correlated with human preferences of optimal human-machine delegation. This framework represents a first step towards characterizing human preferences of AI automation across tasks. We hope this work encourages future efforts towards understanding such individual attitudes; our goal is to inform the public and the AI research community rather than dictating any direction in technology development.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6217",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/9d1827dc5f75b9d65d80e25eb862e676-Paper.pdf",
        "paper_title": "A Zero-Positive Learning Approach for Diagnosing Software Performance Regressions",
        "paper_author": "Mejbah Alam &middot; Justin Gottschlich &middot; Nesime Tatbul &middot; Javier Turek &middot; Tim Mattson &middot; Abdullah Muzahid",
        "video_link": "https://youtu.be/FkT1aNoKbG4",
        "abstract": "The field of machine programming (MP), the automation of the development of software, is making notable research advances. This is, in part, due to the emergence of a wide range of novel techniques in machine learning. In this paper, we apply MP to the automation of software performance regression testing. A performance regression is a software performance degradation caused by a code change. We present AutoPerf \u2013 a novel approach to automate regression testing that utilizes three core techniques: (i) zero-positive learning, (ii) autoencoders, and (iii) hardware telemetry. We demonstrate AutoPerf\u2019s generality and efficacy against 3 types of performance regressions across 10 real performance bugs in 7 benchmark and open-source programs. On average, AutoPerf exhibits 4% profiling\n",
        "transcript": "I'd like to talk to you about our paper at Europe's zero positive learning approach for diagnosing softer performance regressions so this work is part of our larger program around machine programming automating software development and it's described in something we call the three pillars of machine programming intention invention and adaptation this work here falls within that adaptation pillar hunt down this paper you won't be disappointed and take a look it's really great any rate regression testing you release software you modify programs and you don't know it but sometimes you might introduce a performance degradation and when you do that be kind of good if you caught it before you released it for example our good friends with the MySQL world in 5.5 they noticed a performance issue that all the threads were contending over a single lock they got really clever and came out a way to get around that by giving each thread their own lock and released the code and only later found out it was 67% slower it was slower because of false sharing they didn't have a system to catch this and do the regression testing they released slower code so it's very important to look around and find your regression problems your performance problems so auto proof is what we call our tool it uses zero positive learning auto-encoders and hardware telemetry to build an automatic regression testing system so here's an example you run your program you collect performance counters that's the hardware telemetric data you train an autoencoder and then you run the modified program you collect the same hardware performance counters and then you run it through the auto encode a auto encoder and see if you get back the the input and output match if they do then you say you don't have a performance bug if they don't within a threshold you set you soom you have a performance bug and take appropriate action so here's the results we we ran this with performance bugs we inserted into seven benchmark and open source programs and it's important to note we didn't get any false negatives so that's really cool so now we're comparing our auto perf at the blue line to a state-of-the-art automated performance regression system called UBL and then another threshold approach that we came up with it looks at the length of the input and output vectors around the auto encoder and what we're showing here is that for a number of threshold exact quality metric getting a very very high true positive rate without a high false positive rate so really good really successful we're really excited about it so it's a generalized software performance analysis system it's effective general scalable come hunt us down at nura and learn more about this it's really great thank you",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4567",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/6562c5c1f33db6e05a082a88cddab5ea-Paper.pdf",
        "paper_title": "The Synthesis of XNOR Recurrent Neural Networks with Stochastic Logic",
        "paper_author": "Arash Ardakani &middot; Zhengyun Ji &middot; Amir Ardakani &middot; Warren Gross",
        "video_link": "http://isip.ece.mcgill.ca/media/neurips_2019/video.mp4",
        "abstract": "The emergence of XNOR networks seek to reduce the model size and computational cost of neural networks for their deployment on specialized hardware requiring real-time processes with limited hardware resources. In XNOR networks, both weights and activations are binary, bringing great benefits to specialized hardware by replacing expensive multiplications with simple XNOR operations. Although XNOR convolutional and fully-connected neural networks have been successfully developed during the past few years, there is no XNOR network implementing commonly-used variants of recurrent neural networks such as long short-term memories (LSTMs). The main computational core of LSTMs involves vector-matrix multiplications followed by a set of non-linear functions and element-wise multiplications to obtain the gate activations and state vectors, respectively. Several previous attempts on quantization of LSTMs only focused on quantization of the vector-matrix multiplications in LSTMs while retaining the element-wise multiplications in full precision. In this paper, we propose a method that converts all the multiplications in LSTMs to XNOR operations using stochastic computing. To this end, we introduce a weighted finite-state machine and its synthesis method to approximate the non-linear functions used in LSTMs on stochastic bit streams. Experimental results show that the proposed XNOR LSTMs reduce the computational complexity of their quantized counterparts by a factor of 86x without any sacrifice on latency while achieving a better accuracy across various temporal tasks.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-2401",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/959ef477884b6ac2241b19ee4fb776ae-Paper.pdf",
        "paper_title": "Learning Deep Bilinear Transformation for Fine-grained Image Representation",
        "paper_author": "Heliang Zheng &middot; Jianlong Fu &middot; Zheng-Jun Zha &middot; Jiebo Luo",
        "video_link": "https://drive.google.com/open?id=1IBfLuHMZ5cUUDugVgcpupwwT7e5OneAu",
        "abstract": "Bilinear feature transformation has shown the state-of-the-art performance in learning fine-grained image representations. However, the computational cost to learn pairwise interactions between deep feature channels is prohibitively expensive, which restricts this powerful transformation to be used in deep neural networks. In this paper, we propose a deep bilinear transformation (DBT) block, which can be deeply stacked in convolutional neural networks to learn fine-grained image representations. The DBT block can uniformly divide input channels into several semantic groups. As bilinear transformation can be represented by calculating pairwise interactions within each group, the computational cost can be heavily relieved. The output of each block is further obtained by aggregating intra-group bilinear features, with residuals from the entire input features. We found that the proposed network achieves new state-of-the-art in several fine-grained image recognition benchmarks, including CUB-Bird, Stanford-Car, and FGVC-Aircraft.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4927",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/50d2d2262762648589b1943078712aa6-Paper.pdf",
        "paper_title": "Write, Execute, Assess: Program Synthesis with a REPL",
        "paper_author": "Kevin Ellis &middot; Maxwell Nye &middot; Yewen Pu &middot; Felix Sosa &middot; Josh Tenenbaum &middot; Armando Solar-Lezama",
        "video_link": "https://www.youtube.com/watch?v=B3T_mEb2NGA",
        "abstract": "  We present a neural program synthesis approach integrating components which write, execute, and assess code to navigate the search space of possible programs. We equip the search process with an interpreter or a read-eval-print-loop (REPL), which immediately executes partially written programs, exposing their semantics. The REPL addresses a basic challenge of program synthesis: tiny changes in syntax can lead to huge changes in semantics. We train a pair of models, a policy that proposes the new piece of code to write, and a value function that assesses the prospects of the code written so-far. At test time we can combine these models with a Sequential Monte Carlo algorithm. We apply our approach to two domains: synthesizing text editing programs and inferring 2D and 3D graphics programs.",
        "transcript": "hello this is a three-minute presentation on write execute assess program synthesis with the repple program synthesis is a process where one turns a specification into a program which satisfies the specification in this work we consider two domains of program synthesis the first domain is the programmatic recovery of a pixel or voxel field the specification is a voxel field and once the program is recovered it can be rendered under different views in the second domain the spec is a set of text manipulation input/output examples which was the program is synthesized can then be run on different input program synthesis is useful in two ways as the last slide shows it can be directly useful in addition it is a good formulation of general structural induction tasks such as semantic parsing and even modeling human handwriting's program synthesis can be difficult in this work we focus on addressing two difficulties one there is a syntax semantics gap where a small change in syntax can caused a huge change in semantics to the issue of compounding errors in synthesizing long programs to address these two difficulties we use a rebel here's what program synthesis with the rebel looks like first a code writing policy writes a piece of code second a code executing repo execute the code last a code assessing value function looks at the execution and see if we're on the right track by using the repo we address the difficulty of the syntax semantics gap by exposing the semantics of the partially written code as a rebel state we use SMC to address the difficulty of synthesizing lung programs by using the value function on the report state we can better guide the search by reallocating search budgets toward publishing partial programs qualitatively we show that the repple and the value function are important components for successful synthesis where our approach outperforms just a beam search and policy rollouts which do not use the values and we also outperform the note rapport baseline here are the quantitative results showing our approach indeed or performs a baseline that do not leverage the rebel and a learn value function thank you",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-4701",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/a9ad5f2808f68eea468621a04c49efe1-Paper.pdf",
        "paper_title": "Seeing the Wind: Visual Wind Speed Prediction with a Coupled Convolutional and Recurrent Neural Network",
        "paper_author": "Jennifer Cardona &middot; Michael Howland &middot; John Dabiri",
        "video_link": "https://purl.stanford.edu/xx328hs4974",
        "abstract": "Wind energy resource quantification, air pollution monitoring, and weather forecasting all rely on rapid, accurate measurement of local wind conditions. Visual observations of the effects of wind---the swaying of trees and flapping of flags, for example---encode information regarding local wind conditions that can potentially be leveraged for visual anemometry that is inexpensive and ubiquitous. Here, we demonstrate a coupled convolutional neural network and recurrent neural network architecture that extracts the wind speed encoded in visually recorded flow-structure interactions of a flag and tree in naturally occurring wind. Predictions for wind speeds ranging from 0.75-11 m/s showed agreement with measurements from a cup anemometer on site, with a root-mean-squared error approaching the natural wind speed variability due to atmospheric turbulence. Generalizability of the network was demonstrated by successful prediction of wind speed based on recordings of other flags in the field and in a controlled wind tunnel test. Furthermore, physics-based scaling of the flapping dynamics accurately predicts the dependence of the network performance on the video frame rate and duration.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6993",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/383beaea4aa57dd8202dbff464fee3af-Paper.pdf",
        "paper_title": "Recurrent Space-time Graph Neural Networks",
        "paper_author": "Andrei Nicolicioiu &middot; Iulia Duta &middot; Marius Leordeanu",
        "video_link": "https://drive.google.com/file/d/1OY4J4kJV6XF6kH0ZWIthsfUYFK138SMd/view?usp=sharing",
        "abstract": " Learning in the space-time domain remains a very challenging problem in machine learning and computer vision. Current computational models for understanding spatio-temporal visual data are heavily rooted in the classical single-image based paradigm. It is not yet well understood how to integrate information in space and time into a single, general model. We propose a neural graph model, recurrent in space and time, suitable for capturing both the local appearance and the complex higher-level interactions of different entities and objects within the changing world scene. Nodes and edges in our graph have dedicated neural networks for processing information. Nodes operate over features extracted from local parts in space and time and over previous memory states. Edges process messages between connected nodes at different locations and spatial scales or between past and present time. Messages are passed iteratively in order to transmit information globally and establish long range interactions. Our model is general and could learn to recognize a variety of high level spatio-temporal concepts and be applied to different learning tasks. We demonstrate, through extensive experiments and ablation studies, that our model outperforms strong baselines and top published methods on recognizing complex activities in video. Moreover, we obtain state-of-the-art performance on the challenging Something-Something human-object interaction dataset.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-5037",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/97af07a14cacba681feacf3012730892-Paper.pdf",
        "paper_title": "ObjectNet: A large-scale bias-controlled dataset for pushing the limits of object recognition models",
        "paper_author": "Andrei Barbu &middot; David Mayo &middot; Julian Alverio &middot; William Luo &middot; Christopher Wang &middot; Dan Gutfreund &middot; Josh Tenenbaum &middot; Boris Katz",
        "video_link": "https://objectnet.dev/3-minute-video.avi",
        "abstract": "We collect a large real-world test set, ObjectNet, for object recognition with controls where object backgrounds, rotations, and imaging viewpoints are random. Most scientific experiments have controls, confounds which are removed from the data, to ensure that subjects cannot perform a task by exploiting trivial correlations in the data. Historically, large machine learning and computer vision datasets have lacked such controls. This has resulted in models that must be fine-tuned for new datasets and perform better on datasets than in real-world applications. When tested on ObjectNet, object detectors show a 40-45% drop in performance, with respect to their performance on other benchmarks, due to the controls for biases. Controls make ObjectNet robust to fine-tuning showing only small performance increases. We develop a highly automated platform that enables gathering datasets with controls by crowdsourcing image capturing and annotation. ObjectNet is the same size as the ImageNet test set (50,000 images), and by design does not come paired with a training set in order to encourage generalization. The dataset is both easier than ImageNet (objects are largely centered and unoccluded) and harder (due to the controls). Although we focus on object recognition here, data with controls can be gathered at scale using automated tools throughout machine learning to generate datasets that exercise models in new ways thus providing valuable feedback to researchers. This work opens up new avenues for research in generalizable, robust, and more human-like computer vision and in creating datasets where results are predictive of real-world performance.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-1294",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/84438b7aae55a0638073ef798e50b4ef-Paper.pdf",
        "paper_title": "GENO -- GENeric Optimization for Classical Machine Learning",
        "paper_author": "Soeren Laue &middot; Matthias Mitterreiter &middot; Joachim Giesen",
        "video_link": "http://www.geno-project.org/videoNeurIPS.mp4",
        "abstract": "Although optimization is the longstanding, algorithmic backbone of machine learning new models still require the time-consuming implementation of new solvers. As a result, there are thousands of implementations of optimization algorithms for machine learning problems. A natural question is, if it is always necessary to implement a new solver, or is there one algorithm that is sufficient for most models. Common belief suggests that such a one-algorithm-fits-all approach cannot work, because this algorithm cannot exploit model specific structure. At least, a generic algorithm cannot be efficient and robust on a wide variety of problems. Here, we challenge this common belief. We have designed and implemented the optimization framework GENO (GENeric Optimization) that combines a modeling language with a generic solver. GENO takes the declaration of an optimization problem and generates a solver for the specified problem class. The framework is flexible enough to encompass most of the classical machine learning problems. We show on a wide variety of classical but also some recently suggested problems that the automatically generated solvers are (1) as efficient as well engineered, specialized solvers, (2) more efficient by a decent margin than recent state-of-the-art solvers, and (3) orders of magnitude more efficient than classical modeling language plus solver approaches.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-6320",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/faf02b2358de8933f480a146f4d2d98e-Paper.pdf",
        "paper_title": "On the Downstream Performance of Compressed Word Embeddings",
        "paper_author": "Avner May &middot; Jian Zhang &middot; Tri Dao &middot; Christopher R\u00e9",
        "video_link": "https://avnermay.github.io/compressed_embeddings_neurips_2019_video.mp4",
        "abstract": "Compressing word embeddings is important for deploying NLP models in memory-constrained settings. However, understanding what makes compressed embeddings perform well on downstream tasks is challenging---existing measures of compression quality often fail to distinguish between embeddings that perform well and those that do not. We thus propose the eigenspace overlap score as a new measure. We relate the eigenspace overlap score to downstream performance by developing generalization bounds for the compressed embeddings in terms of this score, in the context of linear and logistic regression. We then show that we can lower bound the eigenspace overlap score for a simple uniform quantization compression method, helping to explain the strong empirical performance of this method. Finally, we show that by using the eigenspace overlap score as a selection criterion between embeddings drawn from a representative set we compressed, we can efficiently identify the better performing embedding with up to 2x lower selection error rates than the next best measure of compression quality, and avoid the cost of training a separate model for each task of interest.",
        "transcript": "NA",
        "transcription_mode": "NA"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-7101",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/b33128cb0089003ddfb5199e1b679652-Paper.pdf",
        "paper_title": "Piecewise Strong Convexity of Neural Networks",
        "paper_author": "Tristan Milne",
        "video_link": "https://www.youtube.com/watch?v=z89BTMQGVng",
        "abstract": "We study the loss surface of a feed-forward neural network with ReLU non-linearities, regularized with weight decay. We show that the regularized loss function is piecewise strongly convex on an important open set which contains, under some conditions, all of its global minimizers. This is used to prove that local minima of the regularized loss function in this set are isolated, and that every differentiable critical point in this set is a local minimum, partially addressing an open problem given at the Conference on Learning Theory (COLT) 2015; our result is also applied to linear neural networks to show that with weight decay regularization, there are no non-zero critical points in a norm ball obtaining training error below a given threshold. We also include an experimental section where we validate our theoretical work and show that the regularized loss function is almost always piecewise strongly convex when restricted to stochastic gradient descent trajectories for three standard image classification problems.",
        "transcript": "hello my name is Tristan Milne and this is a short summary of my paper piecewise strong convexity of neural networks in this paper we consider a feed-forward neural network Y with parameters W a scalar output and r lu nonlinearities for a target function f we take the loss function as 1/2 the mean squared error over a data set if the network has more than one layer this function is non convex surprisingly stochastic gradient descent works well on it so how bad can it really be in this paper we obtain some structural results for this loss function regularized with weight decay we will use L lambda for the regularize loss function our first result is that L has no differentiable local Maxima this follows by showing that the laplacian of L is non-negative and then using the maximum principle for sub harmonic functions this means that the loss function can't look like the plot on the left which has a differentiable local maximum it can look like the function on the right however which has a non differentiable local maximum our second result is that L lambda is piecewise strongly convex on the set u lambda theta here C depends on the architecture and data set H is depth the star norm is the largest spectral norm of the weight matrices and L lambda has a positive definite Hessian on you lambda theta does you lambda theta matter at all though well with some conditions it contains all global minimizer's of L lambda so this result describes the structure of L lambda around its global minimizer's how similar are piecewise strongly convex functions and strongly convex functions we show that they share some important properties from an optimization perspective first every differentiable critical point of a piecewise strongly convex function is a local minimum second local minima are isolated from each other in other words they are locally unique whereas for a strongly convex function minimizer's are simply unique we also include an experimental sex where we validate our theoretical work by showing the gradient descent does enter you lambda theta for a toy problem we also analyze three classic image classification problems and show that the loss function on SGD trajectories is almost always piecewise strongly convex to give context for our work will mention some related papers these three papers include strong results for mostly linear networks these two papers include similar results to ours for nonlinear networks with restricted architectures usually with a single hidden layer our contribution is to the understanding of L lambda for nonlinear networks with any architecture and any data set I'll be it on a subset of the weights thanks for watching",
        "transcription_mode": "YouTube Transcript API"
    },
    {
        "paper_link": "http://papers.nips.cc/paper/by-source-2019-8002",
        "paper_pdf_link": "https://proceedings.neurips.cc/paper/2019/file/d9fbed9da256e344c1fa46bb46c34c5f-Paper.pdf",
        "paper_title": "PowerSGD: Practical Low-Rank Gradient Compression for Distributed Optimization",
        "paper_author": "Thijs Vogels &middot; Sai Praneeth Karimireddy &middot; Martin Jaggi",
        "video_link": "https://youtu.be/xVxSu7KGtHw",
        "abstract": "We study gradient compression methods to alleviate the communication bottleneck in data-parallel distributed optimization. Despite the significant attention received, current compression schemes either do not scale well, or fail to achieve the target test accuracy. We propose a low-rank gradient compressor that can i) compress gradients rapidly, ii) efficiently aggregate the compressed gradients using all-reduce, and iii) achieve test performance on par with SGD. The proposed algorithm is the only method evaluated that achieves consistent wall-clock speedups when benchmarked against regular SGD with an optimized communication backend. We demonstrate reduced training times for convolutional networks as well as LSTMs on common datasets.",
        "transcript": "in data parallel optimization of deep learning models several workers compute gradients on their own batches of data after computing them they need to share what they found with each other but because the gradients they compute are typically hundreds of megabytes large this communication limits the scalability of distributed training one way people have dealt with this issue is to apply lossy compression to the gradients before sending them around a popular scheme is to only send a sparse set of the gradient coordinates and another approach is to quantize the coordinates values barosky D compresses gradients differently we see the gradients as a matrix its columns correspond to the layers input features and the rows correspond to output features we compress this matrix using a low-rank approximation you could compute this using a singular value decomposition but that is very expensive so instead power SGD computes a cheap approximation to this factorization using just one step of power iteration ok let's take a look at communication in distributed gradient descent a normal uncompressed SGD workers can quickly settle on their average gradient by computing it in a hierarchical fashion using all reduce unfortunately you usually can't use all reduce for compressed gradients if you have to one bit gradients for example then you cannot average them into a new one bit gradient without additional approximation so for that reason compressed algorithms resort to less scalable all-to-all communication or use a parameter server power std remarkably combines the benefits of compression with all reduce let me show you why to compute the low-rank approximation we apply matrix multiplications with the average gradient across workers but we can actually avoid the heavy communication required to compute this average gradient because of linearity each worker can equivalently do the computation on their own in gradient and we average they're much smaller outputs instead because this is a normal averaging operation per se D enjoys all the benefits of all reduce now even though a sloppy Rank 2 approximation to gray of science thousand five thousand is quite inaccurate porosity still converges that is due to error feedback with error feedback every time workers compress a gradient they memorize the errors they made locally and the next time a grain is compressed they add this error to the gradient before compression this means that all of their gradient will be used eventually to sum up power STV can achieve very high compression ratios and we find that these reductions in communication can result in significant end to end training speed ups to achieve the same test accuracy as normal SGD the best part is simple you can start using power HTV by plugging it into your existing optimizer you shouldn't have to modify the current type of parameters with a high enough rank you should be good to go if you're interested have a look at our paper or the code on github",
        "transcription_mode": "YouTube Transcript API"
    }
]